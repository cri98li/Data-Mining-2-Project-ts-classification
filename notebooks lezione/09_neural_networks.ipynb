{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** [Riccardo Guidotti](http://kdd.isti.cnr.it/people/riccardo-guidotti)  \n",
    "**Python version:**  3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-04 17:51:00</td>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-04 17:51:59</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-04 17:53:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-04 17:54:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-02-04 17:55:00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Temperature  Humidity  Light     CO2  HumidityRatio  \\\n",
       "1  2015-02-04 17:51:00        23.18   27.2720  426.0  721.25       0.004793   \n",
       "2  2015-02-04 17:51:59        23.15   27.2675  429.5  714.00       0.004783   \n",
       "3  2015-02-04 17:53:00        23.15   27.2450  426.0  713.50       0.004779   \n",
       "4  2015-02-04 17:54:00        23.15   27.2000  426.0  708.25       0.004772   \n",
       "5  2015-02-04 17:55:00        23.10   27.2000  426.0  704.50       0.004757   \n",
       "\n",
       "   Occupancy  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = 'Occupancy'\n",
    "df = pd.read_csv('occupancy_data/datatraining.txt', skipinitialspace=True, na_values='?', keep_default_na=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daytime(h):\n",
    "    if 6 <= h < 13:\n",
    "        return 'morning'\n",
    "    elif 13 <= h < 18:\n",
    "        return 'afternoon'\n",
    "    elif 18 <= h < 22:\n",
    "        return 'evening'\n",
    "    return 'night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>daytime</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Light     CO2  HumidityRatio  Occupancy    daytime  \\\n",
       "1        23.18   27.2720  426.0  721.25       0.004793          1  afternoon   \n",
       "2        23.15   27.2675  429.5  714.00       0.004783          1  afternoon   \n",
       "3        23.15   27.2450  426.0  713.50       0.004779          1  afternoon   \n",
       "4        23.15   27.2000  426.0  708.25       0.004772          1  afternoon   \n",
       "5        23.10   27.2000  426.0  704.50       0.004757          1  afternoon   \n",
       "\n",
       "   weekend  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "5        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['daytime'] = [daytime(d.hour) for d in pd.to_datetime(df['date'])]\n",
    "df['weekend'] = [1 if d.weekday() >= 5 else 0 for d in pd.to_datetime(df['date'])]\n",
    "columns2remove = ['date']\n",
    "df.drop(columns2remove, inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>weekend</th>\n",
       "      <th>daytime=afternoon</th>\n",
       "      <th>daytime=evening</th>\n",
       "      <th>daytime=morning</th>\n",
       "      <th>daytime=night</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Light     CO2  HumidityRatio  weekend  \\\n",
       "1        23.18   27.2720  426.0  721.25       0.004793        0   \n",
       "2        23.15   27.2675  429.5  714.00       0.004783        0   \n",
       "3        23.15   27.2450  426.0  713.50       0.004779        0   \n",
       "4        23.15   27.2000  426.0  708.25       0.004772        0   \n",
       "5        23.10   27.2000  426.0  704.50       0.004757        0   \n",
       "\n",
       "   daytime=afternoon  daytime=evening  daytime=morning  daytime=night  \\\n",
       "1                  1                0                0              0   \n",
       "2                  1                0                0              0   \n",
       "3                  1                0                0              0   \n",
       "4                  1                0                0              0   \n",
       "5                  1                0                0              0   \n",
       "\n",
       "   Occupancy  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX = pd.get_dummies(df[[c for c in df.columns if c != class_name]], prefix_sep='=')\n",
    "dfY = df[class_name]\n",
    "df = pd.concat([dfX, dfY], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [col for col in df.columns if col != class_name]\n",
    "X = df[attributes].values\n",
    "y = df[class_name]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "hidden_layer_sizes tuple, length = n_layers - 2, default=(100,)\n",
    "The ith element represents the number of neurons in the ith hidden layer.\n",
    "\n",
    "activation {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
    "Activation function for the hidden layer.\n",
    "* 'identity', no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "* 'logistic', the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "* 'tanh', the hyperbolic tan function, returns f(x) = tanh(x).\n",
    "* 'relu', the rectified linear unit function, returns f(x) = max(0, x)\n",
    "\n",
    "solver {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
    "The solver for weight optimization.\n",
    "* 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
    "* 'sgd' refers to stochastic gradient descent.\n",
    "* 'adam' refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "The default solver 'adam' works pretty well on relatively large datasets (>= 1000 training samples) in terms of both training time and validation score. For small datasets, 'lbfgs' can converge faster and perform better.\n",
    "\n",
    "alpha float, default=0.0001\n",
    "L2 penalty (regularization term) parameter.\n",
    "\n",
    "batch_size int, default='auto'\n",
    "Size of minibatches for stochastic optimizers. If the solver is 'lbfgs', the classifier will not use minibatch. When set to “auto”, batch_size=min(200, n_samples)\n",
    "\n",
    "learning_rate {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
    "Learning rate schedule for weight updates.\n",
    "*'constant' is a constant learning rate given by 'learning_rate_init'.\n",
    "*'invscaling' gradually decreases the learning rate at each time step 't' using an inverse scaling exponent of *'power_t'. effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
    "*'adaptive' keeps the learning rate constant to 'learning_rate_init' as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if 'early_stopping' is on, the current learning rate is divided by 5.\n",
    "Only used when solver='sgd'.\n",
    "\n",
    "learning_rate_init double, default=0.001\n",
    "The initial learning rate used. It controls the step-size in updating the weights. Only used when solver='sgd' or 'adam'.\n",
    "\n",
    "power_t double, default=0.5\n",
    "The exponent for inverse scaling learning rate. It is used in updating effective learning rate when the learning_rate is set to 'invscaling'. Only used when solver='sgd'.\n",
    "\n",
    "max_iter int, default=200\n",
    "Maximum number of iterations. The solver iterates until convergence (determined by 'tol') or this number of iterations. For stochastic solvers ('sgd', 'adam'), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.\n",
    "\n",
    "shuffle bool, default=True\n",
    "Whether to shuffle samples in each iteration. Only used when solver='sgd' or 'adam'.\n",
    "\n",
    "random_state int, RandomState instance or None, default=None\n",
    "If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.\n",
    "\n",
    "tol float, default=1e-4\n",
    "Tolerance for the optimization. When the loss or score is not improving by at least tol for n_iter_no_change consecutive iterations, unless learning_rate is set to 'adaptive', convergence is considered to be reached and training stops.\n",
    "\n",
    "verbose bool, default=False\n",
    "Whether to print progress messages to stdout.\n",
    "\n",
    "warm_start bool, default=False\n",
    "When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.\n",
    "\n",
    "momentum float, default=0.9\n",
    "Momentum for gradient descent update. Should be between 0 and 1. Only used when solver='sgd'.\n",
    "\n",
    "early_stopping bool, default=False\n",
    "Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs. The split is stratified, except in a multilabel setting. Only effective when solver='sgd' or 'adam'\n",
    "\n",
    "validation_fraction float, default=0.1\n",
    "The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True\n",
    "\n",
    "beta_1 float, default=0.9\n",
    "Exponential decay rate for estimates of first moment vector in adam, should be in [0, 1). Only used when solver='adam'\n",
    "\n",
    "beta_2 float, default=0.999\n",
    "Exponential decay rate for estimates of second moment vector in adam, should be in [0, 1). Only used when solver='adam'\n",
    "\n",
    "epsilon float, default=1e-8\n",
    "Value for numerical stability in adam. Only used when solver='adam'\n",
    "\n",
    "n_iter_no_change int, default=10\n",
    "Maximum number of epochs to not meet tol improvement. Only effective when solver='sgd' or 'adam'\n",
    "\n",
    "\n",
    "### Attributes\n",
    "loss_ float\n",
    "The current loss computed with the loss function.\n",
    "\n",
    "coefs_ list, length n_layers - 1\n",
    "The ith element in the list represents the weight matrix corresponding to layer i.\n",
    "\n",
    "intercepts_ list, length n_layers - 1\n",
    "The ith element in the list represents the bias vector corresponding to layer i + 1.\n",
    "\n",
    "n_iter_ int,\n",
    "The number of iterations the solver has ran.\n",
    "\n",
    "n_layers_ int\n",
    "Number of layers.\n",
    "\n",
    "n_outputs_ int\n",
    "Number of outputs.\n",
    "\n",
    "out_activation_ string\n",
    "Name of the output activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9930413426115432\n",
      "F1-score [0.99557407 0.98373206]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      1924\n",
      "           1       0.98      0.99      0.98       519\n",
      "\n",
      "    accuracy                           0.99      2443\n",
      "   macro avg       0.99      0.99      0.99      2443\n",
      "weighted avg       0.99      0.99      0.99      2443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardo/opt/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.loss_curve_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9897666803110929\n",
      "F1-score [0.99350143 0.9759384 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1924\n",
      "           1       0.97      0.98      0.98       519\n",
      "\n",
      "    accuracy                           0.99      2443\n",
      "   macro avg       0.98      0.99      0.98      2443\n",
      "weighted avg       0.99      0.99      0.99      2443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(128, 64, 32,), alpha=0.1, learning_rate='adaptive', \n",
    "                    activation='tanh', early_stopping=False, momentum=0.9, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.loss_curve_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'solver': 'sgd', 'learning_rate': 'constant', 'momentum': 0,'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'constant', 'momentum': .9,\n",
    "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': 0,\n",
    "           'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': .9,\n",
    "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'adam', 'learning_rate_init': 0.01}]\n",
    "\n",
    "labels = [\"constant learning-rate\", \"constant with momentum\",\n",
    "          \"inv-scaling learning-rate\", \"inv-scaling with momentum\", \"adam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant learning-rate\n",
      "training set score and loss: 0.788, 0.749526\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant with momentum\n",
      "training set score and loss: 0.788, 24.231273\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv-scaling learning-rate\n",
      "training set score and loss: 0.788, 0.754787\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv-scaling with momentum\n",
      "training set score and loss: 0.788, 24.244236\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam\n",
      "training set score and loss: 0.989, 0.493000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, param in zip(labels, params):\n",
    "    print(label)\n",
    "    clf = MLPClassifier(random_state=0, max_iter=200, **param)\n",
    "\n",
    "    # some parameter combinations will not converge as can be seen on the\n",
    "    # plots so they are ignored here\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "        clf.fit(X, y)\n",
    "\n",
    "    print(\"training set score and loss: %.3f, %f\" % (clf.score(X, y), clf.loss_))\n",
    "    plt.plot(clf.loss_curve_, label=label)\n",
    "    plt.legend(loc=\"upper center\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    n_feature = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=n_feature, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "570/570 [==============================] - 1s 596us/step - loss: 0.1571 - accuracy: 0.9573\n",
      "Epoch 2/50\n",
      "570/570 [==============================] - 0s 577us/step - loss: 0.0412 - accuracy: 0.9868\n",
      "Epoch 3/50\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0333 - accuracy: 0.9890\n",
      "Epoch 4/50\n",
      "570/570 [==============================] - 0s 604us/step - loss: 0.0340 - accuracy: 0.9889\n",
      "Epoch 5/50\n",
      "570/570 [==============================] - 0s 564us/step - loss: 0.0337 - accuracy: 0.9874\n",
      "Epoch 6/50\n",
      "570/570 [==============================] - 0s 582us/step - loss: 0.0296 - accuracy: 0.9898\n",
      "Epoch 7/50\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0293 - accuracy: 0.9883\n",
      "Epoch 8/50\n",
      "570/570 [==============================] - 0s 564us/step - loss: 0.0370 - accuracy: 0.9859\n",
      "Epoch 9/50\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0320 - accuracy: 0.9903\n",
      "Epoch 10/50\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0189 - accuracy: 0.9939\n",
      "Epoch 11/50\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0257 - accuracy: 0.9913\n",
      "Epoch 12/50\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0223 - accuracy: 0.9924\n",
      "Epoch 13/50\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0274 - accuracy: 0.9909\n",
      "Epoch 14/50\n",
      "570/570 [==============================] - 0s 567us/step - loss: 0.0212 - accuracy: 0.9930\n",
      "Epoch 15/50\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0254 - accuracy: 0.9920\n",
      "Epoch 16/50\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0216 - accuracy: 0.9933\n",
      "Epoch 17/50\n",
      "570/570 [==============================] - 0s 567us/step - loss: 0.0218 - accuracy: 0.9941\n",
      "Epoch 18/50\n",
      "570/570 [==============================] - 0s 571us/step - loss: 0.0213 - accuracy: 0.9926\n",
      "Epoch 19/50\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0251 - accuracy: 0.9906\n",
      "Epoch 20/50\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0206 - accuracy: 0.9927\n",
      "Epoch 21/50\n",
      "570/570 [==============================] - 0s 572us/step - loss: 0.0190 - accuracy: 0.9952\n",
      "Epoch 22/50\n",
      "570/570 [==============================] - 0s 562us/step - loss: 0.0173 - accuracy: 0.9946\n",
      "Epoch 23/50\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0220 - accuracy: 0.9921\n",
      "Epoch 24/50\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0220 - accuracy: 0.9931\n",
      "Epoch 25/50\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0216 - accuracy: 0.9936\n",
      "Epoch 26/50\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0208 - accuracy: 0.9943\n",
      "Epoch 27/50\n",
      "570/570 [==============================] - 0s 571us/step - loss: 0.0166 - accuracy: 0.9936\n",
      "Epoch 28/50\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0219 - accuracy: 0.9926\n",
      "Epoch 29/50\n",
      "570/570 [==============================] - 0s 574us/step - loss: 0.0220 - accuracy: 0.9925\n",
      "Epoch 30/50\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0233 - accuracy: 0.9926\n",
      "Epoch 31/50\n",
      "570/570 [==============================] - 0s 575us/step - loss: 0.0206 - accuracy: 0.9931\n",
      "Epoch 32/50\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0194 - accuracy: 0.9933\n",
      "Epoch 33/50\n",
      "570/570 [==============================] - 0s 624us/step - loss: 0.0224 - accuracy: 0.9928\n",
      "Epoch 34/50\n",
      "570/570 [==============================] - 0s 575us/step - loss: 0.0171 - accuracy: 0.9940\n",
      "Epoch 35/50\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0254 - accuracy: 0.9911\n",
      "Epoch 36/50\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0221 - accuracy: 0.9908\n",
      "Epoch 37/50\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0252 - accuracy: 0.9903\n",
      "Epoch 38/50\n",
      "570/570 [==============================] - 0s 572us/step - loss: 0.0259 - accuracy: 0.9903\n",
      "Epoch 39/50\n",
      "570/570 [==============================] - 0s 577us/step - loss: 0.0218 - accuracy: 0.9917\n",
      "Epoch 40/50\n",
      "570/570 [==============================] - 0s 574us/step - loss: 0.0267 - accuracy: 0.9915\n",
      "Epoch 41/50\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0193 - accuracy: 0.9939\n",
      "Epoch 42/50\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0182 - accuracy: 0.9941\n",
      "Epoch 43/50\n",
      "570/570 [==============================] - 0s 588us/step - loss: 0.0195 - accuracy: 0.9929\n",
      "Epoch 44/50\n",
      "570/570 [==============================] - 0s 582us/step - loss: 0.0235 - accuracy: 0.9929\n",
      "Epoch 45/50\n",
      "570/570 [==============================] - 0s 575us/step - loss: 0.0177 - accuracy: 0.9934\n",
      "Epoch 46/50\n",
      "570/570 [==============================] - 0s 622us/step - loss: 0.0174 - accuracy: 0.9947\n",
      "Epoch 47/50\n",
      "570/570 [==============================] - 0s 579us/step - loss: 0.0203 - accuracy: 0.9922\n",
      "Epoch 48/50\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0188 - accuracy: 0.9936\n",
      "Epoch 49/50\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0208 - accuracy: 0.9918\n",
      "Epoch 50/50\n",
      "570/570 [==============================] - 0s 567us/step - loss: 0.0230 - accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "model1 = build_model()\n",
    "\n",
    "history1 = model1.fit(X_train, y_train, epochs=50, batch_size=10).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "114/114 [==============================] - 0s 711us/step - loss: 0.2738 - accuracy: 0.9239\n",
      "Epoch 2/50\n",
      "114/114 [==============================] - 0s 629us/step - loss: 0.0475 - accuracy: 0.9880\n",
      "Epoch 3/50\n",
      "114/114 [==============================] - 0s 708us/step - loss: 0.0392 - accuracy: 0.9885\n",
      "Epoch 4/50\n",
      "114/114 [==============================] - 0s 647us/step - loss: 0.0421 - accuracy: 0.9855\n",
      "Epoch 5/50\n",
      "114/114 [==============================] - 0s 663us/step - loss: 0.0380 - accuracy: 0.9871\n",
      "Epoch 6/50\n",
      "114/114 [==============================] - 0s 663us/step - loss: 0.0401 - accuracy: 0.9852\n",
      "Epoch 7/50\n",
      "114/114 [==============================] - 0s 720us/step - loss: 0.0339 - accuracy: 0.9878\n",
      "Epoch 8/50\n",
      "114/114 [==============================] - 0s 685us/step - loss: 0.0279 - accuracy: 0.9892\n",
      "Epoch 9/50\n",
      "114/114 [==============================] - 0s 635us/step - loss: 0.0310 - accuracy: 0.9887\n",
      "Epoch 10/50\n",
      "114/114 [==============================] - 0s 748us/step - loss: 0.0282 - accuracy: 0.9892\n",
      "Epoch 11/50\n",
      "114/114 [==============================] - 0s 615us/step - loss: 0.0268 - accuracy: 0.9886\n",
      "Epoch 12/50\n",
      "114/114 [==============================] - 0s 691us/step - loss: 0.0294 - accuracy: 0.9887\n",
      "Epoch 13/50\n",
      "114/114 [==============================] - 0s 662us/step - loss: 0.0308 - accuracy: 0.9888\n",
      "Epoch 14/50\n",
      "114/114 [==============================] - 0s 714us/step - loss: 0.0264 - accuracy: 0.9902\n",
      "Epoch 15/50\n",
      "114/114 [==============================] - 0s 617us/step - loss: 0.0246 - accuracy: 0.9904\n",
      "Epoch 16/50\n",
      "114/114 [==============================] - 0s 666us/step - loss: 0.0228 - accuracy: 0.9919\n",
      "Epoch 17/50\n",
      "114/114 [==============================] - 0s 662us/step - loss: 0.0214 - accuracy: 0.9933\n",
      "Epoch 18/50\n",
      "114/114 [==============================] - 0s 638us/step - loss: 0.0271 - accuracy: 0.9905\n",
      "Epoch 19/50\n",
      "114/114 [==============================] - 0s 647us/step - loss: 0.0264 - accuracy: 0.9914\n",
      "Epoch 20/50\n",
      "114/114 [==============================] - 0s 665us/step - loss: 0.0283 - accuracy: 0.9895\n",
      "Epoch 21/50\n",
      "114/114 [==============================] - 0s 670us/step - loss: 0.0271 - accuracy: 0.9907\n",
      "Epoch 22/50\n",
      "114/114 [==============================] - 0s 632us/step - loss: 0.0191 - accuracy: 0.9931\n",
      "Epoch 23/50\n",
      "114/114 [==============================] - 0s 681us/step - loss: 0.0242 - accuracy: 0.9901\n",
      "Epoch 24/50\n",
      "114/114 [==============================] - 0s 647us/step - loss: 0.0229 - accuracy: 0.9914\n",
      "Epoch 25/50\n",
      "114/114 [==============================] - 0s 759us/step - loss: 0.0211 - accuracy: 0.9924\n",
      "Epoch 26/50\n",
      "114/114 [==============================] - 0s 658us/step - loss: 0.0172 - accuracy: 0.9953\n",
      "Epoch 27/50\n",
      "114/114 [==============================] - 0s 668us/step - loss: 0.0221 - accuracy: 0.9915\n",
      "Epoch 28/50\n",
      "114/114 [==============================] - 0s 645us/step - loss: 0.0208 - accuracy: 0.9920\n",
      "Epoch 29/50\n",
      "114/114 [==============================] - 0s 689us/step - loss: 0.0220 - accuracy: 0.9936\n",
      "Epoch 30/50\n",
      "114/114 [==============================] - 0s 635us/step - loss: 0.0188 - accuracy: 0.9948\n",
      "Epoch 31/50\n",
      "114/114 [==============================] - 0s 664us/step - loss: 0.0174 - accuracy: 0.9943\n",
      "Epoch 32/50\n",
      "114/114 [==============================] - 0s 654us/step - loss: 0.0197 - accuracy: 0.9928\n",
      "Epoch 33/50\n",
      "114/114 [==============================] - 0s 646us/step - loss: 0.0212 - accuracy: 0.9911\n",
      "Epoch 34/50\n",
      "114/114 [==============================] - 0s 663us/step - loss: 0.0247 - accuracy: 0.9915\n",
      "Epoch 35/50\n",
      "114/114 [==============================] - 0s 646us/step - loss: 0.0229 - accuracy: 0.9913\n",
      "Epoch 36/50\n",
      "114/114 [==============================] - 0s 650us/step - loss: 0.0176 - accuracy: 0.9935\n",
      "Epoch 37/50\n",
      "114/114 [==============================] - 0s 664us/step - loss: 0.0253 - accuracy: 0.9926\n",
      "Epoch 38/50\n",
      "114/114 [==============================] - 0s 635us/step - loss: 0.0215 - accuracy: 0.9922\n",
      "Epoch 39/50\n",
      "114/114 [==============================] - 0s 672us/step - loss: 0.0223 - accuracy: 0.9912\n",
      "Epoch 40/50\n",
      "114/114 [==============================] - 0s 678us/step - loss: 0.0185 - accuracy: 0.9939\n",
      "Epoch 41/50\n",
      "114/114 [==============================] - 0s 796us/step - loss: 0.0206 - accuracy: 0.9928\n",
      "Epoch 42/50\n",
      "114/114 [==============================] - 0s 797us/step - loss: 0.0173 - accuracy: 0.9944\n",
      "Epoch 43/50\n",
      "114/114 [==============================] - 0s 674us/step - loss: 0.0216 - accuracy: 0.9916\n",
      "Epoch 44/50\n",
      "114/114 [==============================] - 0s 699us/step - loss: 0.0168 - accuracy: 0.9935\n",
      "Epoch 45/50\n",
      "114/114 [==============================] - 0s 652us/step - loss: 0.0198 - accuracy: 0.9933\n",
      "Epoch 46/50\n",
      "114/114 [==============================] - 0s 855us/step - loss: 0.0208 - accuracy: 0.9941\n",
      "Epoch 47/50\n",
      "114/114 [==============================] - 0s 726us/step - loss: 0.0202 - accuracy: 0.9946\n",
      "Epoch 48/50\n",
      "114/114 [==============================] - 0s 677us/step - loss: 0.0177 - accuracy: 0.9945\n",
      "Epoch 49/50\n",
      "114/114 [==============================] - 0s 632us/step - loss: 0.0219 - accuracy: 0.9922\n",
      "Epoch 50/50\n",
      "114/114 [==============================] - 0s 701us/step - loss: 0.0221 - accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model()\n",
    "\n",
    "history2 = model2.fit(X_train, y_train, epochs=50, batch_size=50).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1['loss'], label='Loss 10')\n",
    "plt.plot(history2['loss'], label='Loss 50')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 528us/step - loss: 0.0199 - accuracy: 0.9935\n",
      "77/77 [==============================] - 0s 571us/step - loss: 0.0235 - accuracy: 0.9910\n",
      "Loss 0.019907, Accuracy 0.993451\n",
      "Loss 0.023489, Accuracy 0.990995\n"
     ]
    }
   ],
   "source": [
    "test_loss_1, test_acc_1 = model1.evaluate(X_test, y_test)\n",
    "test_loss_2, test_acc_2 = model2.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7920589439214081\n",
      "F1-score [0.88337925 0.04150943]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      1924\n",
      "           1       1.00      0.02      0.04       519\n",
      "\n",
      "    accuracy                           0.79      2443\n",
      "   macro avg       0.90      0.51      0.46      2443\n",
      "weighted avg       0.84      0.79      0.70      2443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(X_test).astype(int)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "570/570 [==============================] - 1s 2ms/step - loss: 0.1336 - accuracy: 0.9560 - val_loss: 0.0366 - val_accuracy: 0.9910\n",
      "Epoch 2/1000\n",
      "570/570 [==============================] - 0s 849us/step - loss: 0.0419 - accuracy: 0.9885 - val_loss: 0.0322 - val_accuracy: 0.9902\n",
      "Epoch 3/1000\n",
      "570/570 [==============================] - 0s 875us/step - loss: 0.0298 - accuracy: 0.9904 - val_loss: 0.0279 - val_accuracy: 0.9889\n",
      "Epoch 4/1000\n",
      "570/570 [==============================] - 0s 860us/step - loss: 0.0311 - accuracy: 0.9895 - val_loss: 0.0308 - val_accuracy: 0.9898\n",
      "Epoch 5/1000\n",
      "570/570 [==============================] - 0s 810us/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.0298 - val_accuracy: 0.9906\n",
      "Epoch 6/1000\n",
      "570/570 [==============================] - 0s 840us/step - loss: 0.0352 - accuracy: 0.9871 - val_loss: 0.0317 - val_accuracy: 0.9902\n",
      "Epoch 7/1000\n",
      "570/570 [==============================] - 0s 795us/step - loss: 0.0408 - accuracy: 0.9860 - val_loss: 0.0297 - val_accuracy: 0.9902\n",
      "Epoch 8/1000\n",
      "570/570 [==============================] - 0s 809us/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.0246 - val_accuracy: 0.9914\n",
      "Epoch 9/1000\n",
      "570/570 [==============================] - 1s 910us/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 0.0250 - val_accuracy: 0.9918\n",
      "Epoch 10/1000\n",
      "570/570 [==============================] - 0s 863us/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 0.0281 - val_accuracy: 0.9914\n",
      "Epoch 11/1000\n",
      "570/570 [==============================] - 0s 826us/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.0261 - val_accuracy: 0.9922\n",
      "Epoch 12/1000\n",
      "570/570 [==============================] - 0s 835us/step - loss: 0.0265 - accuracy: 0.9910 - val_loss: 0.0227 - val_accuracy: 0.9926\n",
      "Epoch 13/1000\n",
      "570/570 [==============================] - 0s 839us/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.0214 - val_accuracy: 0.9922\n",
      "Epoch 14/1000\n",
      "570/570 [==============================] - 1s 907us/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 0.0217 - val_accuracy: 0.9914\n",
      "Epoch 15/1000\n",
      "570/570 [==============================] - 0s 869us/step - loss: 0.0255 - accuracy: 0.9934 - val_loss: 0.0280 - val_accuracy: 0.9894\n",
      "Epoch 16/1000\n",
      "570/570 [==============================] - 0s 795us/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0233 - val_accuracy: 0.9918\n",
      "Epoch 17/1000\n",
      "570/570 [==============================] - 0s 794us/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.0243 - val_accuracy: 0.9910\n",
      "Epoch 18/1000\n",
      "570/570 [==============================] - 0s 835us/step - loss: 0.0291 - accuracy: 0.9897 - val_loss: 0.0209 - val_accuracy: 0.9922\n",
      "Epoch 19/1000\n",
      "570/570 [==============================] - 0s 810us/step - loss: 0.0221 - accuracy: 0.9908 - val_loss: 0.0330 - val_accuracy: 0.9885\n",
      "Epoch 20/1000\n",
      "570/570 [==============================] - 0s 774us/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0290 - val_accuracy: 0.9885\n",
      "Epoch 21/1000\n",
      "570/570 [==============================] - 0s 835us/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.0304 - val_accuracy: 0.9881\n",
      "Epoch 22/1000\n",
      "570/570 [==============================] - 0s 863us/step - loss: 0.0308 - accuracy: 0.9901 - val_loss: 0.0222 - val_accuracy: 0.9918\n",
      "Epoch 23/1000\n",
      "570/570 [==============================] - 0s 848us/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.0233 - val_accuracy: 0.9918\n",
      "Epoch 24/1000\n",
      "570/570 [==============================] - 0s 810us/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.0259 - val_accuracy: 0.9889\n",
      "Epoch 25/1000\n",
      "570/570 [==============================] - 0s 859us/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.0228 - val_accuracy: 0.9906\n",
      "Epoch 26/1000\n",
      "570/570 [==============================] - 0s 849us/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0210 - val_accuracy: 0.9918\n",
      "Epoch 27/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.0201 - val_accuracy: 0.9922\n",
      "Epoch 28/1000\n",
      "570/570 [==============================] - 0s 799us/step - loss: 0.0236 - accuracy: 0.9905 - val_loss: 0.0204 - val_accuracy: 0.9926\n",
      "Epoch 29/1000\n",
      "570/570 [==============================] - 0s 799us/step - loss: 0.0229 - accuracy: 0.9917 - val_loss: 0.0231 - val_accuracy: 0.9918\n",
      "Epoch 30/1000\n",
      "570/570 [==============================] - 0s 788us/step - loss: 0.0242 - accuracy: 0.9910 - val_loss: 0.0217 - val_accuracy: 0.9930\n",
      "Epoch 31/1000\n",
      "570/570 [==============================] - 0s 850us/step - loss: 0.0249 - accuracy: 0.9901 - val_loss: 0.0221 - val_accuracy: 0.9918\n",
      "Epoch 32/1000\n",
      "570/570 [==============================] - 0s 790us/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.0230 - val_accuracy: 0.9922\n",
      "Epoch 33/1000\n",
      "570/570 [==============================] - 0s 799us/step - loss: 0.0232 - accuracy: 0.9919 - val_loss: 0.0206 - val_accuracy: 0.9918\n",
      "Epoch 34/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0205 - accuracy: 0.9926 - val_loss: 0.0215 - val_accuracy: 0.9910\n",
      "Epoch 35/1000\n",
      "570/570 [==============================] - 0s 795us/step - loss: 0.0212 - accuracy: 0.9918 - val_loss: 0.0209 - val_accuracy: 0.9914\n",
      "Epoch 36/1000\n",
      "570/570 [==============================] - 0s 820us/step - loss: 0.0231 - accuracy: 0.9919 - val_loss: 0.0201 - val_accuracy: 0.9930\n",
      "Epoch 37/1000\n",
      "570/570 [==============================] - 0s 805us/step - loss: 0.0206 - accuracy: 0.9915 - val_loss: 0.0226 - val_accuracy: 0.9902\n",
      "Epoch 38/1000\n",
      "570/570 [==============================] - 0s 794us/step - loss: 0.0225 - accuracy: 0.9906 - val_loss: 0.0210 - val_accuracy: 0.9898\n",
      "Epoch 39/1000\n",
      "570/570 [==============================] - 0s 777us/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.0215 - val_accuracy: 0.9939\n",
      "Epoch 40/1000\n",
      "570/570 [==============================] - 0s 783us/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.0230 - val_accuracy: 0.9922\n",
      "Epoch 41/1000\n",
      "570/570 [==============================] - 0s 781us/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.0207 - val_accuracy: 0.9918\n",
      "Epoch 42/1000\n",
      "570/570 [==============================] - 0s 785us/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0217 - val_accuracy: 0.9914\n",
      "Epoch 43/1000\n",
      "570/570 [==============================] - 0s 823us/step - loss: 0.0222 - accuracy: 0.9918 - val_loss: 0.0222 - val_accuracy: 0.9914\n",
      "Epoch 44/1000\n",
      "570/570 [==============================] - 0s 850us/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.0202 - val_accuracy: 0.9914\n",
      "Epoch 45/1000\n",
      "570/570 [==============================] - 0s 837us/step - loss: 0.0215 - accuracy: 0.9917 - val_loss: 0.0230 - val_accuracy: 0.9914\n",
      "Epoch 46/1000\n",
      "570/570 [==============================] - 1s 1ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0193 - val_accuracy: 0.9914\n",
      "Epoch 47/1000\n",
      "570/570 [==============================] - 1s 1ms/step - loss: 0.0269 - accuracy: 0.9916 - val_loss: 0.0181 - val_accuracy: 0.9935\n",
      "Epoch 48/1000\n",
      "570/570 [==============================] - 0s 857us/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.0182 - val_accuracy: 0.9926\n",
      "Epoch 49/1000\n",
      "570/570 [==============================] - 0s 812us/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 0.0238 - val_accuracy: 0.9922\n",
      "Epoch 50/1000\n",
      "570/570 [==============================] - 0s 857us/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.0228 - val_accuracy: 0.9914\n",
      "Epoch 51/1000\n",
      "570/570 [==============================] - 0s 801us/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.0247 - val_accuracy: 0.9918\n",
      "Epoch 52/1000\n",
      "570/570 [==============================] - 0s 789us/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.0219 - val_accuracy: 0.9922\n",
      "Epoch 53/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.0211 - val_accuracy: 0.9926\n",
      "Epoch 54/1000\n",
      "570/570 [==============================] - 0s 791us/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.0238 - val_accuracy: 0.9914\n",
      "Epoch 55/1000\n",
      "570/570 [==============================] - 0s 819us/step - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.0183 - val_accuracy: 0.9926\n",
      "Epoch 56/1000\n",
      "570/570 [==============================] - 0s 820us/step - loss: 0.0220 - accuracy: 0.9920 - val_loss: 0.0218 - val_accuracy: 0.9926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "570/570 [==============================] - 1s 878us/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 0.0199 - val_accuracy: 0.9922\n",
      "Epoch 58/1000\n",
      "570/570 [==============================] - 0s 803us/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.0248 - val_accuracy: 0.9914\n",
      "Epoch 59/1000\n",
      "570/570 [==============================] - 0s 764us/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0235 - val_accuracy: 0.9902\n",
      "Epoch 60/1000\n",
      "570/570 [==============================] - 0s 809us/step - loss: 0.0192 - accuracy: 0.9923 - val_loss: 0.0201 - val_accuracy: 0.9922\n",
      "Epoch 61/1000\n",
      "570/570 [==============================] - 0s 817us/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0264 - val_accuracy: 0.9910\n",
      "Epoch 62/1000\n",
      "570/570 [==============================] - 0s 797us/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 0.0223 - val_accuracy: 0.9918\n",
      "Epoch 63/1000\n",
      "570/570 [==============================] - 0s 843us/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0193 - val_accuracy: 0.9922\n",
      "Epoch 64/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0218 - val_accuracy: 0.9914\n",
      "Epoch 65/1000\n",
      "570/570 [==============================] - 0s 811us/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0185 - val_accuracy: 0.9930\n",
      "Epoch 66/1000\n",
      "570/570 [==============================] - 0s 821us/step - loss: 0.0189 - accuracy: 0.9930 - val_loss: 0.0201 - val_accuracy: 0.9930\n",
      "Epoch 67/1000\n",
      "570/570 [==============================] - 0s 775us/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 0.0213 - val_accuracy: 0.9914\n",
      "Epoch 68/1000\n",
      "570/570 [==============================] - 0s 787us/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.0181 - val_accuracy: 0.9922\n",
      "Epoch 69/1000\n",
      "570/570 [==============================] - 0s 789us/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0196 - val_accuracy: 0.9918\n",
      "Epoch 70/1000\n",
      "570/570 [==============================] - 0s 820us/step - loss: 0.0191 - accuracy: 0.9930 - val_loss: 0.0196 - val_accuracy: 0.9918\n",
      "Epoch 71/1000\n",
      "570/570 [==============================] - 0s 800us/step - loss: 0.0204 - accuracy: 0.9905 - val_loss: 0.0180 - val_accuracy: 0.9918\n",
      "Epoch 72/1000\n",
      "570/570 [==============================] - 0s 778us/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.0191 - val_accuracy: 0.9922\n",
      "Epoch 73/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.0253 - val_accuracy: 0.9918\n",
      "Epoch 74/1000\n",
      "570/570 [==============================] - 0s 775us/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0241 - val_accuracy: 0.9894\n",
      "Epoch 75/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.0237 - val_accuracy: 0.9914\n",
      "Epoch 76/1000\n",
      "570/570 [==============================] - 0s 779us/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.0221 - val_accuracy: 0.9910\n",
      "Epoch 77/1000\n",
      "570/570 [==============================] - 0s 799us/step - loss: 0.0171 - accuracy: 0.9932 - val_loss: 0.0223 - val_accuracy: 0.9930\n",
      "Epoch 78/1000\n",
      "570/570 [==============================] - 0s 837us/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0228 - val_accuracy: 0.9910\n",
      "Epoch 79/1000\n",
      "570/570 [==============================] - 0s 781us/step - loss: 0.0215 - accuracy: 0.9918 - val_loss: 0.0220 - val_accuracy: 0.9914\n",
      "Epoch 80/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.0191 - val_accuracy: 0.9922\n",
      "Epoch 81/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 0.0193 - val_accuracy: 0.9930\n",
      "Epoch 82/1000\n",
      "570/570 [==============================] - 0s 806us/step - loss: 0.0132 - accuracy: 0.9950 - val_loss: 0.0279 - val_accuracy: 0.9894\n",
      "Epoch 83/1000\n",
      "570/570 [==============================] - 0s 864us/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.0246 - val_accuracy: 0.9918\n",
      "Epoch 84/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0219 - val_accuracy: 0.9914\n",
      "Epoch 85/1000\n",
      "570/570 [==============================] - 0s 798us/step - loss: 0.0137 - accuracy: 0.9950 - val_loss: 0.0257 - val_accuracy: 0.9918\n",
      "Epoch 86/1000\n",
      "570/570 [==============================] - 0s 799us/step - loss: 0.0164 - accuracy: 0.9941 - val_loss: 0.0244 - val_accuracy: 0.9918\n",
      "Epoch 87/1000\n",
      "570/570 [==============================] - 0s 869us/step - loss: 0.0191 - accuracy: 0.9927 - val_loss: 0.0215 - val_accuracy: 0.9914\n",
      "Epoch 88/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.0207 - val_accuracy: 0.9930\n",
      "Epoch 89/1000\n",
      "570/570 [==============================] - 1s 882us/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.0216 - val_accuracy: 0.9922\n",
      "Epoch 90/1000\n",
      "570/570 [==============================] - 0s 813us/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.0229 - val_accuracy: 0.9918\n",
      "Epoch 91/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0191 - accuracy: 0.9927 - val_loss: 0.0205 - val_accuracy: 0.9935\n",
      "Epoch 92/1000\n",
      "570/570 [==============================] - 0s 782us/step - loss: 0.0182 - accuracy: 0.9930 - val_loss: 0.0201 - val_accuracy: 0.9926\n",
      "Epoch 93/1000\n",
      "570/570 [==============================] - 0s 786us/step - loss: 0.0198 - accuracy: 0.9917 - val_loss: 0.0218 - val_accuracy: 0.9914\n",
      "Epoch 94/1000\n",
      "570/570 [==============================] - 0s 842us/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0192 - val_accuracy: 0.9918\n",
      "Epoch 95/1000\n",
      "570/570 [==============================] - 0s 774us/step - loss: 0.0164 - accuracy: 0.9933 - val_loss: 0.0203 - val_accuracy: 0.9922\n",
      "Epoch 96/1000\n",
      "570/570 [==============================] - 0s 805us/step - loss: 0.0166 - accuracy: 0.9932 - val_loss: 0.0201 - val_accuracy: 0.9918\n",
      "Epoch 97/1000\n",
      "570/570 [==============================] - 0s 795us/step - loss: 0.0169 - accuracy: 0.9932 - val_loss: 0.0213 - val_accuracy: 0.9922\n",
      "Epoch 98/1000\n",
      "570/570 [==============================] - 0s 800us/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.0214 - val_accuracy: 0.9926\n",
      "Epoch 99/1000\n",
      "570/570 [==============================] - 0s 778us/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0198 - val_accuracy: 0.9930\n",
      "Epoch 100/1000\n",
      "570/570 [==============================] - 0s 790us/step - loss: 0.0160 - accuracy: 0.9936 - val_loss: 0.0202 - val_accuracy: 0.9926\n",
      "Epoch 101/1000\n",
      "570/570 [==============================] - 0s 787us/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 0.0202 - val_accuracy: 0.9910\n",
      "Epoch 102/1000\n",
      "570/570 [==============================] - 0s 789us/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0203 - val_accuracy: 0.9918\n",
      "Epoch 103/1000\n",
      "570/570 [==============================] - 0s 870us/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.0223 - val_accuracy: 0.9914\n",
      "Epoch 104/1000\n",
      "570/570 [==============================] - 0s 852us/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.0233 - val_accuracy: 0.9898\n",
      "Epoch 105/1000\n",
      "570/570 [==============================] - 0s 869us/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0200 - val_accuracy: 0.9906\n",
      "Epoch 106/1000\n",
      "570/570 [==============================] - 0s 816us/step - loss: 0.0169 - accuracy: 0.9924 - val_loss: 0.0226 - val_accuracy: 0.9922\n",
      "Epoch 107/1000\n",
      "570/570 [==============================] - 0s 825us/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.0247 - val_accuracy: 0.9918\n",
      "Epoch 108/1000\n",
      "570/570 [==============================] - 0s 807us/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.0221 - val_accuracy: 0.9906\n",
      "Epoch 109/1000\n",
      "570/570 [==============================] - 1s 897us/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0193 - val_accuracy: 0.9922\n",
      "Epoch 110/1000\n",
      "570/570 [==============================] - 0s 818us/step - loss: 0.0202 - accuracy: 0.9915 - val_loss: 0.0191 - val_accuracy: 0.9922\n",
      "Epoch 111/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 0.0221 - val_accuracy: 0.9922\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 799us/step - loss: 0.0174 - accuracy: 0.9935 - val_loss: 0.0217 - val_accuracy: 0.9906\n",
      "Epoch 113/1000\n",
      "570/570 [==============================] - 0s 809us/step - loss: 0.0163 - accuracy: 0.9929 - val_loss: 0.0199 - val_accuracy: 0.9918\n",
      "Epoch 114/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.0254 - val_accuracy: 0.9910\n",
      "Epoch 115/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0186 - accuracy: 0.9924 - val_loss: 0.0204 - val_accuracy: 0.9918\n",
      "Epoch 116/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0170 - accuracy: 0.9935 - val_loss: 0.0219 - val_accuracy: 0.9926\n",
      "Epoch 117/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0233 - val_accuracy: 0.9914\n",
      "Epoch 118/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0227 - val_accuracy: 0.9922\n",
      "Epoch 119/1000\n",
      "570/570 [==============================] - 0s 786us/step - loss: 0.0169 - accuracy: 0.9934 - val_loss: 0.0235 - val_accuracy: 0.9914\n",
      "Epoch 120/1000\n",
      "570/570 [==============================] - 0s 781us/step - loss: 0.0179 - accuracy: 0.9929 - val_loss: 0.0246 - val_accuracy: 0.9894\n",
      "Epoch 121/1000\n",
      "570/570 [==============================] - 0s 800us/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0200 - val_accuracy: 0.9918\n",
      "Epoch 122/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0185 - accuracy: 0.9934 - val_loss: 0.0219 - val_accuracy: 0.9914\n",
      "Epoch 123/1000\n",
      "570/570 [==============================] - 0s 826us/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0186 - val_accuracy: 0.9926\n",
      "Epoch 124/1000\n",
      "570/570 [==============================] - 0s 841us/step - loss: 0.0182 - accuracy: 0.9930 - val_loss: 0.0249 - val_accuracy: 0.9898\n",
      "Epoch 125/1000\n",
      "570/570 [==============================] - 0s 784us/step - loss: 0.0185 - accuracy: 0.9925 - val_loss: 0.0194 - val_accuracy: 0.9926\n",
      "Epoch 126/1000\n",
      "570/570 [==============================] - 0s 814us/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.0221 - val_accuracy: 0.9918\n",
      "Epoch 127/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0215 - val_accuracy: 0.9918\n",
      "Epoch 128/1000\n",
      "570/570 [==============================] - 0s 812us/step - loss: 0.0166 - accuracy: 0.9928 - val_loss: 0.0235 - val_accuracy: 0.9922\n",
      "Epoch 129/1000\n",
      "570/570 [==============================] - 0s 803us/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.0193 - val_accuracy: 0.9922\n",
      "Epoch 130/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.0206 - val_accuracy: 0.9918\n",
      "Epoch 131/1000\n",
      "570/570 [==============================] - 0s 831us/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.0191 - val_accuracy: 0.9922\n",
      "Epoch 132/1000\n",
      "570/570 [==============================] - 0s 842us/step - loss: 0.0123 - accuracy: 0.9952 - val_loss: 0.0231 - val_accuracy: 0.9918\n",
      "Epoch 133/1000\n",
      "570/570 [==============================] - 0s 816us/step - loss: 0.0150 - accuracy: 0.9938 - val_loss: 0.0223 - val_accuracy: 0.9918\n",
      "Epoch 134/1000\n",
      "570/570 [==============================] - 0s 842us/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.0204 - val_accuracy: 0.9926\n",
      "Epoch 135/1000\n",
      "570/570 [==============================] - 0s 816us/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.0311 - val_accuracy: 0.9930\n",
      "Epoch 136/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.0189 - val_accuracy: 0.9939\n",
      "Epoch 137/1000\n",
      "570/570 [==============================] - 0s 794us/step - loss: 0.0144 - accuracy: 0.9944 - val_loss: 0.0225 - val_accuracy: 0.9922\n",
      "Epoch 138/1000\n",
      "570/570 [==============================] - 0s 818us/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.0244 - val_accuracy: 0.9926\n",
      "Epoch 139/1000\n",
      "570/570 [==============================] - 1s 897us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0255 - val_accuracy: 0.9902\n",
      "Epoch 140/1000\n",
      "570/570 [==============================] - 0s 811us/step - loss: 0.0155 - accuracy: 0.9936 - val_loss: 0.0205 - val_accuracy: 0.9914\n",
      "Epoch 141/1000\n",
      "570/570 [==============================] - 0s 864us/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.0254 - val_accuracy: 0.9918\n",
      "Epoch 142/1000\n",
      "570/570 [==============================] - 0s 846us/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0240 - val_accuracy: 0.9922\n",
      "Epoch 143/1000\n",
      "570/570 [==============================] - 0s 833us/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0206 - val_accuracy: 0.9902\n",
      "Epoch 144/1000\n",
      "570/570 [==============================] - 0s 786us/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.0197 - val_accuracy: 0.9910\n",
      "Epoch 145/1000\n",
      "570/570 [==============================] - 0s 847us/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0188 - val_accuracy: 0.9918\n",
      "Epoch 146/1000\n",
      "570/570 [==============================] - 1s 938us/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.0197 - val_accuracy: 0.9922\n",
      "Epoch 147/1000\n",
      "570/570 [==============================] - 0s 846us/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.0202 - val_accuracy: 0.9930\n",
      "Epoch 148/1000\n",
      "570/570 [==============================] - 0s 779us/step - loss: 0.0160 - accuracy: 0.9916 - val_loss: 0.0221 - val_accuracy: 0.9918\n",
      "Epoch 149/1000\n",
      "570/570 [==============================] - 0s 787us/step - loss: 0.0159 - accuracy: 0.9938 - val_loss: 0.0187 - val_accuracy: 0.9926\n",
      "Epoch 150/1000\n",
      "570/570 [==============================] - 0s 778us/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.0207 - val_accuracy: 0.9922\n",
      "Epoch 151/1000\n",
      "570/570 [==============================] - 0s 864us/step - loss: 0.0177 - accuracy: 0.9922 - val_loss: 0.0271 - val_accuracy: 0.9894\n",
      "Epoch 152/1000\n",
      "570/570 [==============================] - 0s 875us/step - loss: 0.0167 - accuracy: 0.9923 - val_loss: 0.0179 - val_accuracy: 0.9926\n",
      "Epoch 153/1000\n",
      "570/570 [==============================] - 0s 868us/step - loss: 0.0128 - accuracy: 0.9967 - val_loss: 0.0233 - val_accuracy: 0.9910\n",
      "Epoch 154/1000\n",
      "570/570 [==============================] - 0s 867us/step - loss: 0.0154 - accuracy: 0.9940 - val_loss: 0.0212 - val_accuracy: 0.9922\n",
      "Epoch 155/1000\n",
      "570/570 [==============================] - 0s 824us/step - loss: 0.0158 - accuracy: 0.9934 - val_loss: 0.0257 - val_accuracy: 0.9902\n",
      "Epoch 156/1000\n",
      "570/570 [==============================] - 0s 785us/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 0.0190 - val_accuracy: 0.9922\n",
      "Epoch 157/1000\n",
      "570/570 [==============================] - 0s 775us/step - loss: 0.0136 - accuracy: 0.9948 - val_loss: 0.0182 - val_accuracy: 0.9935\n",
      "Epoch 158/1000\n",
      "570/570 [==============================] - 0s 805us/step - loss: 0.0161 - accuracy: 0.9936 - val_loss: 0.0186 - val_accuracy: 0.9935\n",
      "Epoch 159/1000\n",
      "570/570 [==============================] - 0s 877us/step - loss: 0.0135 - accuracy: 0.9942 - val_loss: 0.0201 - val_accuracy: 0.9922\n",
      "Epoch 160/1000\n",
      "570/570 [==============================] - 1s 880us/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.0235 - val_accuracy: 0.9898\n",
      "Epoch 161/1000\n",
      "570/570 [==============================] - 1s 881us/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.0195 - val_accuracy: 0.9935\n",
      "Epoch 162/1000\n",
      "570/570 [==============================] - 0s 876us/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0210 - val_accuracy: 0.9930\n",
      "Epoch 163/1000\n",
      "570/570 [==============================] - 0s 859us/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.0268 - val_accuracy: 0.9922\n",
      "Epoch 164/1000\n",
      "570/570 [==============================] - 1s 890us/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0223 - val_accuracy: 0.9910\n",
      "Epoch 165/1000\n",
      "570/570 [==============================] - 1s 898us/step - loss: 0.0131 - accuracy: 0.9944 - val_loss: 0.0178 - val_accuracy: 0.9914\n",
      "Epoch 166/1000\n",
      "570/570 [==============================] - 1s 885us/step - loss: 0.0145 - accuracy: 0.9946 - val_loss: 0.0222 - val_accuracy: 0.9910\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 874us/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.0222 - val_accuracy: 0.9914\n",
      "Epoch 168/1000\n",
      "570/570 [==============================] - 0s 866us/step - loss: 0.0165 - accuracy: 0.9938 - val_loss: 0.0200 - val_accuracy: 0.9922\n",
      "Epoch 169/1000\n",
      "570/570 [==============================] - 0s 875us/step - loss: 0.0164 - accuracy: 0.9936 - val_loss: 0.0200 - val_accuracy: 0.9914\n",
      "Epoch 170/1000\n",
      "570/570 [==============================] - 1s 947us/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.0201 - val_accuracy: 0.9914\n",
      "Epoch 171/1000\n",
      "570/570 [==============================] - 0s 797us/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.0186 - val_accuracy: 0.9906\n",
      "Epoch 172/1000\n",
      "570/570 [==============================] - 0s 834us/step - loss: 0.0156 - accuracy: 0.9926 - val_loss: 0.0201 - val_accuracy: 0.9906\n",
      "Epoch 173/1000\n",
      "570/570 [==============================] - 0s 824us/step - loss: 0.0152 - accuracy: 0.9943 - val_loss: 0.0197 - val_accuracy: 0.9914\n",
      "Epoch 174/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0186 - accuracy: 0.9926 - val_loss: 0.0231 - val_accuracy: 0.9918\n",
      "Epoch 175/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0192 - val_accuracy: 0.9922\n",
      "Epoch 176/1000\n",
      "570/570 [==============================] - 0s 846us/step - loss: 0.0138 - accuracy: 0.9941 - val_loss: 0.0228 - val_accuracy: 0.9910\n",
      "Epoch 177/1000\n",
      "570/570 [==============================] - 0s 829us/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.0180 - val_accuracy: 0.9926\n",
      "Epoch 178/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.0188 - val_accuracy: 0.9922\n",
      "Epoch 179/1000\n",
      "570/570 [==============================] - 0s 795us/step - loss: 0.0166 - accuracy: 0.9940 - val_loss: 0.0215 - val_accuracy: 0.9918\n",
      "Epoch 180/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0130 - accuracy: 0.9950 - val_loss: 0.0215 - val_accuracy: 0.9898\n",
      "Epoch 181/1000\n",
      "570/570 [==============================] - 0s 800us/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.0228 - val_accuracy: 0.9918\n",
      "Epoch 182/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0148 - accuracy: 0.9939 - val_loss: 0.0228 - val_accuracy: 0.9922\n",
      "Epoch 183/1000\n",
      "570/570 [==============================] - 0s 812us/step - loss: 0.0130 - accuracy: 0.9950 - val_loss: 0.0193 - val_accuracy: 0.9922\n",
      "Epoch 184/1000\n",
      "570/570 [==============================] - 0s 830us/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 0.0183 - val_accuracy: 0.9926\n",
      "Epoch 185/1000\n",
      "570/570 [==============================] - 0s 763us/step - loss: 0.0201 - accuracy: 0.9922 - val_loss: 0.0195 - val_accuracy: 0.9930\n",
      "Epoch 186/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.0235 - val_accuracy: 0.9914\n",
      "Epoch 187/1000\n",
      "570/570 [==============================] - 1s 932us/step - loss: 0.0135 - accuracy: 0.9940 - val_loss: 0.0187 - val_accuracy: 0.9914\n",
      "Epoch 188/1000\n",
      "570/570 [==============================] - 0s 800us/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.0194 - val_accuracy: 0.9930\n",
      "Epoch 189/1000\n",
      "570/570 [==============================] - 0s 818us/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.0206 - val_accuracy: 0.9926\n",
      "Epoch 190/1000\n",
      "570/570 [==============================] - 0s 847us/step - loss: 0.0159 - accuracy: 0.9941 - val_loss: 0.0218 - val_accuracy: 0.9922\n",
      "Epoch 191/1000\n",
      "570/570 [==============================] - 0s 815us/step - loss: 0.0182 - accuracy: 0.9931 - val_loss: 0.0211 - val_accuracy: 0.9922\n",
      "Epoch 192/1000\n",
      "570/570 [==============================] - 0s 834us/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0196 - val_accuracy: 0.9918\n",
      "Epoch 193/1000\n",
      "570/570 [==============================] - 0s 849us/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0232 - val_accuracy: 0.9922\n",
      "Epoch 194/1000\n",
      "570/570 [==============================] - 0s 847us/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0203 - val_accuracy: 0.9926\n",
      "Epoch 195/1000\n",
      "570/570 [==============================] - 0s 847us/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.0293 - val_accuracy: 0.9902\n",
      "Epoch 196/1000\n",
      "570/570 [==============================] - 0s 823us/step - loss: 0.0131 - accuracy: 0.9941 - val_loss: 0.0206 - val_accuracy: 0.9930\n",
      "Epoch 197/1000\n",
      "570/570 [==============================] - 0s 848us/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0209 - val_accuracy: 0.9918\n",
      "Epoch 198/1000\n",
      "570/570 [==============================] - 1s 881us/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.0222 - val_accuracy: 0.9922\n",
      "Epoch 199/1000\n",
      "570/570 [==============================] - 1s 914us/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.0225 - val_accuracy: 0.9918\n",
      "Epoch 200/1000\n",
      "570/570 [==============================] - 1s 932us/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.0201 - val_accuracy: 0.9926\n",
      "Epoch 201/1000\n",
      "570/570 [==============================] - 0s 815us/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.0207 - val_accuracy: 0.9906\n",
      "Epoch 202/1000\n",
      "570/570 [==============================] - 0s 844us/step - loss: 0.0122 - accuracy: 0.9943 - val_loss: 0.0234 - val_accuracy: 0.9926\n",
      "Epoch 203/1000\n",
      "570/570 [==============================] - 1s 907us/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.0207 - val_accuracy: 0.9910\n",
      "Epoch 204/1000\n",
      "570/570 [==============================] - 0s 837us/step - loss: 0.0157 - accuracy: 0.9929 - val_loss: 0.0193 - val_accuracy: 0.9930\n",
      "Epoch 205/1000\n",
      "570/570 [==============================] - 0s 807us/step - loss: 0.0110 - accuracy: 0.9951 - val_loss: 0.0233 - val_accuracy: 0.9918\n",
      "Epoch 206/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0179 - val_accuracy: 0.9922\n",
      "Epoch 207/1000\n",
      "570/570 [==============================] - 0s 791us/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.0206 - val_accuracy: 0.9926\n",
      "Epoch 208/1000\n",
      "570/570 [==============================] - 0s 785us/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 0.0197 - val_accuracy: 0.9922\n",
      "Epoch 209/1000\n",
      "570/570 [==============================] - 0s 809us/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.0223 - val_accuracy: 0.9918\n",
      "Epoch 210/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0201 - val_accuracy: 0.9926\n",
      "Epoch 211/1000\n",
      "570/570 [==============================] - 0s 858us/step - loss: 0.0143 - accuracy: 0.9944 - val_loss: 0.0247 - val_accuracy: 0.9889\n",
      "Epoch 212/1000\n",
      "570/570 [==============================] - 1s 940us/step - loss: 0.0158 - accuracy: 0.9941 - val_loss: 0.0216 - val_accuracy: 0.9918\n",
      "Epoch 213/1000\n",
      "570/570 [==============================] - 0s 870us/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.0188 - val_accuracy: 0.9939\n",
      "Epoch 214/1000\n",
      "570/570 [==============================] - 0s 869us/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.0207 - val_accuracy: 0.9922\n",
      "Epoch 215/1000\n",
      "570/570 [==============================] - 0s 855us/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.0211 - val_accuracy: 0.9930\n",
      "Epoch 216/1000\n",
      "570/570 [==============================] - 0s 813us/step - loss: 0.0128 - accuracy: 0.9950 - val_loss: 0.0203 - val_accuracy: 0.9918\n",
      "Epoch 217/1000\n",
      "570/570 [==============================] - 0s 798us/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0359 - val_accuracy: 0.9914\n",
      "Epoch 218/1000\n",
      "570/570 [==============================] - 1s 910us/step - loss: 0.0182 - accuracy: 0.9935 - val_loss: 0.0222 - val_accuracy: 0.9918\n",
      "Epoch 219/1000\n",
      "570/570 [==============================] - 1s 947us/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.0224 - val_accuracy: 0.9918\n",
      "Epoch 220/1000\n",
      "570/570 [==============================] - 1s 921us/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.0219 - val_accuracy: 0.9918\n",
      "Epoch 221/1000\n",
      "570/570 [==============================] - 0s 858us/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0227 - val_accuracy: 0.9930\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 795us/step - loss: 0.0127 - accuracy: 0.9942 - val_loss: 0.0214 - val_accuracy: 0.9939\n",
      "Epoch 223/1000\n",
      "570/570 [==============================] - 0s 856us/step - loss: 0.0200 - accuracy: 0.9915 - val_loss: 0.0250 - val_accuracy: 0.9898\n",
      "Epoch 224/1000\n",
      "570/570 [==============================] - 0s 833us/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.0217 - val_accuracy: 0.9926\n",
      "Epoch 225/1000\n",
      "570/570 [==============================] - 0s 786us/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.0223 - val_accuracy: 0.9914\n",
      "Epoch 226/1000\n",
      "570/570 [==============================] - 0s 790us/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0237 - val_accuracy: 0.9922\n",
      "Epoch 227/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0150 - accuracy: 0.9943 - val_loss: 0.0209 - val_accuracy: 0.9926\n",
      "Epoch 228/1000\n",
      "570/570 [==============================] - 0s 787us/step - loss: 0.0135 - accuracy: 0.9948 - val_loss: 0.0208 - val_accuracy: 0.9918\n",
      "Epoch 229/1000\n",
      "570/570 [==============================] - 0s 785us/step - loss: 0.0144 - accuracy: 0.9948 - val_loss: 0.0193 - val_accuracy: 0.9926\n",
      "Epoch 230/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0223 - val_accuracy: 0.9910\n",
      "Epoch 231/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0217 - val_accuracy: 0.9918\n",
      "Epoch 232/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0145 - accuracy: 0.9944 - val_loss: 0.0187 - val_accuracy: 0.9922\n",
      "Epoch 233/1000\n",
      "570/570 [==============================] - 0s 770us/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.0219 - val_accuracy: 0.9906\n",
      "Epoch 234/1000\n",
      "570/570 [==============================] - 0s 783us/step - loss: 0.0170 - accuracy: 0.9933 - val_loss: 0.0211 - val_accuracy: 0.9918\n",
      "Epoch 235/1000\n",
      "570/570 [==============================] - 0s 766us/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0237 - val_accuracy: 0.9926\n",
      "Epoch 236/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0184 - accuracy: 0.9928 - val_loss: 0.0227 - val_accuracy: 0.9910\n",
      "Epoch 237/1000\n",
      "570/570 [==============================] - 0s 769us/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.0213 - val_accuracy: 0.9914\n",
      "Epoch 238/1000\n",
      "570/570 [==============================] - 0s 821us/step - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.0224 - val_accuracy: 0.9926\n",
      "Epoch 239/1000\n",
      "570/570 [==============================] - 0s 856us/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.0222 - val_accuracy: 0.9935\n",
      "Epoch 240/1000\n",
      "570/570 [==============================] - 0s 789us/step - loss: 0.0154 - accuracy: 0.9936 - val_loss: 0.0194 - val_accuracy: 0.9918\n",
      "Epoch 241/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0172 - accuracy: 0.9932 - val_loss: 0.0252 - val_accuracy: 0.9910\n",
      "Epoch 242/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0165 - accuracy: 0.9937 - val_loss: 0.0221 - val_accuracy: 0.9922\n",
      "Epoch 243/1000\n",
      "570/570 [==============================] - 0s 763us/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.0207 - val_accuracy: 0.9918\n",
      "Epoch 244/1000\n",
      "570/570 [==============================] - 0s 809us/step - loss: 0.0137 - accuracy: 0.9950 - val_loss: 0.0226 - val_accuracy: 0.9910\n",
      "Epoch 245/1000\n",
      "570/570 [==============================] - 0s 821us/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0200 - val_accuracy: 0.9918\n",
      "Epoch 246/1000\n",
      "570/570 [==============================] - 0s 799us/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.0253 - val_accuracy: 0.9922\n",
      "Epoch 247/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.0202 - val_accuracy: 0.9918\n",
      "Epoch 248/1000\n",
      "570/570 [==============================] - 0s 809us/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.0201 - val_accuracy: 0.9922\n",
      "Epoch 249/1000\n",
      "570/570 [==============================] - 0s 870us/step - loss: 0.0148 - accuracy: 0.9934 - val_loss: 0.0234 - val_accuracy: 0.9910\n",
      "Epoch 250/1000\n",
      "570/570 [==============================] - 0s 846us/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0232 - val_accuracy: 0.9922\n",
      "Epoch 251/1000\n",
      "570/570 [==============================] - 0s 855us/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0239 - val_accuracy: 0.9914\n",
      "Epoch 252/1000\n",
      "570/570 [==============================] - 0s 784us/step - loss: 0.0153 - accuracy: 0.9941 - val_loss: 0.0196 - val_accuracy: 0.9910\n",
      "Epoch 253/1000\n",
      "570/570 [==============================] - 0s 811us/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0221 - val_accuracy: 0.9930\n",
      "Epoch 254/1000\n",
      "570/570 [==============================] - 0s 838us/step - loss: 0.0171 - accuracy: 0.9934 - val_loss: 0.0222 - val_accuracy: 0.9918\n",
      "Epoch 255/1000\n",
      "570/570 [==============================] - 0s 851us/step - loss: 0.0154 - accuracy: 0.9935 - val_loss: 0.0218 - val_accuracy: 0.9910\n",
      "Epoch 256/1000\n",
      "570/570 [==============================] - 1s 884us/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.0230 - val_accuracy: 0.9918\n",
      "Epoch 257/1000\n",
      "570/570 [==============================] - 0s 836us/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0242 - val_accuracy: 0.9918\n",
      "Epoch 258/1000\n",
      "570/570 [==============================] - 0s 831us/step - loss: 0.0163 - accuracy: 0.9931 - val_loss: 0.0196 - val_accuracy: 0.9930\n",
      "Epoch 259/1000\n",
      "570/570 [==============================] - 0s 782us/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.0217 - val_accuracy: 0.9906\n",
      "Epoch 260/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0215 - val_accuracy: 0.9922\n",
      "Epoch 261/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0136 - accuracy: 0.9948 - val_loss: 0.0228 - val_accuracy: 0.9922\n",
      "Epoch 262/1000\n",
      "570/570 [==============================] - 0s 799us/step - loss: 0.0176 - accuracy: 0.9930 - val_loss: 0.0238 - val_accuracy: 0.9922\n",
      "Epoch 263/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.0207 - val_accuracy: 0.9918\n",
      "Epoch 264/1000\n",
      "570/570 [==============================] - 0s 781us/step - loss: 0.0143 - accuracy: 0.9943 - val_loss: 0.0211 - val_accuracy: 0.9910\n",
      "Epoch 265/1000\n",
      "570/570 [==============================] - 0s 803us/step - loss: 0.0121 - accuracy: 0.9955 - val_loss: 0.0199 - val_accuracy: 0.9935\n",
      "Epoch 266/1000\n",
      "570/570 [==============================] - 0s 842us/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0225 - val_accuracy: 0.9922\n",
      "Epoch 267/1000\n",
      "570/570 [==============================] - 0s 775us/step - loss: 0.0176 - accuracy: 0.9931 - val_loss: 0.0236 - val_accuracy: 0.9926\n",
      "Epoch 268/1000\n",
      "570/570 [==============================] - 1s 898us/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.0201 - val_accuracy: 0.9918\n",
      "Epoch 269/1000\n",
      "570/570 [==============================] - 0s 803us/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.0210 - val_accuracy: 0.9914\n",
      "Epoch 270/1000\n",
      "570/570 [==============================] - 0s 786us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0223 - val_accuracy: 0.9926\n",
      "Epoch 271/1000\n",
      "570/570 [==============================] - 0s 790us/step - loss: 0.0146 - accuracy: 0.9944 - val_loss: 0.0210 - val_accuracy: 0.9935\n",
      "Epoch 272/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.0211 - val_accuracy: 0.9918\n",
      "Epoch 273/1000\n",
      "570/570 [==============================] - 0s 800us/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0194 - val_accuracy: 0.9918\n",
      "Epoch 274/1000\n",
      "570/570 [==============================] - 0s 795us/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0206 - val_accuracy: 0.9939\n",
      "Epoch 275/1000\n",
      "570/570 [==============================] - 0s 784us/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0223 - val_accuracy: 0.9922\n",
      "Epoch 276/1000\n",
      "570/570 [==============================] - 0s 786us/step - loss: 0.0132 - accuracy: 0.9950 - val_loss: 0.0203 - val_accuracy: 0.9930\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 774us/step - loss: 0.0108 - accuracy: 0.9954 - val_loss: 0.0233 - val_accuracy: 0.9926\n",
      "Epoch 278/1000\n",
      "570/570 [==============================] - 0s 759us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0263 - val_accuracy: 0.9894\n",
      "Epoch 279/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0157 - accuracy: 0.9929 - val_loss: 0.0208 - val_accuracy: 0.9935\n",
      "Epoch 280/1000\n",
      "570/570 [==============================] - 0s 835us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0194 - val_accuracy: 0.9935\n",
      "Epoch 281/1000\n",
      "570/570 [==============================] - 0s 838us/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0232 - val_accuracy: 0.9918\n",
      "Epoch 282/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0243 - val_accuracy: 0.9914\n",
      "Epoch 283/1000\n",
      "570/570 [==============================] - 0s 779us/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0208 - val_accuracy: 0.9914\n",
      "Epoch 284/1000\n",
      "570/570 [==============================] - 0s 825us/step - loss: 0.0107 - accuracy: 0.9953 - val_loss: 0.0181 - val_accuracy: 0.9943\n",
      "Epoch 285/1000\n",
      "570/570 [==============================] - 0s 793us/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0225 - val_accuracy: 0.9910\n",
      "Epoch 286/1000\n",
      "570/570 [==============================] - 0s 781us/step - loss: 0.0127 - accuracy: 0.9946 - val_loss: 0.0195 - val_accuracy: 0.9930\n",
      "Epoch 287/1000\n",
      "570/570 [==============================] - 0s 838us/step - loss: 0.0153 - accuracy: 0.9938 - val_loss: 0.0201 - val_accuracy: 0.9922\n",
      "Epoch 288/1000\n",
      "570/570 [==============================] - 0s 868us/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.0254 - val_accuracy: 0.9881\n",
      "Epoch 289/1000\n",
      "570/570 [==============================] - 0s 831us/step - loss: 0.0166 - accuracy: 0.9925 - val_loss: 0.0225 - val_accuracy: 0.9922\n",
      "Epoch 290/1000\n",
      "570/570 [==============================] - 0s 815us/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0199 - val_accuracy: 0.9926\n",
      "Epoch 291/1000\n",
      "570/570 [==============================] - 0s 791us/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0197 - val_accuracy: 0.9918\n",
      "Epoch 292/1000\n",
      "570/570 [==============================] - 0s 839us/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0203 - val_accuracy: 0.9930\n",
      "Epoch 293/1000\n",
      "570/570 [==============================] - 0s 865us/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.0199 - val_accuracy: 0.9930\n",
      "Epoch 294/1000\n",
      "570/570 [==============================] - 1s 889us/step - loss: 0.0123 - accuracy: 0.9947 - val_loss: 0.0204 - val_accuracy: 0.9935\n",
      "Epoch 295/1000\n",
      "570/570 [==============================] - 0s 770us/step - loss: 0.0100 - accuracy: 0.9957 - val_loss: 0.0220 - val_accuracy: 0.9922\n",
      "Epoch 296/1000\n",
      "570/570 [==============================] - 0s 805us/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.0229 - val_accuracy: 0.9922\n",
      "Epoch 297/1000\n",
      "570/570 [==============================] - 0s 828us/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.0217 - val_accuracy: 0.9935\n",
      "Epoch 298/1000\n",
      "570/570 [==============================] - 0s 853us/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0190 - val_accuracy: 0.9926\n",
      "Epoch 299/1000\n",
      "570/570 [==============================] - 0s 813us/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.0212 - val_accuracy: 0.9922\n",
      "Epoch 300/1000\n",
      "570/570 [==============================] - 0s 853us/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.0238 - val_accuracy: 0.9918\n",
      "Epoch 301/1000\n",
      "570/570 [==============================] - 0s 825us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0238 - val_accuracy: 0.9906\n",
      "Epoch 302/1000\n",
      "570/570 [==============================] - 0s 821us/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.0227 - val_accuracy: 0.9914\n",
      "Epoch 303/1000\n",
      "570/570 [==============================] - 0s 841us/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.0224 - val_accuracy: 0.9906\n",
      "Epoch 304/1000\n",
      "570/570 [==============================] - 0s 862us/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0214 - val_accuracy: 0.9935\n",
      "Epoch 305/1000\n",
      "570/570 [==============================] - 0s 850us/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.0242 - val_accuracy: 0.9922\n",
      "Epoch 306/1000\n",
      "570/570 [==============================] - 0s 801us/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0215 - val_accuracy: 0.9922\n",
      "Epoch 307/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0248 - val_accuracy: 0.9918\n",
      "Epoch 308/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.0195 - val_accuracy: 0.9918\n",
      "Epoch 309/1000\n",
      "570/570 [==============================] - 0s 789us/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0219 - val_accuracy: 0.9902\n",
      "Epoch 310/1000\n",
      "570/570 [==============================] - 0s 792us/step - loss: 0.0112 - accuracy: 0.9953 - val_loss: 0.0238 - val_accuracy: 0.9922\n",
      "Epoch 311/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0210 - val_accuracy: 0.9930\n",
      "Epoch 312/1000\n",
      "570/570 [==============================] - 0s 791us/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.0235 - val_accuracy: 0.9930\n",
      "Epoch 313/1000\n",
      "570/570 [==============================] - 0s 806us/step - loss: 0.0123 - accuracy: 0.9941 - val_loss: 0.0205 - val_accuracy: 0.9926\n",
      "Epoch 314/1000\n",
      "570/570 [==============================] - 0s 781us/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.0167 - val_accuracy: 0.9943\n",
      "Epoch 315/1000\n",
      "570/570 [==============================] - 0s 791us/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0189 - val_accuracy: 0.9935\n",
      "Epoch 316/1000\n",
      "570/570 [==============================] - 0s 816us/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 0.0192 - val_accuracy: 0.9914\n",
      "Epoch 317/1000\n",
      "570/570 [==============================] - 0s 844us/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0212 - val_accuracy: 0.9930\n",
      "Epoch 318/1000\n",
      "570/570 [==============================] - 0s 779us/step - loss: 0.0140 - accuracy: 0.9941 - val_loss: 0.0210 - val_accuracy: 0.9930\n",
      "Epoch 319/1000\n",
      "570/570 [==============================] - 0s 791us/step - loss: 0.0179 - accuracy: 0.9923 - val_loss: 0.0225 - val_accuracy: 0.9930\n",
      "Epoch 320/1000\n",
      "570/570 [==============================] - 0s 785us/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.0199 - val_accuracy: 0.9926\n",
      "Epoch 321/1000\n",
      "570/570 [==============================] - 0s 835us/step - loss: 0.0129 - accuracy: 0.9944 - val_loss: 0.0243 - val_accuracy: 0.9918\n",
      "Epoch 322/1000\n",
      "570/570 [==============================] - 0s 793us/step - loss: 0.0142 - accuracy: 0.9941 - val_loss: 0.0249 - val_accuracy: 0.9914\n",
      "Epoch 323/1000\n",
      "570/570 [==============================] - 0s 793us/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.0190 - val_accuracy: 0.9943\n",
      "Epoch 324/1000\n",
      "570/570 [==============================] - 0s 784us/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.0192 - val_accuracy: 0.9926\n",
      "Epoch 325/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0198 - val_accuracy: 0.9930\n",
      "Epoch 326/1000\n",
      "570/570 [==============================] - 0s 785us/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.0198 - val_accuracy: 0.9910\n",
      "Epoch 327/1000\n",
      "570/570 [==============================] - 0s 787us/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.0199 - val_accuracy: 0.9939\n",
      "Epoch 328/1000\n",
      "570/570 [==============================] - 0s 844us/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 0.0201 - val_accuracy: 0.9935\n",
      "Epoch 329/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.0211 - val_accuracy: 0.9926\n",
      "Epoch 330/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.0226 - val_accuracy: 0.9926\n",
      "Epoch 331/1000\n",
      "570/570 [==============================] - 0s 797us/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0230 - val_accuracy: 0.9906\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 762us/step - loss: 0.0095 - accuracy: 0.9957 - val_loss: 0.0235 - val_accuracy: 0.9906\n",
      "Epoch 333/1000\n",
      "570/570 [==============================] - 0s 788us/step - loss: 0.0158 - accuracy: 0.9934 - val_loss: 0.0237 - val_accuracy: 0.9910\n",
      "Epoch 334/1000\n",
      "570/570 [==============================] - 0s 810us/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.0218 - val_accuracy: 0.9918\n",
      "Epoch 335/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.0217 - val_accuracy: 0.9930\n",
      "Epoch 336/1000\n",
      "570/570 [==============================] - 0s 799us/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0251 - val_accuracy: 0.9918\n",
      "Epoch 337/1000\n",
      "570/570 [==============================] - 0s 786us/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.0231 - val_accuracy: 0.9922\n",
      "Epoch 338/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0231 - val_accuracy: 0.9926\n",
      "Epoch 339/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.0261 - val_accuracy: 0.9902\n",
      "Epoch 340/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0142 - accuracy: 0.9943 - val_loss: 0.0254 - val_accuracy: 0.9926\n",
      "Epoch 341/1000\n",
      "570/570 [==============================] - 0s 787us/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0264 - val_accuracy: 0.9926\n",
      "Epoch 342/1000\n",
      "570/570 [==============================] - 0s 807us/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.0199 - val_accuracy: 0.9926\n",
      "Epoch 343/1000\n",
      "570/570 [==============================] - 0s 806us/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.0220 - val_accuracy: 0.9935\n",
      "Epoch 344/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.0222 - val_accuracy: 0.9914\n",
      "Epoch 345/1000\n",
      "570/570 [==============================] - 0s 764us/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.0284 - val_accuracy: 0.9914\n",
      "Epoch 346/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.0231 - val_accuracy: 0.9935\n",
      "Epoch 347/1000\n",
      "570/570 [==============================] - 0s 795us/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.0238 - val_accuracy: 0.9918\n",
      "Epoch 348/1000\n",
      "570/570 [==============================] - 0s 761us/step - loss: 0.0146 - accuracy: 0.9940 - val_loss: 0.0286 - val_accuracy: 0.9910\n",
      "Epoch 349/1000\n",
      "570/570 [==============================] - 0s 824us/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0218 - val_accuracy: 0.9939\n",
      "Epoch 350/1000\n",
      "570/570 [==============================] - 0s 809us/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0262 - val_accuracy: 0.9918\n",
      "Epoch 351/1000\n",
      "570/570 [==============================] - 0s 797us/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.0273 - val_accuracy: 0.9906\n",
      "Epoch 352/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.0245 - val_accuracy: 0.9910\n",
      "Epoch 353/1000\n",
      "570/570 [==============================] - 0s 848us/step - loss: 0.0115 - accuracy: 0.9952 - val_loss: 0.0247 - val_accuracy: 0.9910\n",
      "Epoch 354/1000\n",
      "570/570 [==============================] - 0s 806us/step - loss: 0.0144 - accuracy: 0.9948 - val_loss: 0.0222 - val_accuracy: 0.9922\n",
      "Epoch 355/1000\n",
      "570/570 [==============================] - 0s 869us/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0233 - val_accuracy: 0.9914\n",
      "Epoch 356/1000\n",
      "570/570 [==============================] - 0s 816us/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0206 - val_accuracy: 0.9918\n",
      "Epoch 357/1000\n",
      "570/570 [==============================] - 0s 831us/step - loss: 0.0182 - accuracy: 0.9929 - val_loss: 0.0200 - val_accuracy: 0.9926\n",
      "Epoch 358/1000\n",
      "570/570 [==============================] - 0s 836us/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.0188 - val_accuracy: 0.9922\n",
      "Epoch 359/1000\n",
      "570/570 [==============================] - 0s 829us/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.0268 - val_accuracy: 0.9906\n",
      "Epoch 360/1000\n",
      "570/570 [==============================] - 0s 801us/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.0213 - val_accuracy: 0.9910\n",
      "Epoch 361/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.0256 - val_accuracy: 0.9906\n",
      "Epoch 362/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.0247 - val_accuracy: 0.9914\n",
      "Epoch 363/1000\n",
      "570/570 [==============================] - 0s 769us/step - loss: 0.0137 - accuracy: 0.9948 - val_loss: 0.0232 - val_accuracy: 0.9930\n",
      "Epoch 364/1000\n",
      "570/570 [==============================] - 0s 823us/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0237 - val_accuracy: 0.9894\n",
      "Epoch 365/1000\n",
      "570/570 [==============================] - 0s 787us/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.0219 - val_accuracy: 0.9939\n",
      "Epoch 366/1000\n",
      "570/570 [==============================] - 0s 830us/step - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.0221 - val_accuracy: 0.9910\n",
      "Epoch 367/1000\n",
      "570/570 [==============================] - 0s 864us/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0227 - val_accuracy: 0.9914\n",
      "Epoch 368/1000\n",
      "570/570 [==============================] - 0s 800us/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0237 - val_accuracy: 0.9918\n",
      "Epoch 369/1000\n",
      "570/570 [==============================] - 0s 819us/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.0211 - val_accuracy: 0.9914\n",
      "Epoch 370/1000\n",
      "570/570 [==============================] - 0s 851us/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.0245 - val_accuracy: 0.9918\n",
      "Epoch 371/1000\n",
      "570/570 [==============================] - 0s 801us/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0451 - val_accuracy: 0.9930\n",
      "Epoch 372/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.0434 - val_accuracy: 0.9906\n",
      "Epoch 373/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.0351 - val_accuracy: 0.9910\n",
      "Epoch 374/1000\n",
      "570/570 [==============================] - 0s 764us/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.0343 - val_accuracy: 0.9914\n",
      "Epoch 375/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.0348 - val_accuracy: 0.9926\n",
      "Epoch 376/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0123 - accuracy: 0.9952 - val_loss: 0.0387 - val_accuracy: 0.9926\n",
      "Epoch 377/1000\n",
      "570/570 [==============================] - 0s 817us/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.0334 - val_accuracy: 0.9914\n",
      "Epoch 378/1000\n",
      "570/570 [==============================] - 0s 806us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0324 - val_accuracy: 0.9930\n",
      "Epoch 379/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0316 - val_accuracy: 0.9902\n",
      "Epoch 380/1000\n",
      "570/570 [==============================] - 0s 849us/step - loss: 0.0128 - accuracy: 0.9946 - val_loss: 0.0342 - val_accuracy: 0.9898\n",
      "Epoch 381/1000\n",
      "570/570 [==============================] - 0s 803us/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.0373 - val_accuracy: 0.9918\n",
      "Epoch 382/1000\n",
      "570/570 [==============================] - 0s 838us/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.0284 - val_accuracy: 0.9918\n",
      "Epoch 383/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0133 - accuracy: 0.9944 - val_loss: 0.0354 - val_accuracy: 0.9906\n",
      "Epoch 384/1000\n",
      "570/570 [==============================] - 0s 840us/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 0.0343 - val_accuracy: 0.9918\n",
      "Epoch 385/1000\n",
      "570/570 [==============================] - 0s 794us/step - loss: 0.0104 - accuracy: 0.9954 - val_loss: 0.0351 - val_accuracy: 0.9922\n",
      "Epoch 386/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0311 - val_accuracy: 0.9894\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 829us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0307 - val_accuracy: 0.9918\n",
      "Epoch 388/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0302 - val_accuracy: 0.9918\n",
      "Epoch 389/1000\n",
      "570/570 [==============================] - 0s 761us/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0371 - val_accuracy: 0.9906\n",
      "Epoch 390/1000\n",
      "570/570 [==============================] - 0s 758us/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0302 - val_accuracy: 0.9914\n",
      "Epoch 391/1000\n",
      "570/570 [==============================] - 0s 762us/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0307 - val_accuracy: 0.9922\n",
      "Epoch 392/1000\n",
      "570/570 [==============================] - 0s 759us/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0376 - val_accuracy: 0.9918\n",
      "Epoch 393/1000\n",
      "570/570 [==============================] - 0s 761us/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.0333 - val_accuracy: 0.9922\n",
      "Epoch 394/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0341 - val_accuracy: 0.9926\n",
      "Epoch 395/1000\n",
      "570/570 [==============================] - 0s 762us/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.0322 - val_accuracy: 0.9918\n",
      "Epoch 396/1000\n",
      "570/570 [==============================] - 0s 759us/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0253 - val_accuracy: 0.9922\n",
      "Epoch 397/1000\n",
      "570/570 [==============================] - 0s 757us/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.0282 - val_accuracy: 0.9922\n",
      "Epoch 398/1000\n",
      "570/570 [==============================] - 0s 812us/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.0288 - val_accuracy: 0.9906\n",
      "Epoch 399/1000\n",
      "570/570 [==============================] - 0s 803us/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0233 - val_accuracy: 0.9922\n",
      "Epoch 400/1000\n",
      "570/570 [==============================] - 0s 821us/step - loss: 0.0134 - accuracy: 0.9944 - val_loss: 0.0310 - val_accuracy: 0.9902\n",
      "Epoch 401/1000\n",
      "570/570 [==============================] - 0s 766us/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.0279 - val_accuracy: 0.9914\n",
      "Epoch 402/1000\n",
      "570/570 [==============================] - 1s 880us/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0329 - val_accuracy: 0.9922\n",
      "Epoch 403/1000\n",
      "570/570 [==============================] - 1s 926us/step - loss: 0.0127 - accuracy: 0.9952 - val_loss: 0.0216 - val_accuracy: 0.9943\n",
      "Epoch 404/1000\n",
      "570/570 [==============================] - 0s 870us/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0261 - val_accuracy: 0.9898\n",
      "Epoch 405/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0271 - val_accuracy: 0.9914\n",
      "Epoch 406/1000\n",
      "570/570 [==============================] - 0s 794us/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 0.0279 - val_accuracy: 0.9930\n",
      "Epoch 407/1000\n",
      "570/570 [==============================] - 0s 769us/step - loss: 0.0122 - accuracy: 0.9947 - val_loss: 0.0245 - val_accuracy: 0.9935\n",
      "Epoch 408/1000\n",
      "570/570 [==============================] - 0s 788us/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.0318 - val_accuracy: 0.9898\n",
      "Epoch 409/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.0230 - val_accuracy: 0.9930\n",
      "Epoch 410/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.0260 - val_accuracy: 0.9918\n",
      "Epoch 411/1000\n",
      "570/570 [==============================] - 0s 775us/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.0307 - val_accuracy: 0.9914\n",
      "Epoch 412/1000\n",
      "570/570 [==============================] - 0s 779us/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0247 - val_accuracy: 0.9930\n",
      "Epoch 413/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 0.0265 - val_accuracy: 0.9918\n",
      "Epoch 414/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0248 - val_accuracy: 0.9918\n",
      "Epoch 415/1000\n",
      "570/570 [==============================] - 0s 798us/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 0.0271 - val_accuracy: 0.9918\n",
      "Epoch 416/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0250 - val_accuracy: 0.9918\n",
      "Epoch 417/1000\n",
      "570/570 [==============================] - 0s 793us/step - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.0250 - val_accuracy: 0.9930\n",
      "Epoch 418/1000\n",
      "570/570 [==============================] - 0s 789us/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0258 - val_accuracy: 0.9914\n",
      "Epoch 419/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0274 - val_accuracy: 0.9889\n",
      "Epoch 420/1000\n",
      "570/570 [==============================] - 0s 781us/step - loss: 0.0206 - accuracy: 0.9921 - val_loss: 0.0281 - val_accuracy: 0.9918\n",
      "Epoch 421/1000\n",
      "570/570 [==============================] - 0s 779us/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0265 - val_accuracy: 0.9930\n",
      "Epoch 422/1000\n",
      "570/570 [==============================] - 0s 783us/step - loss: 0.0118 - accuracy: 0.9955 - val_loss: 0.0250 - val_accuracy: 0.9926\n",
      "Epoch 423/1000\n",
      "570/570 [==============================] - 0s 796us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0255 - val_accuracy: 0.9918\n",
      "Epoch 424/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0192 - val_accuracy: 0.9930\n",
      "Epoch 425/1000\n",
      "570/570 [==============================] - 0s 796us/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.0268 - val_accuracy: 0.9918\n",
      "Epoch 426/1000\n",
      "570/570 [==============================] - 0s 855us/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.0242 - val_accuracy: 0.9922\n",
      "Epoch 427/1000\n",
      "570/570 [==============================] - 0s 833us/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0340 - val_accuracy: 0.9918\n",
      "Epoch 428/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0113 - accuracy: 0.9951 - val_loss: 0.0244 - val_accuracy: 0.9914\n",
      "Epoch 429/1000\n",
      "570/570 [==============================] - 1s 891us/step - loss: 0.0108 - accuracy: 0.9949 - val_loss: 0.0244 - val_accuracy: 0.9906\n",
      "Epoch 430/1000\n",
      "570/570 [==============================] - 0s 831us/step - loss: 0.0121 - accuracy: 0.9947 - val_loss: 0.0247 - val_accuracy: 0.9914\n",
      "Epoch 431/1000\n",
      "570/570 [==============================] - 0s 803us/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0224 - val_accuracy: 0.9922\n",
      "Epoch 432/1000\n",
      "570/570 [==============================] - 0s 873us/step - loss: 0.0117 - accuracy: 0.9944 - val_loss: 0.0251 - val_accuracy: 0.9918\n",
      "Epoch 433/1000\n",
      "570/570 [==============================] - 0s 786us/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.0206 - val_accuracy: 0.9922\n",
      "Epoch 434/1000\n",
      "570/570 [==============================] - 1s 892us/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.0258 - val_accuracy: 0.9926\n",
      "Epoch 435/1000\n",
      "570/570 [==============================] - 0s 867us/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0232 - val_accuracy: 0.9935\n",
      "Epoch 436/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0146 - accuracy: 0.9944 - val_loss: 0.0227 - val_accuracy: 0.9926\n",
      "Epoch 437/1000\n",
      "570/570 [==============================] - 0s 766us/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0269 - val_accuracy: 0.9902\n",
      "Epoch 438/1000\n",
      "570/570 [==============================] - 0s 777us/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0256 - val_accuracy: 0.9930\n",
      "Epoch 439/1000\n",
      "570/570 [==============================] - 0s 778us/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.0282 - val_accuracy: 0.9922\n",
      "Epoch 440/1000\n",
      "570/570 [==============================] - 0s 793us/step - loss: 0.0134 - accuracy: 0.9950 - val_loss: 0.0227 - val_accuracy: 0.9914\n",
      "Epoch 441/1000\n",
      "570/570 [==============================] - 0s 807us/step - loss: 0.0107 - accuracy: 0.9956 - val_loss: 0.0255 - val_accuracy: 0.9926\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 793us/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.0290 - val_accuracy: 0.9922\n",
      "Epoch 443/1000\n",
      "570/570 [==============================] - 0s 794us/step - loss: 0.0100 - accuracy: 0.9959 - val_loss: 0.0247 - val_accuracy: 0.9922\n",
      "Epoch 444/1000\n",
      "570/570 [==============================] - 0s 793us/step - loss: 0.0129 - accuracy: 0.9948 - val_loss: 0.0234 - val_accuracy: 0.9935\n",
      "Epoch 445/1000\n",
      "570/570 [==============================] - 0s 782us/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0281 - val_accuracy: 0.9918\n",
      "Epoch 446/1000\n",
      "570/570 [==============================] - 0s 877us/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.0256 - val_accuracy: 0.9910\n",
      "Epoch 447/1000\n",
      "570/570 [==============================] - 1s 957us/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.0213 - val_accuracy: 0.9930\n",
      "Epoch 448/1000\n",
      "570/570 [==============================] - 1s 1ms/step - loss: 0.0116 - accuracy: 0.9955 - val_loss: 0.0256 - val_accuracy: 0.9914\n",
      "Epoch 449/1000\n",
      "570/570 [==============================] - 1s 986us/step - loss: 0.0141 - accuracy: 0.9948 - val_loss: 0.0252 - val_accuracy: 0.9930\n",
      "Epoch 450/1000\n",
      "570/570 [==============================] - 0s 857us/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0236 - val_accuracy: 0.9935\n",
      "Epoch 451/1000\n",
      "570/570 [==============================] - 0s 845us/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.0260 - val_accuracy: 0.9922\n",
      "Epoch 452/1000\n",
      "570/570 [==============================] - 0s 813us/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.0261 - val_accuracy: 0.9935\n",
      "Epoch 453/1000\n",
      "570/570 [==============================] - 1s 1ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.0250 - val_accuracy: 0.9922\n",
      "Epoch 454/1000\n",
      "570/570 [==============================] - 1s 964us/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.0280 - val_accuracy: 0.9910\n",
      "Epoch 455/1000\n",
      "570/570 [==============================] - 0s 865us/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0307 - val_accuracy: 0.9906\n",
      "Epoch 456/1000\n",
      "570/570 [==============================] - 0s 801us/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.0265 - val_accuracy: 0.9914\n",
      "Epoch 457/1000\n",
      "570/570 [==============================] - 0s 794us/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.0273 - val_accuracy: 0.9926\n",
      "Epoch 458/1000\n",
      "570/570 [==============================] - 0s 838us/step - loss: 0.0138 - accuracy: 0.9940 - val_loss: 0.0292 - val_accuracy: 0.9926\n",
      "Epoch 459/1000\n",
      "570/570 [==============================] - 0s 867us/step - loss: 0.0094 - accuracy: 0.9962 - val_loss: 0.0269 - val_accuracy: 0.9914\n",
      "Epoch 460/1000\n",
      "570/570 [==============================] - 0s 854us/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0267 - val_accuracy: 0.9930\n",
      "Epoch 461/1000\n",
      "570/570 [==============================] - 0s 835us/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.0256 - val_accuracy: 0.9943\n",
      "Epoch 462/1000\n",
      "570/570 [==============================] - 0s 817us/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0291 - val_accuracy: 0.9918\n",
      "Epoch 463/1000\n",
      "570/570 [==============================] - 0s 814us/step - loss: 0.0117 - accuracy: 0.9952 - val_loss: 0.0267 - val_accuracy: 0.9930\n",
      "Epoch 464/1000\n",
      "570/570 [==============================] - 1s 881us/step - loss: 0.0081 - accuracy: 0.9967 - val_loss: 0.0323 - val_accuracy: 0.9906\n",
      "Epoch 465/1000\n",
      "570/570 [==============================] - 1s 918us/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0270 - val_accuracy: 0.9914\n",
      "Epoch 466/1000\n",
      "570/570 [==============================] - 0s 865us/step - loss: 0.0114 - accuracy: 0.9948 - val_loss: 0.0210 - val_accuracy: 0.9930\n",
      "Epoch 467/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.0240 - val_accuracy: 0.9935\n",
      "Epoch 468/1000\n",
      "570/570 [==============================] - 0s 841us/step - loss: 0.0157 - accuracy: 0.9941 - val_loss: 0.0239 - val_accuracy: 0.9935\n",
      "Epoch 469/1000\n",
      "570/570 [==============================] - 0s 809us/step - loss: 0.0128 - accuracy: 0.9946 - val_loss: 0.0263 - val_accuracy: 0.9914\n",
      "Epoch 470/1000\n",
      "570/570 [==============================] - 1s 987us/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 0.0261 - val_accuracy: 0.9922\n",
      "Epoch 471/1000\n",
      "570/570 [==============================] - 0s 800us/step - loss: 0.0145 - accuracy: 0.9931 - val_loss: 0.0247 - val_accuracy: 0.9939\n",
      "Epoch 472/1000\n",
      "570/570 [==============================] - 0s 822us/step - loss: 0.0109 - accuracy: 0.9953 - val_loss: 0.0222 - val_accuracy: 0.9914\n",
      "Epoch 473/1000\n",
      "570/570 [==============================] - 1s 964us/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0241 - val_accuracy: 0.9939\n",
      "Epoch 474/1000\n",
      "570/570 [==============================] - 1s 989us/step - loss: 0.0148 - accuracy: 0.9938 - val_loss: 0.0261 - val_accuracy: 0.9926\n",
      "Epoch 475/1000\n",
      "570/570 [==============================] - 1s 909us/step - loss: 0.0111 - accuracy: 0.9955 - val_loss: 0.0256 - val_accuracy: 0.9926\n",
      "Epoch 476/1000\n",
      "570/570 [==============================] - 0s 841us/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.0250 - val_accuracy: 0.9910\n",
      "Epoch 477/1000\n",
      "570/570 [==============================] - 1s 913us/step - loss: 0.0115 - accuracy: 0.9952 - val_loss: 0.0236 - val_accuracy: 0.9935\n",
      "Epoch 478/1000\n",
      "570/570 [==============================] - 1s 882us/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0306 - val_accuracy: 0.9910\n",
      "Epoch 479/1000\n",
      "570/570 [==============================] - 0s 818us/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.0293 - val_accuracy: 0.9926\n",
      "Epoch 480/1000\n",
      "570/570 [==============================] - 0s 820us/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0235 - val_accuracy: 0.9930\n",
      "Epoch 481/1000\n",
      "570/570 [==============================] - 0s 860us/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0249 - val_accuracy: 0.9926\n",
      "Epoch 482/1000\n",
      "570/570 [==============================] - 0s 874us/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0283 - val_accuracy: 0.9922\n",
      "Epoch 483/1000\n",
      "570/570 [==============================] - 1s 886us/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.0285 - val_accuracy: 0.9930\n",
      "Epoch 484/1000\n",
      "570/570 [==============================] - 0s 817us/step - loss: 0.0121 - accuracy: 0.9950 - val_loss: 0.0266 - val_accuracy: 0.9922\n",
      "Epoch 485/1000\n",
      "570/570 [==============================] - 0s 823us/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 0.0244 - val_accuracy: 0.9918\n",
      "Epoch 486/1000\n",
      "570/570 [==============================] - 0s 835us/step - loss: 0.0133 - accuracy: 0.9944 - val_loss: 0.0283 - val_accuracy: 0.9922\n",
      "Epoch 487/1000\n",
      "570/570 [==============================] - 0s 806us/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.0261 - val_accuracy: 0.9906\n",
      "Epoch 488/1000\n",
      "570/570 [==============================] - 0s 825us/step - loss: 0.0144 - accuracy: 0.9948 - val_loss: 0.0283 - val_accuracy: 0.9902\n",
      "Epoch 489/1000\n",
      "570/570 [==============================] - 0s 791us/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.0261 - val_accuracy: 0.9910\n",
      "Epoch 490/1000\n",
      "570/570 [==============================] - 0s 787us/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.0242 - val_accuracy: 0.9922\n",
      "Epoch 491/1000\n",
      "570/570 [==============================] - 0s 806us/step - loss: 0.0148 - accuracy: 0.9939 - val_loss: 0.0229 - val_accuracy: 0.9922\n",
      "Epoch 492/1000\n",
      "570/570 [==============================] - 0s 803us/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0270 - val_accuracy: 0.9922\n",
      "Epoch 493/1000\n",
      "570/570 [==============================] - 0s 875us/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0259 - val_accuracy: 0.9922\n",
      "Epoch 494/1000\n",
      "570/570 [==============================] - 0s 817us/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0244 - val_accuracy: 0.9918\n",
      "Epoch 495/1000\n",
      "570/570 [==============================] - 0s 816us/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.0255 - val_accuracy: 0.9939\n",
      "Epoch 496/1000\n",
      "570/570 [==============================] - 0s 866us/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0275 - val_accuracy: 0.9939\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 1s 948us/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0238 - val_accuracy: 0.9922\n",
      "Epoch 498/1000\n",
      "570/570 [==============================] - 0s 846us/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.0259 - val_accuracy: 0.9935\n",
      "Epoch 499/1000\n",
      "570/570 [==============================] - 0s 816us/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0301 - val_accuracy: 0.9926\n",
      "Epoch 500/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.0250 - val_accuracy: 0.9935\n",
      "Epoch 501/1000\n",
      "570/570 [==============================] - 0s 830us/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0289 - val_accuracy: 0.9930\n",
      "Epoch 502/1000\n",
      "570/570 [==============================] - 0s 809us/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 0.0291 - val_accuracy: 0.9910\n",
      "Epoch 503/1000\n",
      "570/570 [==============================] - 0s 795us/step - loss: 0.0159 - accuracy: 0.9939 - val_loss: 0.0298 - val_accuracy: 0.9914\n",
      "Epoch 504/1000\n",
      "570/570 [==============================] - 0s 850us/step - loss: 0.0152 - accuracy: 0.9945 - val_loss: 0.0290 - val_accuracy: 0.9910\n",
      "Epoch 505/1000\n",
      "570/570 [==============================] - 1s 882us/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0309 - val_accuracy: 0.9894\n",
      "Epoch 506/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.0264 - val_accuracy: 0.9914\n",
      "Epoch 507/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0119 - accuracy: 0.9941 - val_loss: 0.0268 - val_accuracy: 0.9914\n",
      "Epoch 508/1000\n",
      "570/570 [==============================] - 0s 777us/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.0248 - val_accuracy: 0.9922\n",
      "Epoch 509/1000\n",
      "570/570 [==============================] - 0s 764us/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.0265 - val_accuracy: 0.9922\n",
      "Epoch 510/1000\n",
      "570/570 [==============================] - 0s 781us/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0230 - val_accuracy: 0.9914\n",
      "Epoch 511/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.0276 - val_accuracy: 0.9902\n",
      "Epoch 512/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0169 - accuracy: 0.9933 - val_loss: 0.0264 - val_accuracy: 0.9930\n",
      "Epoch 513/1000\n",
      "570/570 [==============================] - 0s 796us/step - loss: 0.0113 - accuracy: 0.9955 - val_loss: 0.0282 - val_accuracy: 0.9914\n",
      "Epoch 514/1000\n",
      "570/570 [==============================] - 1s 880us/step - loss: 0.0169 - accuracy: 0.9938 - val_loss: 0.0241 - val_accuracy: 0.9935\n",
      "Epoch 515/1000\n",
      "570/570 [==============================] - 1s 928us/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0236 - val_accuracy: 0.9926\n",
      "Epoch 516/1000\n",
      "570/570 [==============================] - 0s 775us/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0228 - val_accuracy: 0.9910\n",
      "Epoch 517/1000\n",
      "570/570 [==============================] - 0s 797us/step - loss: 0.0137 - accuracy: 0.9950 - val_loss: 0.0225 - val_accuracy: 0.9926\n",
      "Epoch 518/1000\n",
      "570/570 [==============================] - 1s 964us/step - loss: 0.0150 - accuracy: 0.9943 - val_loss: 0.0233 - val_accuracy: 0.9914\n",
      "Epoch 519/1000\n",
      "570/570 [==============================] - 0s 760us/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0245 - val_accuracy: 0.9930\n",
      "Epoch 520/1000\n",
      "570/570 [==============================] - 0s 762us/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.0244 - val_accuracy: 0.9930\n",
      "Epoch 521/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.0212 - val_accuracy: 0.9943\n",
      "Epoch 522/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0240 - val_accuracy: 0.9935\n",
      "Epoch 523/1000\n",
      "570/570 [==============================] - 0s 798us/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0237 - val_accuracy: 0.9918\n",
      "Epoch 524/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.0229 - val_accuracy: 0.9926\n",
      "Epoch 525/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.0230 - val_accuracy: 0.9935\n",
      "Epoch 526/1000\n",
      "570/570 [==============================] - 0s 851us/step - loss: 0.0133 - accuracy: 0.9942 - val_loss: 0.0219 - val_accuracy: 0.9939\n",
      "Epoch 527/1000\n",
      "570/570 [==============================] - 1s 894us/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0228 - val_accuracy: 0.9926\n",
      "Epoch 528/1000\n",
      "570/570 [==============================] - 0s 822us/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.0222 - val_accuracy: 0.9918\n",
      "Epoch 529/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0247 - val_accuracy: 0.9918\n",
      "Epoch 530/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.0247 - val_accuracy: 0.9930\n",
      "Epoch 531/1000\n",
      "570/570 [==============================] - 0s 837us/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0256 - val_accuracy: 0.9935\n",
      "Epoch 532/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0242 - val_accuracy: 0.9922\n",
      "Epoch 533/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.0224 - val_accuracy: 0.9930\n",
      "Epoch 534/1000\n",
      "570/570 [==============================] - 1s 886us/step - loss: 0.0117 - accuracy: 0.9952 - val_loss: 0.0222 - val_accuracy: 0.9922\n",
      "Epoch 535/1000\n",
      "570/570 [==============================] - 1s 969us/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0249 - val_accuracy: 0.9926\n",
      "Epoch 536/1000\n",
      "570/570 [==============================] - 1s 950us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0202 - val_accuracy: 0.9926\n",
      "Epoch 537/1000\n",
      "570/570 [==============================] - 0s 850us/step - loss: 0.0144 - accuracy: 0.9941 - val_loss: 0.0238 - val_accuracy: 0.9943\n",
      "Epoch 538/1000\n",
      "570/570 [==============================] - 0s 798us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0245 - val_accuracy: 0.9922\n",
      "Epoch 539/1000\n",
      "570/570 [==============================] - 0s 789us/step - loss: 0.0126 - accuracy: 0.9945 - val_loss: 0.0266 - val_accuracy: 0.9918\n",
      "Epoch 540/1000\n",
      "570/570 [==============================] - 0s 790us/step - loss: 0.0126 - accuracy: 0.9950 - val_loss: 0.0255 - val_accuracy: 0.9939\n",
      "Epoch 541/1000\n",
      "570/570 [==============================] - 0s 816us/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.0236 - val_accuracy: 0.9943\n",
      "Epoch 542/1000\n",
      "570/570 [==============================] - 0s 777us/step - loss: 0.0098 - accuracy: 0.9958 - val_loss: 0.0269 - val_accuracy: 0.9918\n",
      "Epoch 543/1000\n",
      "570/570 [==============================] - 0s 779us/step - loss: 0.0109 - accuracy: 0.9952 - val_loss: 0.0206 - val_accuracy: 0.9939\n",
      "Epoch 544/1000\n",
      "570/570 [==============================] - 0s 775us/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.0216 - val_accuracy: 0.9939\n",
      "Epoch 545/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0225 - val_accuracy: 0.9935\n",
      "Epoch 546/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 0.0263 - val_accuracy: 0.9914\n",
      "Epoch 547/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0275 - val_accuracy: 0.9918\n",
      "Epoch 548/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0215 - val_accuracy: 0.9926\n",
      "Epoch 549/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0110 - accuracy: 0.9953 - val_loss: 0.0190 - val_accuracy: 0.9939\n",
      "Epoch 550/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.0213 - val_accuracy: 0.9943\n",
      "Epoch 551/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0268 - val_accuracy: 0.9914\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 776us/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0186 - val_accuracy: 0.9947\n",
      "Epoch 553/1000\n",
      "570/570 [==============================] - 0s 753us/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.0247 - val_accuracy: 0.9922\n",
      "Epoch 554/1000\n",
      "570/570 [==============================] - 0s 764us/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0241 - val_accuracy: 0.9922\n",
      "Epoch 555/1000\n",
      "570/570 [==============================] - 0s 752us/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.0228 - val_accuracy: 0.9930\n",
      "Epoch 556/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 0.0275 - val_accuracy: 0.9922\n",
      "Epoch 557/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.0234 - val_accuracy: 0.9926\n",
      "Epoch 558/1000\n",
      "570/570 [==============================] - 1s 924us/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.0251 - val_accuracy: 0.9926\n",
      "Epoch 559/1000\n",
      "570/570 [==============================] - 0s 761us/step - loss: 0.0130 - accuracy: 0.9950 - val_loss: 0.0272 - val_accuracy: 0.9918\n",
      "Epoch 560/1000\n",
      "570/570 [==============================] - 0s 759us/step - loss: 0.0116 - accuracy: 0.9952 - val_loss: 0.0293 - val_accuracy: 0.9910\n",
      "Epoch 561/1000\n",
      "570/570 [==============================] - 0s 760us/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.0223 - val_accuracy: 0.9922\n",
      "Epoch 562/1000\n",
      "570/570 [==============================] - 0s 812us/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.0223 - val_accuracy: 0.9918\n",
      "Epoch 563/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0286 - val_accuracy: 0.9910\n",
      "Epoch 564/1000\n",
      "570/570 [==============================] - 0s 764us/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.0220 - val_accuracy: 0.9918\n",
      "Epoch 565/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0270 - val_accuracy: 0.9926\n",
      "Epoch 566/1000\n",
      "570/570 [==============================] - 0s 761us/step - loss: 0.0147 - accuracy: 0.9943 - val_loss: 0.0192 - val_accuracy: 0.9939\n",
      "Epoch 567/1000\n",
      "570/570 [==============================] - 0s 759us/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.0216 - val_accuracy: 0.9939\n",
      "Epoch 568/1000\n",
      "570/570 [==============================] - 0s 764us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0252 - val_accuracy: 0.9918\n",
      "Epoch 569/1000\n",
      "570/570 [==============================] - 0s 777us/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0245 - val_accuracy: 0.9935\n",
      "Epoch 570/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.0250 - val_accuracy: 0.9935\n",
      "Epoch 571/1000\n",
      "570/570 [==============================] - 0s 757us/step - loss: 0.0105 - accuracy: 0.9961 - val_loss: 0.0217 - val_accuracy: 0.9914\n",
      "Epoch 572/1000\n",
      "570/570 [==============================] - 0s 763us/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.0215 - val_accuracy: 0.9939\n",
      "Epoch 573/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0239 - val_accuracy: 0.9930\n",
      "Epoch 574/1000\n",
      "570/570 [==============================] - 0s 760us/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.0201 - val_accuracy: 0.9918\n",
      "Epoch 575/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0230 - val_accuracy: 0.9935\n",
      "Epoch 576/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.0234 - val_accuracy: 0.9926\n",
      "Epoch 577/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0084 - accuracy: 0.9964 - val_loss: 0.0272 - val_accuracy: 0.9922\n",
      "Epoch 578/1000\n",
      "570/570 [==============================] - 0s 761us/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0241 - val_accuracy: 0.9930\n",
      "Epoch 579/1000\n",
      "570/570 [==============================] - 0s 766us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0268 - val_accuracy: 0.9922\n",
      "Epoch 580/1000\n",
      "570/570 [==============================] - 0s 792us/step - loss: 0.0115 - accuracy: 0.9950 - val_loss: 0.0218 - val_accuracy: 0.9939\n",
      "Epoch 581/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0222 - val_accuracy: 0.9922\n",
      "Epoch 582/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.0227 - val_accuracy: 0.9935\n",
      "Epoch 583/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0208 - val_accuracy: 0.9926\n",
      "Epoch 584/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0262 - val_accuracy: 0.9910\n",
      "Epoch 585/1000\n",
      "570/570 [==============================] - 0s 762us/step - loss: 0.0106 - accuracy: 0.9953 - val_loss: 0.0244 - val_accuracy: 0.9930\n",
      "Epoch 586/1000\n",
      "570/570 [==============================] - 0s 761us/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.0203 - val_accuracy: 0.9930\n",
      "Epoch 587/1000\n",
      "570/570 [==============================] - 0s 793us/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0247 - val_accuracy: 0.9926\n",
      "Epoch 588/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0264 - val_accuracy: 0.9926\n",
      "Epoch 589/1000\n",
      "570/570 [==============================] - 0s 796us/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.0237 - val_accuracy: 0.9930\n",
      "Epoch 590/1000\n",
      "570/570 [==============================] - 0s 788us/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.0236 - val_accuracy: 0.9930\n",
      "Epoch 591/1000\n",
      "570/570 [==============================] - 0s 820us/step - loss: 0.0151 - accuracy: 0.9941 - val_loss: 0.0278 - val_accuracy: 0.9918\n",
      "Epoch 592/1000\n",
      "570/570 [==============================] - 0s 853us/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.0224 - val_accuracy: 0.9935\n",
      "Epoch 593/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0195 - val_accuracy: 0.9943\n",
      "Epoch 594/1000\n",
      "570/570 [==============================] - 1s 918us/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.0247 - val_accuracy: 0.9939\n",
      "Epoch 595/1000\n",
      "570/570 [==============================] - 1s 959us/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.0218 - val_accuracy: 0.9939\n",
      "Epoch 596/1000\n",
      "570/570 [==============================] - 1s 941us/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.0233 - val_accuracy: 0.9918\n",
      "Epoch 597/1000\n",
      "570/570 [==============================] - 1s 932us/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.0205 - val_accuracy: 0.9935\n",
      "Epoch 598/1000\n",
      "570/570 [==============================] - 1s 978us/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0261 - val_accuracy: 0.9926\n",
      "Epoch 599/1000\n",
      "570/570 [==============================] - 0s 848us/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0233 - val_accuracy: 0.9935\n",
      "Epoch 600/1000\n",
      "570/570 [==============================] - 0s 813us/step - loss: 0.0141 - accuracy: 0.9933 - val_loss: 0.0241 - val_accuracy: 0.9935\n",
      "Epoch 601/1000\n",
      "570/570 [==============================] - 0s 871us/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0289 - val_accuracy: 0.9930\n",
      "Epoch 602/1000\n",
      "570/570 [==============================] - 1s 880us/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0255 - val_accuracy: 0.9922\n",
      "Epoch 603/1000\n",
      "570/570 [==============================] - 1s 916us/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.0232 - val_accuracy: 0.9926\n",
      "Epoch 604/1000\n",
      "570/570 [==============================] - 1s 939us/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.0212 - val_accuracy: 0.9939\n",
      "Epoch 605/1000\n",
      "570/570 [==============================] - 1s 968us/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.0227 - val_accuracy: 0.9939\n",
      "Epoch 606/1000\n",
      "570/570 [==============================] - 1s 928us/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0231 - val_accuracy: 0.9930\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 798us/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.0275 - val_accuracy: 0.9918\n",
      "Epoch 608/1000\n",
      "570/570 [==============================] - 0s 788us/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.0230 - val_accuracy: 0.9943\n",
      "Epoch 609/1000\n",
      "570/570 [==============================] - 0s 760us/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.0231 - val_accuracy: 0.9926\n",
      "Epoch 610/1000\n",
      "570/570 [==============================] - 1s 958us/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0243 - val_accuracy: 0.9939\n",
      "Epoch 611/1000\n",
      "570/570 [==============================] - 0s 824us/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0227 - val_accuracy: 0.9943\n",
      "Epoch 612/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0204 - val_accuracy: 0.9926\n",
      "Epoch 613/1000\n",
      "570/570 [==============================] - 0s 874us/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0253 - val_accuracy: 0.9935\n",
      "Epoch 614/1000\n",
      "570/570 [==============================] - 1s 890us/step - loss: 0.0095 - accuracy: 0.9960 - val_loss: 0.0242 - val_accuracy: 0.9922\n",
      "Epoch 615/1000\n",
      "570/570 [==============================] - 0s 860us/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.0213 - val_accuracy: 0.9935\n",
      "Epoch 616/1000\n",
      "570/570 [==============================] - 1s 880us/step - loss: 0.0114 - accuracy: 0.9948 - val_loss: 0.0237 - val_accuracy: 0.9922\n",
      "Epoch 617/1000\n",
      "570/570 [==============================] - 0s 799us/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0208 - val_accuracy: 0.9939\n",
      "Epoch 618/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0270 - val_accuracy: 0.9935\n",
      "Epoch 619/1000\n",
      "570/570 [==============================] - 0s 766us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0215 - val_accuracy: 0.9930\n",
      "Epoch 620/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0102 - accuracy: 0.9953 - val_loss: 0.0190 - val_accuracy: 0.9930\n",
      "Epoch 621/1000\n",
      "570/570 [==============================] - 1s 896us/step - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.0222 - val_accuracy: 0.9926\n",
      "Epoch 622/1000\n",
      "570/570 [==============================] - 1s 899us/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.0251 - val_accuracy: 0.9930\n",
      "Epoch 623/1000\n",
      "570/570 [==============================] - 0s 824us/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.0235 - val_accuracy: 0.9910\n",
      "Epoch 624/1000\n",
      "570/570 [==============================] - 0s 782us/step - loss: 0.0092 - accuracy: 0.9957 - val_loss: 0.0226 - val_accuracy: 0.9935\n",
      "Epoch 625/1000\n",
      "570/570 [==============================] - 0s 796us/step - loss: 0.0149 - accuracy: 0.9943 - val_loss: 0.0246 - val_accuracy: 0.9918\n",
      "Epoch 626/1000\n",
      "570/570 [==============================] - 0s 825us/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.0217 - val_accuracy: 0.9910\n",
      "Epoch 627/1000\n",
      "570/570 [==============================] - 0s 837us/step - loss: 0.0101 - accuracy: 0.9959 - val_loss: 0.0244 - val_accuracy: 0.9906\n",
      "Epoch 628/1000\n",
      "570/570 [==============================] - 1s 925us/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0263 - val_accuracy: 0.9935\n",
      "Epoch 629/1000\n",
      "570/570 [==============================] - 0s 782us/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0211 - val_accuracy: 0.9922\n",
      "Epoch 630/1000\n",
      "570/570 [==============================] - 0s 857us/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0208 - val_accuracy: 0.9939\n",
      "Epoch 631/1000\n",
      "570/570 [==============================] - 1s 904us/step - loss: 0.0099 - accuracy: 0.9960 - val_loss: 0.0219 - val_accuracy: 0.9930\n",
      "Epoch 632/1000\n",
      "570/570 [==============================] - 1s 1ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0208 - val_accuracy: 0.9910\n",
      "Epoch 633/1000\n",
      "570/570 [==============================] - 1s 1ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0262 - val_accuracy: 0.9926\n",
      "Epoch 634/1000\n",
      "570/570 [==============================] - 1s 1ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0242 - val_accuracy: 0.9918\n",
      "Epoch 635/1000\n",
      "570/570 [==============================] - 1s 880us/step - loss: 0.0095 - accuracy: 0.9959 - val_loss: 0.0185 - val_accuracy: 0.9947\n",
      "Epoch 636/1000\n",
      "570/570 [==============================] - 0s 844us/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0205 - val_accuracy: 0.9935\n",
      "Epoch 637/1000\n",
      "570/570 [==============================] - 0s 777us/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.0255 - val_accuracy: 0.9935\n",
      "Epoch 638/1000\n",
      "570/570 [==============================] - 0s 778us/step - loss: 0.0079 - accuracy: 0.9967 - val_loss: 0.0244 - val_accuracy: 0.9935\n",
      "Epoch 639/1000\n",
      "570/570 [==============================] - 0s 860us/step - loss: 0.0114 - accuracy: 0.9952 - val_loss: 0.0253 - val_accuracy: 0.9935\n",
      "Epoch 640/1000\n",
      "570/570 [==============================] - 0s 818us/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.0319 - val_accuracy: 0.9910\n",
      "Epoch 641/1000\n",
      "570/570 [==============================] - 0s 803us/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.0293 - val_accuracy: 0.9910\n",
      "Epoch 642/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.0230 - val_accuracy: 0.9926\n",
      "Epoch 643/1000\n",
      "570/570 [==============================] - 0s 790us/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.0232 - val_accuracy: 0.9935\n",
      "Epoch 644/1000\n",
      "570/570 [==============================] - 0s 852us/step - loss: 0.0112 - accuracy: 0.9954 - val_loss: 0.0261 - val_accuracy: 0.9918\n",
      "Epoch 645/1000\n",
      "570/570 [==============================] - 0s 796us/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.0227 - val_accuracy: 0.9926\n",
      "Epoch 646/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 0.0229 - val_accuracy: 0.9930\n",
      "Epoch 647/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.0292 - val_accuracy: 0.9914\n",
      "Epoch 648/1000\n",
      "570/570 [==============================] - 0s 774us/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0227 - val_accuracy: 0.9939\n",
      "Epoch 649/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0263 - val_accuracy: 0.9918\n",
      "Epoch 650/1000\n",
      "570/570 [==============================] - 0s 770us/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0235 - val_accuracy: 0.9935\n",
      "Epoch 651/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0072 - accuracy: 0.9968 - val_loss: 0.0282 - val_accuracy: 0.9918\n",
      "Epoch 652/1000\n",
      "570/570 [==============================] - 0s 798us/step - loss: 0.0116 - accuracy: 0.9949 - val_loss: 0.0231 - val_accuracy: 0.9930\n",
      "Epoch 653/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0108 - accuracy: 0.9956 - val_loss: 0.0232 - val_accuracy: 0.9947\n",
      "Epoch 654/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.0223 - val_accuracy: 0.9935\n",
      "Epoch 655/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0246 - val_accuracy: 0.9922\n",
      "Epoch 656/1000\n",
      "570/570 [==============================] - 0s 781us/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.0218 - val_accuracy: 0.9930\n",
      "Epoch 657/1000\n",
      "570/570 [==============================] - 0s 770us/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.0232 - val_accuracy: 0.9935\n",
      "Epoch 658/1000\n",
      "570/570 [==============================] - 0s 769us/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0282 - val_accuracy: 0.9939\n",
      "Epoch 659/1000\n",
      "570/570 [==============================] - 0s 815us/step - loss: 0.0133 - accuracy: 0.9950 - val_loss: 0.0256 - val_accuracy: 0.9926\n",
      "Epoch 660/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0229 - val_accuracy: 0.9930\n",
      "Epoch 661/1000\n",
      "570/570 [==============================] - 0s 819us/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.0250 - val_accuracy: 0.9926\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 806us/step - loss: 0.0099 - accuracy: 0.9955 - val_loss: 0.0298 - val_accuracy: 0.9930\n",
      "Epoch 663/1000\n",
      "570/570 [==============================] - 0s 793us/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0225 - val_accuracy: 0.9939\n",
      "Epoch 664/1000\n",
      "570/570 [==============================] - 0s 797us/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0245 - val_accuracy: 0.9922\n",
      "Epoch 665/1000\n",
      "570/570 [==============================] - 1s 1ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.0274 - val_accuracy: 0.9914\n",
      "Epoch 666/1000\n",
      "570/570 [==============================] - 1s 906us/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0275 - val_accuracy: 0.9926\n",
      "Epoch 667/1000\n",
      "570/570 [==============================] - 0s 774us/step - loss: 0.0113 - accuracy: 0.9955 - val_loss: 0.0267 - val_accuracy: 0.9935\n",
      "Epoch 668/1000\n",
      "570/570 [==============================] - 0s 745us/step - loss: 0.0096 - accuracy: 0.9959 - val_loss: 0.0249 - val_accuracy: 0.9939\n",
      "Epoch 669/1000\n",
      "570/570 [==============================] - 0s 739us/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.0270 - val_accuracy: 0.9922\n",
      "Epoch 670/1000\n",
      "570/570 [==============================] - 0s 751us/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0246 - val_accuracy: 0.9935\n",
      "Epoch 671/1000\n",
      "570/570 [==============================] - 0s 730us/step - loss: 0.0100 - accuracy: 0.9954 - val_loss: 0.0219 - val_accuracy: 0.9914\n",
      "Epoch 672/1000\n",
      "570/570 [==============================] - 0s 749us/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.0245 - val_accuracy: 0.9930\n",
      "Epoch 673/1000\n",
      "570/570 [==============================] - 0s 741us/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.0245 - val_accuracy: 0.9922\n",
      "Epoch 674/1000\n",
      "570/570 [==============================] - 0s 759us/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0246 - val_accuracy: 0.9918\n",
      "Epoch 675/1000\n",
      "570/570 [==============================] - 0s 764us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0226 - val_accuracy: 0.9930\n",
      "Epoch 676/1000\n",
      "570/570 [==============================] - 0s 755us/step - loss: 0.0140 - accuracy: 0.9950 - val_loss: 0.0283 - val_accuracy: 0.9922\n",
      "Epoch 677/1000\n",
      "570/570 [==============================] - 0s 746us/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.0258 - val_accuracy: 0.9943\n",
      "Epoch 678/1000\n",
      "570/570 [==============================] - 0s 747us/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0279 - val_accuracy: 0.9922\n",
      "Epoch 679/1000\n",
      "570/570 [==============================] - 0s 749us/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0278 - val_accuracy: 0.9922\n",
      "Epoch 680/1000\n",
      "570/570 [==============================] - 0s 742us/step - loss: 0.0122 - accuracy: 0.9945 - val_loss: 0.0249 - val_accuracy: 0.9935\n",
      "Epoch 681/1000\n",
      "570/570 [==============================] - 0s 734us/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0262 - val_accuracy: 0.9930\n",
      "Epoch 682/1000\n",
      "570/570 [==============================] - 0s 743us/step - loss: 0.0110 - accuracy: 0.9941 - val_loss: 0.0272 - val_accuracy: 0.9930\n",
      "Epoch 683/1000\n",
      "570/570 [==============================] - 0s 737us/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.0285 - val_accuracy: 0.9930\n",
      "Epoch 684/1000\n",
      "570/570 [==============================] - 0s 753us/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.0254 - val_accuracy: 0.9922\n",
      "Epoch 685/1000\n",
      "570/570 [==============================] - 0s 827us/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0329 - val_accuracy: 0.9902\n",
      "Epoch 686/1000\n",
      "570/570 [==============================] - 0s 738us/step - loss: 0.0101 - accuracy: 0.9962 - val_loss: 0.0270 - val_accuracy: 0.9914\n",
      "Epoch 687/1000\n",
      "570/570 [==============================] - 1s 1ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0302 - val_accuracy: 0.9930\n",
      "Epoch 688/1000\n",
      "570/570 [==============================] - 0s 846us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0285 - val_accuracy: 0.9922\n",
      "Epoch 689/1000\n",
      "570/570 [==============================] - 0s 877us/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.0268 - val_accuracy: 0.9930\n",
      "Epoch 690/1000\n",
      "570/570 [==============================] - 0s 740us/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0305 - val_accuracy: 0.9914\n",
      "Epoch 691/1000\n",
      "570/570 [==============================] - 0s 747us/step - loss: 0.0127 - accuracy: 0.9952 - val_loss: 0.0255 - val_accuracy: 0.9926\n",
      "Epoch 692/1000\n",
      "570/570 [==============================] - 0s 743us/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.0246 - val_accuracy: 0.9939\n",
      "Epoch 693/1000\n",
      "570/570 [==============================] - 0s 733us/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.0266 - val_accuracy: 0.9939\n",
      "Epoch 694/1000\n",
      "570/570 [==============================] - 0s 737us/step - loss: 0.0132 - accuracy: 0.9949 - val_loss: 0.0251 - val_accuracy: 0.9939\n",
      "Epoch 695/1000\n",
      "570/570 [==============================] - 0s 748us/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 0.0266 - val_accuracy: 0.9939\n",
      "Epoch 696/1000\n",
      "570/570 [==============================] - 0s 738us/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.0248 - val_accuracy: 0.9926\n",
      "Epoch 697/1000\n",
      "570/570 [==============================] - 0s 737us/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0239 - val_accuracy: 0.9910\n",
      "Epoch 698/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.0218 - val_accuracy: 0.9930\n",
      "Epoch 699/1000\n",
      "570/570 [==============================] - 0s 754us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.0333 - val_accuracy: 0.9935\n",
      "Epoch 700/1000\n",
      "570/570 [==============================] - 0s 736us/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0238 - val_accuracy: 0.9930\n",
      "Epoch 701/1000\n",
      "570/570 [==============================] - 0s 734us/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.0345 - val_accuracy: 0.9914\n",
      "Epoch 702/1000\n",
      "570/570 [==============================] - 0s 737us/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 0.0328 - val_accuracy: 0.9926\n",
      "Epoch 703/1000\n",
      "570/570 [==============================] - 0s 784us/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9930\n",
      "Epoch 704/1000\n",
      "570/570 [==============================] - 0s 739us/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.0305 - val_accuracy: 0.9935\n",
      "Epoch 705/1000\n",
      "570/570 [==============================] - 0s 758us/step - loss: 0.0116 - accuracy: 0.9955 - val_loss: 0.0286 - val_accuracy: 0.9922\n",
      "Epoch 706/1000\n",
      "570/570 [==============================] - 0s 822us/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0287 - val_accuracy: 0.9914\n",
      "Epoch 707/1000\n",
      "570/570 [==============================] - 0s 830us/step - loss: 0.0116 - accuracy: 0.9955 - val_loss: 0.0246 - val_accuracy: 0.9939\n",
      "Epoch 708/1000\n",
      "570/570 [==============================] - 1s 1ms/step - loss: 0.0120 - accuracy: 0.9953 - val_loss: 0.0251 - val_accuracy: 0.9935\n",
      "Epoch 709/1000\n",
      "570/570 [==============================] - 0s 872us/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0211 - val_accuracy: 0.9926\n",
      "Epoch 710/1000\n",
      "570/570 [==============================] - 1s 1ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0240 - val_accuracy: 0.9935\n",
      "Epoch 711/1000\n",
      "570/570 [==============================] - 1s 885us/step - loss: 0.0129 - accuracy: 0.9934 - val_loss: 0.0291 - val_accuracy: 0.9918\n",
      "Epoch 712/1000\n",
      "570/570 [==============================] - 0s 861us/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0249 - val_accuracy: 0.9918\n",
      "Epoch 713/1000\n",
      "570/570 [==============================] - 0s 845us/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0258 - val_accuracy: 0.9930\n",
      "Epoch 714/1000\n",
      "570/570 [==============================] - 0s 851us/step - loss: 0.0097 - accuracy: 0.9960 - val_loss: 0.0192 - val_accuracy: 0.9943\n",
      "Epoch 715/1000\n",
      "570/570 [==============================] - 1s 975us/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.0254 - val_accuracy: 0.9914\n",
      "Epoch 716/1000\n",
      "570/570 [==============================] - 1s 935us/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 0.0308 - val_accuracy: 0.9918\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 819us/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.0298 - val_accuracy: 0.9922\n",
      "Epoch 718/1000\n",
      "570/570 [==============================] - 0s 856us/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0313 - val_accuracy: 0.9935\n",
      "Epoch 719/1000\n",
      "570/570 [==============================] - 0s 844us/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0413 - val_accuracy: 0.9894\n",
      "Epoch 720/1000\n",
      "570/570 [==============================] - 0s 860us/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0289 - val_accuracy: 0.9914\n",
      "Epoch 721/1000\n",
      "570/570 [==============================] - 0s 872us/step - loss: 0.0126 - accuracy: 0.9944 - val_loss: 0.0231 - val_accuracy: 0.9935\n",
      "Epoch 722/1000\n",
      "570/570 [==============================] - 0s 841us/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 0.0250 - val_accuracy: 0.9939\n",
      "Epoch 723/1000\n",
      "570/570 [==============================] - 0s 811us/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0294 - val_accuracy: 0.9935\n",
      "Epoch 724/1000\n",
      "570/570 [==============================] - 0s 810us/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.0279 - val_accuracy: 0.9926\n",
      "Epoch 725/1000\n",
      "570/570 [==============================] - 0s 834us/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0337 - val_accuracy: 0.9922\n",
      "Epoch 726/1000\n",
      "570/570 [==============================] - 0s 820us/step - loss: 0.0113 - accuracy: 0.9952 - val_loss: 0.0258 - val_accuracy: 0.9930\n",
      "Epoch 727/1000\n",
      "570/570 [==============================] - 0s 777us/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0296 - val_accuracy: 0.9906\n",
      "Epoch 728/1000\n",
      "570/570 [==============================] - 0s 747us/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0290 - val_accuracy: 0.9922\n",
      "Epoch 729/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0126 - accuracy: 0.9949 - val_loss: 0.0321 - val_accuracy: 0.9914\n",
      "Epoch 730/1000\n",
      "570/570 [==============================] - 0s 874us/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.0286 - val_accuracy: 0.9930\n",
      "Epoch 731/1000\n",
      "570/570 [==============================] - 1s 878us/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.0260 - val_accuracy: 0.9926\n",
      "Epoch 732/1000\n",
      "570/570 [==============================] - 0s 845us/step - loss: 0.0084 - accuracy: 0.9966 - val_loss: 0.0235 - val_accuracy: 0.9914\n",
      "Epoch 733/1000\n",
      "570/570 [==============================] - 0s 849us/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.0210 - val_accuracy: 0.9939\n",
      "Epoch 734/1000\n",
      "570/570 [==============================] - 0s 815us/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.0260 - val_accuracy: 0.9943\n",
      "Epoch 735/1000\n",
      "570/570 [==============================] - 0s 825us/step - loss: 0.0105 - accuracy: 0.9955 - val_loss: 0.0221 - val_accuracy: 0.9951\n",
      "Epoch 736/1000\n",
      "570/570 [==============================] - 0s 829us/step - loss: 0.0106 - accuracy: 0.9954 - val_loss: 0.0239 - val_accuracy: 0.9914\n",
      "Epoch 737/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.0231 - val_accuracy: 0.9926\n",
      "Epoch 738/1000\n",
      "570/570 [==============================] - 0s 823us/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0261 - val_accuracy: 0.9922\n",
      "Epoch 739/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0241 - val_accuracy: 0.9939\n",
      "Epoch 740/1000\n",
      "570/570 [==============================] - 0s 798us/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0212 - val_accuracy: 0.9935\n",
      "Epoch 741/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.0250 - val_accuracy: 0.9926\n",
      "Epoch 742/1000\n",
      "570/570 [==============================] - 0s 757us/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0219 - val_accuracy: 0.9935\n",
      "Epoch 743/1000\n",
      "570/570 [==============================] - 1s 962us/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0191 - val_accuracy: 0.9939\n",
      "Epoch 744/1000\n",
      "570/570 [==============================] - 0s 814us/step - loss: 0.0117 - accuracy: 0.9948 - val_loss: 0.0249 - val_accuracy: 0.9914\n",
      "Epoch 745/1000\n",
      "570/570 [==============================] - 0s 783us/step - loss: 0.0119 - accuracy: 0.9955 - val_loss: 0.0220 - val_accuracy: 0.9939\n",
      "Epoch 746/1000\n",
      "570/570 [==============================] - 0s 874us/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0238 - val_accuracy: 0.9943\n",
      "Epoch 747/1000\n",
      "570/570 [==============================] - 0s 781us/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0256 - val_accuracy: 0.9930\n",
      "Epoch 748/1000\n",
      "570/570 [==============================] - 0s 782us/step - loss: 0.0103 - accuracy: 0.9949 - val_loss: 0.0296 - val_accuracy: 0.9926\n",
      "Epoch 749/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0183 - accuracy: 0.9967 - val_loss: 0.0204 - val_accuracy: 0.9922\n",
      "Epoch 750/1000\n",
      "570/570 [==============================] - 0s 770us/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0260 - val_accuracy: 0.9935\n",
      "Epoch 751/1000\n",
      "570/570 [==============================] - 0s 797us/step - loss: 0.0121 - accuracy: 0.9945 - val_loss: 0.0295 - val_accuracy: 0.9914\n",
      "Epoch 752/1000\n",
      "570/570 [==============================] - 0s 758us/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0232 - val_accuracy: 0.9926\n",
      "Epoch 753/1000\n",
      "570/570 [==============================] - 0s 781us/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.0232 - val_accuracy: 0.9926\n",
      "Epoch 754/1000\n",
      "570/570 [==============================] - 0s 790us/step - loss: 0.0095 - accuracy: 0.9957 - val_loss: 0.0339 - val_accuracy: 0.9930\n",
      "Epoch 755/1000\n",
      "570/570 [==============================] - 0s 763us/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0231 - val_accuracy: 0.9918\n",
      "Epoch 756/1000\n",
      "570/570 [==============================] - 0s 793us/step - loss: 0.0096 - accuracy: 0.9959 - val_loss: 0.0235 - val_accuracy: 0.9947\n",
      "Epoch 757/1000\n",
      "570/570 [==============================] - 0s 736us/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0247 - val_accuracy: 0.9922\n",
      "Epoch 758/1000\n",
      "570/570 [==============================] - 0s 733us/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.0308 - val_accuracy: 0.9902\n",
      "Epoch 759/1000\n",
      "570/570 [==============================] - 0s 743us/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.9930\n",
      "Epoch 760/1000\n",
      "570/570 [==============================] - 0s 736us/step - loss: 0.0111 - accuracy: 0.9952 - val_loss: 0.0264 - val_accuracy: 0.9939\n",
      "Epoch 761/1000\n",
      "570/570 [==============================] - 0s 736us/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.0290 - val_accuracy: 0.9935\n",
      "Epoch 762/1000\n",
      "570/570 [==============================] - 0s 742us/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.0219 - val_accuracy: 0.9939\n",
      "Epoch 763/1000\n",
      "570/570 [==============================] - 0s 747us/step - loss: 0.0129 - accuracy: 0.9950 - val_loss: 0.0286 - val_accuracy: 0.9943\n",
      "Epoch 764/1000\n",
      "570/570 [==============================] - 0s 787us/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0334 - val_accuracy: 0.9926\n",
      "Epoch 765/1000\n",
      "570/570 [==============================] - 0s 760us/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.0290 - val_accuracy: 0.9939\n",
      "Epoch 766/1000\n",
      "570/570 [==============================] - 0s 757us/step - loss: 0.0096 - accuracy: 0.9960 - val_loss: 0.0261 - val_accuracy: 0.9935\n",
      "Epoch 767/1000\n",
      "570/570 [==============================] - 0s 755us/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.0342 - val_accuracy: 0.9918\n",
      "Epoch 768/1000\n",
      "570/570 [==============================] - 0s 756us/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.0310 - val_accuracy: 0.9930\n",
      "Epoch 769/1000\n",
      "570/570 [==============================] - 0s 774us/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0315 - val_accuracy: 0.9930\n",
      "Epoch 770/1000\n",
      "570/570 [==============================] - 0s 758us/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.0293 - val_accuracy: 0.9918\n",
      "Epoch 771/1000\n",
      "570/570 [==============================] - 0s 761us/step - loss: 0.0110 - accuracy: 0.9955 - val_loss: 0.0272 - val_accuracy: 0.9939\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 754us/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.0371 - val_accuracy: 0.9926\n",
      "Epoch 773/1000\n",
      "570/570 [==============================] - 0s 786us/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0244 - val_accuracy: 0.9922\n",
      "Epoch 774/1000\n",
      "570/570 [==============================] - 0s 786us/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0272 - val_accuracy: 0.9943\n",
      "Epoch 775/1000\n",
      "570/570 [==============================] - 0s 763us/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0318 - val_accuracy: 0.9910\n",
      "Epoch 776/1000\n",
      "570/570 [==============================] - 0s 766us/step - loss: 0.0128 - accuracy: 0.9943 - val_loss: 0.0261 - val_accuracy: 0.9922\n",
      "Epoch 777/1000\n",
      "570/570 [==============================] - 0s 754us/step - loss: 0.0092 - accuracy: 0.9966 - val_loss: 0.0275 - val_accuracy: 0.9918\n",
      "Epoch 778/1000\n",
      "570/570 [==============================] - 0s 803us/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0331 - val_accuracy: 0.9922\n",
      "Epoch 779/1000\n",
      "570/570 [==============================] - 0s 759us/step - loss: 0.0154 - accuracy: 0.9940 - val_loss: 0.0336 - val_accuracy: 0.9922\n",
      "Epoch 780/1000\n",
      "570/570 [==============================] - 0s 740us/step - loss: 0.0093 - accuracy: 0.9955 - val_loss: 0.0354 - val_accuracy: 0.9922\n",
      "Epoch 781/1000\n",
      "570/570 [==============================] - 0s 771us/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.0300 - val_accuracy: 0.9922\n",
      "Epoch 782/1000\n",
      "570/570 [==============================] - 0s 762us/step - loss: 0.0111 - accuracy: 0.9953 - val_loss: 0.0317 - val_accuracy: 0.9935\n",
      "Epoch 783/1000\n",
      "570/570 [==============================] - 0s 800us/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.0259 - val_accuracy: 0.9943\n",
      "Epoch 784/1000\n",
      "570/570 [==============================] - 0s 793us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0228 - val_accuracy: 0.9930\n",
      "Epoch 785/1000\n",
      "570/570 [==============================] - 0s 788us/step - loss: 0.0107 - accuracy: 0.9954 - val_loss: 0.0310 - val_accuracy: 0.9922\n",
      "Epoch 786/1000\n",
      "570/570 [==============================] - 0s 757us/step - loss: 0.0092 - accuracy: 0.9960 - val_loss: 0.0281 - val_accuracy: 0.9922\n",
      "Epoch 787/1000\n",
      "570/570 [==============================] - 0s 809us/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0232 - val_accuracy: 0.9930\n",
      "Epoch 788/1000\n",
      "570/570 [==============================] - 0s 815us/step - loss: 0.0133 - accuracy: 0.9948 - val_loss: 0.0320 - val_accuracy: 0.9918\n",
      "Epoch 789/1000\n",
      "570/570 [==============================] - 0s 819us/step - loss: 0.0113 - accuracy: 0.9946 - val_loss: 0.0253 - val_accuracy: 0.9939\n",
      "Epoch 790/1000\n",
      "570/570 [==============================] - 0s 841us/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0369 - val_accuracy: 0.9918\n",
      "Epoch 791/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0293 - val_accuracy: 0.9906\n",
      "Epoch 792/1000\n",
      "570/570 [==============================] - 0s 794us/step - loss: 0.0120 - accuracy: 0.9953 - val_loss: 0.0244 - val_accuracy: 0.9930\n",
      "Epoch 793/1000\n",
      "570/570 [==============================] - 0s 789us/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0342 - val_accuracy: 0.9922\n",
      "Epoch 794/1000\n",
      "570/570 [==============================] - 0s 783us/step - loss: 0.0097 - accuracy: 0.9956 - val_loss: 0.0336 - val_accuracy: 0.9926\n",
      "Epoch 795/1000\n",
      "570/570 [==============================] - 0s 794us/step - loss: 0.0105 - accuracy: 0.9955 - val_loss: 0.0313 - val_accuracy: 0.9930\n",
      "Epoch 796/1000\n",
      "570/570 [==============================] - 0s 831us/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 0.0293 - val_accuracy: 0.9930\n",
      "Epoch 797/1000\n",
      "570/570 [==============================] - 0s 864us/step - loss: 0.0095 - accuracy: 0.9959 - val_loss: 0.0305 - val_accuracy: 0.9918\n",
      "Epoch 798/1000\n",
      "570/570 [==============================] - 0s 840us/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.0286 - val_accuracy: 0.9930\n",
      "Epoch 799/1000\n",
      "570/570 [==============================] - 0s 779us/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 0.0337 - val_accuracy: 0.9926\n",
      "Epoch 800/1000\n",
      "570/570 [==============================] - 0s 759us/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0322 - val_accuracy: 0.9922\n",
      "Epoch 801/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0224 - val_accuracy: 0.9943\n",
      "Epoch 802/1000\n",
      "570/570 [==============================] - 0s 757us/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0204 - val_accuracy: 0.9935\n",
      "Epoch 803/1000\n",
      "570/570 [==============================] - 0s 756us/step - loss: 0.0140 - accuracy: 0.9948 - val_loss: 0.0223 - val_accuracy: 0.9951\n",
      "Epoch 804/1000\n",
      "570/570 [==============================] - 0s 759us/step - loss: 0.0082 - accuracy: 0.9967 - val_loss: 0.0216 - val_accuracy: 0.9935\n",
      "Epoch 805/1000\n",
      "570/570 [==============================] - 0s 753us/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0295 - val_accuracy: 0.9935\n",
      "Epoch 806/1000\n",
      "570/570 [==============================] - 0s 760us/step - loss: 0.0101 - accuracy: 0.9951 - val_loss: 0.0275 - val_accuracy: 0.9935\n",
      "Epoch 807/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 0.0285 - val_accuracy: 0.9930\n",
      "Epoch 808/1000\n",
      "570/570 [==============================] - 0s 806us/step - loss: 0.0070 - accuracy: 0.9966 - val_loss: 0.0285 - val_accuracy: 0.9926\n",
      "Epoch 809/1000\n",
      "570/570 [==============================] - 0s 790us/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.0328 - val_accuracy: 0.9922\n",
      "Epoch 810/1000\n",
      "570/570 [==============================] - 0s 838us/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.0300 - val_accuracy: 0.9906\n",
      "Epoch 811/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0269 - val_accuracy: 0.9926\n",
      "Epoch 812/1000\n",
      "570/570 [==============================] - 0s 795us/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.0256 - val_accuracy: 0.9943\n",
      "Epoch 813/1000\n",
      "570/570 [==============================] - 0s 784us/step - loss: 0.0094 - accuracy: 0.9961 - val_loss: 0.0272 - val_accuracy: 0.9930\n",
      "Epoch 814/1000\n",
      "570/570 [==============================] - 0s 757us/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.0236 - val_accuracy: 0.9943\n",
      "Epoch 815/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.0249 - val_accuracy: 0.9935\n",
      "Epoch 816/1000\n",
      "570/570 [==============================] - 1s 898us/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.0194 - val_accuracy: 0.9955\n",
      "Epoch 817/1000\n",
      "570/570 [==============================] - 0s 849us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0276 - val_accuracy: 0.9939\n",
      "Epoch 818/1000\n",
      "570/570 [==============================] - 1s 921us/step - loss: 0.0087 - accuracy: 0.9966 - val_loss: 0.0258 - val_accuracy: 0.9935\n",
      "Epoch 819/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0098 - accuracy: 0.9961 - val_loss: 0.0269 - val_accuracy: 0.9930\n",
      "Epoch 820/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0111 - accuracy: 0.9950 - val_loss: 0.0274 - val_accuracy: 0.9943\n",
      "Epoch 821/1000\n",
      "570/570 [==============================] - 0s 774us/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0269 - val_accuracy: 0.9935\n",
      "Epoch 822/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.0255 - val_accuracy: 0.9926\n",
      "Epoch 823/1000\n",
      "570/570 [==============================] - 0s 758us/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.0282 - val_accuracy: 0.9935\n",
      "Epoch 824/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0096 - accuracy: 0.9959 - val_loss: 0.0257 - val_accuracy: 0.9935\n",
      "Epoch 825/1000\n",
      "570/570 [==============================] - 0s 756us/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.0272 - val_accuracy: 0.9926\n",
      "Epoch 826/1000\n",
      "570/570 [==============================] - 0s 794us/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.0305 - val_accuracy: 0.9922\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 786us/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.0299 - val_accuracy: 0.9935\n",
      "Epoch 828/1000\n",
      "570/570 [==============================] - 0s 835us/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0324 - val_accuracy: 0.9926\n",
      "Epoch 829/1000\n",
      "570/570 [==============================] - 0s 815us/step - loss: 0.0103 - accuracy: 0.9954 - val_loss: 0.0262 - val_accuracy: 0.9935\n",
      "Epoch 830/1000\n",
      "570/570 [==============================] - 0s 777us/step - loss: 0.0085 - accuracy: 0.9964 - val_loss: 0.0297 - val_accuracy: 0.9918\n",
      "Epoch 831/1000\n",
      "570/570 [==============================] - 0s 788us/step - loss: 0.0125 - accuracy: 0.9929 - val_loss: 0.0273 - val_accuracy: 0.9930\n",
      "Epoch 832/1000\n",
      "570/570 [==============================] - 0s 809us/step - loss: 0.0094 - accuracy: 0.9962 - val_loss: 0.0281 - val_accuracy: 0.9918\n",
      "Epoch 833/1000\n",
      "570/570 [==============================] - 0s 787us/step - loss: 0.0119 - accuracy: 0.9947 - val_loss: 0.0235 - val_accuracy: 0.9935\n",
      "Epoch 834/1000\n",
      "570/570 [==============================] - 0s 806us/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0277 - val_accuracy: 0.9935\n",
      "Epoch 835/1000\n",
      "570/570 [==============================] - 0s 822us/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.0288 - val_accuracy: 0.9918\n",
      "Epoch 836/1000\n",
      "570/570 [==============================] - 0s 814us/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.0263 - val_accuracy: 0.9939\n",
      "Epoch 837/1000\n",
      "570/570 [==============================] - 0s 788us/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 0.0193 - val_accuracy: 0.9922\n",
      "Epoch 838/1000\n",
      "570/570 [==============================] - 0s 817us/step - loss: 0.0094 - accuracy: 0.9950 - val_loss: 0.0212 - val_accuracy: 0.9939\n",
      "Epoch 839/1000\n",
      "570/570 [==============================] - 0s 831us/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.0340 - val_accuracy: 0.9914\n",
      "Epoch 840/1000\n",
      "570/570 [==============================] - 0s 766us/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0346 - val_accuracy: 0.9918\n",
      "Epoch 841/1000\n",
      "570/570 [==============================] - 0s 760us/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0302 - val_accuracy: 0.9939\n",
      "Epoch 842/1000\n",
      "570/570 [==============================] - 0s 809us/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0275 - val_accuracy: 0.9935\n",
      "Epoch 843/1000\n",
      "570/570 [==============================] - 0s 836us/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0328 - val_accuracy: 0.9930\n",
      "Epoch 844/1000\n",
      "570/570 [==============================] - 0s 811us/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.0338 - val_accuracy: 0.9926\n",
      "Epoch 845/1000\n",
      "570/570 [==============================] - 0s 858us/step - loss: 0.0117 - accuracy: 0.9946 - val_loss: 0.0350 - val_accuracy: 0.9930\n",
      "Epoch 846/1000\n",
      "570/570 [==============================] - 0s 842us/step - loss: 0.0089 - accuracy: 0.9959 - val_loss: 0.0302 - val_accuracy: 0.9930\n",
      "Epoch 847/1000\n",
      "570/570 [==============================] - 0s 773us/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 0.0299 - val_accuracy: 0.9926\n",
      "Epoch 848/1000\n",
      "570/570 [==============================] - 0s 832us/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.0356 - val_accuracy: 0.9935\n",
      "Epoch 849/1000\n",
      "570/570 [==============================] - 0s 789us/step - loss: 0.0132 - accuracy: 0.9941 - val_loss: 0.0296 - val_accuracy: 0.9939\n",
      "Epoch 850/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0320 - val_accuracy: 0.9935\n",
      "Epoch 851/1000\n",
      "570/570 [==============================] - 0s 789us/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0263 - val_accuracy: 0.9939\n",
      "Epoch 852/1000\n",
      "570/570 [==============================] - 1s 944us/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.0325 - val_accuracy: 0.9922\n",
      "Epoch 853/1000\n",
      "570/570 [==============================] - 0s 831us/step - loss: 0.0118 - accuracy: 0.9955 - val_loss: 0.0342 - val_accuracy: 0.9930\n",
      "Epoch 854/1000\n",
      "570/570 [==============================] - 0s 778us/step - loss: 0.0103 - accuracy: 0.9960 - val_loss: 0.0366 - val_accuracy: 0.9914\n",
      "Epoch 855/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.0304 - val_accuracy: 0.9922\n",
      "Epoch 856/1000\n",
      "570/570 [==============================] - 0s 753us/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 0.0359 - val_accuracy: 0.9918\n",
      "Epoch 857/1000\n",
      "570/570 [==============================] - 0s 738us/step - loss: 0.0095 - accuracy: 0.9958 - val_loss: 0.0379 - val_accuracy: 0.9926\n",
      "Epoch 858/1000\n",
      "570/570 [==============================] - 0s 740us/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.0286 - val_accuracy: 0.9914\n",
      "Epoch 859/1000\n",
      "570/570 [==============================] - 0s 745us/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 0.0334 - val_accuracy: 0.9935\n",
      "Epoch 860/1000\n",
      "570/570 [==============================] - 0s 737us/step - loss: 0.0115 - accuracy: 0.9948 - val_loss: 0.0335 - val_accuracy: 0.9922\n",
      "Epoch 861/1000\n",
      "570/570 [==============================] - 0s 740us/step - loss: 0.0096 - accuracy: 0.9960 - val_loss: 0.0395 - val_accuracy: 0.9918\n",
      "Epoch 862/1000\n",
      "570/570 [==============================] - 0s 734us/step - loss: 0.0104 - accuracy: 0.9954 - val_loss: 0.0296 - val_accuracy: 0.9926\n",
      "Epoch 863/1000\n",
      "570/570 [==============================] - 0s 734us/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0363 - val_accuracy: 0.9926\n",
      "Epoch 864/1000\n",
      "570/570 [==============================] - 0s 746us/step - loss: 0.0099 - accuracy: 0.9958 - val_loss: 0.0320 - val_accuracy: 0.9930\n",
      "Epoch 865/1000\n",
      "570/570 [==============================] - 0s 737us/step - loss: 0.0113 - accuracy: 0.9952 - val_loss: 0.0357 - val_accuracy: 0.9930\n",
      "Epoch 866/1000\n",
      "570/570 [==============================] - 0s 734us/step - loss: 0.0107 - accuracy: 0.9954 - val_loss: 0.0318 - val_accuracy: 0.9926\n",
      "Epoch 867/1000\n",
      "570/570 [==============================] - 0s 737us/step - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.0307 - val_accuracy: 0.9930\n",
      "Epoch 868/1000\n",
      "570/570 [==============================] - 0s 733us/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0245 - val_accuracy: 0.9951\n",
      "Epoch 869/1000\n",
      "570/570 [==============================] - 0s 736us/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0296 - val_accuracy: 0.9926\n",
      "Epoch 870/1000\n",
      "570/570 [==============================] - 0s 738us/step - loss: 0.0078 - accuracy: 0.9965 - val_loss: 0.0323 - val_accuracy: 0.9930\n",
      "Epoch 871/1000\n",
      "570/570 [==============================] - 0s 737us/step - loss: 0.0108 - accuracy: 0.9955 - val_loss: 0.0300 - val_accuracy: 0.9935\n",
      "Epoch 872/1000\n",
      "570/570 [==============================] - 0s 738us/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.0297 - val_accuracy: 0.9914\n",
      "Epoch 873/1000\n",
      "570/570 [==============================] - 0s 735us/step - loss: 0.0096 - accuracy: 0.9959 - val_loss: 0.0255 - val_accuracy: 0.9935\n",
      "Epoch 874/1000\n",
      "570/570 [==============================] - 0s 738us/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0362 - val_accuracy: 0.9902\n",
      "Epoch 875/1000\n",
      "570/570 [==============================] - 0s 745us/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0358 - val_accuracy: 0.9930\n",
      "Epoch 876/1000\n",
      "570/570 [==============================] - 0s 782us/step - loss: 0.0098 - accuracy: 0.9958 - val_loss: 0.0353 - val_accuracy: 0.9939\n",
      "Epoch 877/1000\n",
      "570/570 [==============================] - 0s 782us/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0274 - val_accuracy: 0.9935\n",
      "Epoch 878/1000\n",
      "570/570 [==============================] - 0s 756us/step - loss: 0.0106 - accuracy: 0.9948 - val_loss: 0.0304 - val_accuracy: 0.9922\n",
      "Epoch 879/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0266 - val_accuracy: 0.9943\n",
      "Epoch 880/1000\n",
      "570/570 [==============================] - 0s 791us/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0274 - val_accuracy: 0.9943\n",
      "Epoch 881/1000\n",
      "570/570 [==============================] - 0s 741us/step - loss: 0.0106 - accuracy: 0.9960 - val_loss: 0.0258 - val_accuracy: 0.9922\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 777us/step - loss: 0.0087 - accuracy: 0.9967 - val_loss: 0.0341 - val_accuracy: 0.9926\n",
      "Epoch 883/1000\n",
      "570/570 [==============================] - 0s 868us/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0289 - val_accuracy: 0.9935\n",
      "Epoch 884/1000\n",
      "570/570 [==============================] - 0s 817us/step - loss: 0.0101 - accuracy: 0.9958 - val_loss: 0.0369 - val_accuracy: 0.9930\n",
      "Epoch 885/1000\n",
      "570/570 [==============================] - 0s 838us/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.0240 - val_accuracy: 0.9947\n",
      "Epoch 886/1000\n",
      "570/570 [==============================] - 0s 818us/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.0283 - val_accuracy: 0.9930\n",
      "Epoch 887/1000\n",
      "570/570 [==============================] - 0s 812us/step - loss: 0.0098 - accuracy: 0.9961 - val_loss: 0.0308 - val_accuracy: 0.9935\n",
      "Epoch 888/1000\n",
      "570/570 [==============================] - 0s 777us/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0255 - val_accuracy: 0.9939\n",
      "Epoch 889/1000\n",
      "570/570 [==============================] - 0s 802us/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 0.0289 - val_accuracy: 0.9935\n",
      "Epoch 890/1000\n",
      "570/570 [==============================] - 0s 796us/step - loss: 0.0095 - accuracy: 0.9954 - val_loss: 0.0284 - val_accuracy: 0.9918\n",
      "Epoch 891/1000\n",
      "570/570 [==============================] - 0s 818us/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.0302 - val_accuracy: 0.9926\n",
      "Epoch 892/1000\n",
      "570/570 [==============================] - 0s 795us/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0292 - val_accuracy: 0.9926\n",
      "Epoch 893/1000\n",
      "570/570 [==============================] - 0s 758us/step - loss: 0.0130 - accuracy: 0.9952 - val_loss: 0.0318 - val_accuracy: 0.9935\n",
      "Epoch 894/1000\n",
      "570/570 [==============================] - 0s 753us/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0368 - val_accuracy: 0.9930\n",
      "Epoch 895/1000\n",
      "570/570 [==============================] - 0s 752us/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0268 - val_accuracy: 0.9926\n",
      "Epoch 896/1000\n",
      "570/570 [==============================] - 0s 755us/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.0337 - val_accuracy: 0.9939\n",
      "Epoch 897/1000\n",
      "570/570 [==============================] - 0s 798us/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.0382 - val_accuracy: 0.9943\n",
      "Epoch 898/1000\n",
      "570/570 [==============================] - 0s 801us/step - loss: 0.0086 - accuracy: 0.9965 - val_loss: 0.0359 - val_accuracy: 0.9935\n",
      "Epoch 899/1000\n",
      "570/570 [==============================] - 0s 775us/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.0375 - val_accuracy: 0.9935\n",
      "Epoch 900/1000\n",
      "570/570 [==============================] - 0s 800us/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0408 - val_accuracy: 0.9922\n",
      "Epoch 901/1000\n",
      "570/570 [==============================] - 0s 822us/step - loss: 0.0102 - accuracy: 0.9960 - val_loss: 0.0416 - val_accuracy: 0.9935\n",
      "Epoch 902/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.0392 - val_accuracy: 0.9922\n",
      "Epoch 903/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0117 - accuracy: 0.9947 - val_loss: 0.0343 - val_accuracy: 0.9935\n",
      "Epoch 904/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0342 - val_accuracy: 0.9930\n",
      "Epoch 905/1000\n",
      "570/570 [==============================] - 0s 756us/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0386 - val_accuracy: 0.9930\n",
      "Epoch 906/1000\n",
      "570/570 [==============================] - 0s 783us/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0355 - val_accuracy: 0.9926\n",
      "Epoch 907/1000\n",
      "570/570 [==============================] - 0s 778us/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0319 - val_accuracy: 0.9918\n",
      "Epoch 908/1000\n",
      "570/570 [==============================] - 0s 769us/step - loss: 0.0094 - accuracy: 0.9955 - val_loss: 0.0341 - val_accuracy: 0.9914\n",
      "Epoch 909/1000\n",
      "570/570 [==============================] - 0s 785us/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.0294 - val_accuracy: 0.9939\n",
      "Epoch 910/1000\n",
      "570/570 [==============================] - 0s 821us/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0327 - val_accuracy: 0.9930\n",
      "Epoch 911/1000\n",
      "570/570 [==============================] - 0s 750us/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.0314 - val_accuracy: 0.9914\n",
      "Epoch 912/1000\n",
      "570/570 [==============================] - 0s 783us/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.0339 - val_accuracy: 0.9935\n",
      "Epoch 913/1000\n",
      "570/570 [==============================] - 0s 801us/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.0296 - val_accuracy: 0.9914\n",
      "Epoch 914/1000\n",
      "570/570 [==============================] - 0s 851us/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.0373 - val_accuracy: 0.9935\n",
      "Epoch 915/1000\n",
      "570/570 [==============================] - 0s 774us/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.0296 - val_accuracy: 0.9935\n",
      "Epoch 916/1000\n",
      "570/570 [==============================] - 0s 810us/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0273 - val_accuracy: 0.9914\n",
      "Epoch 917/1000\n",
      "570/570 [==============================] - 0s 831us/step - loss: 0.0114 - accuracy: 0.9947 - val_loss: 0.0330 - val_accuracy: 0.9935\n",
      "Epoch 918/1000\n",
      "570/570 [==============================] - 1s 909us/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0333 - val_accuracy: 0.9914\n",
      "Epoch 919/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0338 - val_accuracy: 0.9935\n",
      "Epoch 920/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.0355 - val_accuracy: 0.9939\n",
      "Epoch 921/1000\n",
      "570/570 [==============================] - 0s 807us/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0322 - val_accuracy: 0.9918\n",
      "Epoch 922/1000\n",
      "570/570 [==============================] - 0s 800us/step - loss: 0.0087 - accuracy: 0.9965 - val_loss: 0.0378 - val_accuracy: 0.9939\n",
      "Epoch 923/1000\n",
      "570/570 [==============================] - 0s 810us/step - loss: 0.0085 - accuracy: 0.9959 - val_loss: 0.0323 - val_accuracy: 0.9935\n",
      "Epoch 924/1000\n",
      "570/570 [==============================] - 0s 764us/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.0306 - val_accuracy: 0.9930\n",
      "Epoch 925/1000\n",
      "570/570 [==============================] - 0s 780us/step - loss: 0.0085 - accuracy: 0.9965 - val_loss: 0.0343 - val_accuracy: 0.9930\n",
      "Epoch 926/1000\n",
      "570/570 [==============================] - 0s 779us/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0340 - val_accuracy: 0.9922\n",
      "Epoch 927/1000\n",
      "570/570 [==============================] - 0s 856us/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 928/1000\n",
      "570/570 [==============================] - 0s 824us/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0376 - val_accuracy: 0.9926\n",
      "Epoch 929/1000\n",
      "570/570 [==============================] - 0s 801us/step - loss: 0.0119 - accuracy: 0.9948 - val_loss: 0.0399 - val_accuracy: 0.9918\n",
      "Epoch 930/1000\n",
      "570/570 [==============================] - 0s 770us/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.0311 - val_accuracy: 0.9939\n",
      "Epoch 931/1000\n",
      "570/570 [==============================] - 0s 774us/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0301 - val_accuracy: 0.9939\n",
      "Epoch 932/1000\n",
      "570/570 [==============================] - 0s 790us/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 933/1000\n",
      "570/570 [==============================] - 0s 740us/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0313 - val_accuracy: 0.9939\n",
      "Epoch 934/1000\n",
      "570/570 [==============================] - 0s 741us/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0338 - val_accuracy: 0.9930\n",
      "Epoch 935/1000\n",
      "570/570 [==============================] - 0s 743us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0335 - val_accuracy: 0.9930\n",
      "Epoch 936/1000\n",
      "570/570 [==============================] - 0s 735us/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.0366 - val_accuracy: 0.9930\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 755us/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.0278 - val_accuracy: 0.9930\n",
      "Epoch 938/1000\n",
      "570/570 [==============================] - 0s 751us/step - loss: 0.0098 - accuracy: 0.9961 - val_loss: 0.0375 - val_accuracy: 0.9935\n",
      "Epoch 939/1000\n",
      "570/570 [==============================] - 0s 742us/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0307 - val_accuracy: 0.9939\n",
      "Epoch 940/1000\n",
      "570/570 [==============================] - 0s 776us/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0381 - val_accuracy: 0.9914\n",
      "Epoch 941/1000\n",
      "570/570 [==============================] - 0s 739us/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0271 - val_accuracy: 0.9947\n",
      "Epoch 942/1000\n",
      "570/570 [==============================] - 0s 741us/step - loss: 0.0112 - accuracy: 0.9941 - val_loss: 0.0360 - val_accuracy: 0.9926\n",
      "Epoch 943/1000\n",
      "570/570 [==============================] - 0s 741us/step - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.0376 - val_accuracy: 0.9935\n",
      "Epoch 944/1000\n",
      "570/570 [==============================] - 0s 817us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0325 - val_accuracy: 0.9922\n",
      "Epoch 945/1000\n",
      "570/570 [==============================] - 0s 789us/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.0283 - val_accuracy: 0.9935\n",
      "Epoch 946/1000\n",
      "570/570 [==============================] - 0s 764us/step - loss: 0.0086 - accuracy: 0.9967 - val_loss: 0.0240 - val_accuracy: 0.9935\n",
      "Epoch 947/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0097 - accuracy: 0.9957 - val_loss: 0.0370 - val_accuracy: 0.9926\n",
      "Epoch 948/1000\n",
      "570/570 [==============================] - 0s 760us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0304 - val_accuracy: 0.9926\n",
      "Epoch 949/1000\n",
      "570/570 [==============================] - 0s 758us/step - loss: 0.0095 - accuracy: 0.9960 - val_loss: 0.0279 - val_accuracy: 0.9947\n",
      "Epoch 950/1000\n",
      "570/570 [==============================] - 1s 880us/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.0350 - val_accuracy: 0.9926\n",
      "Epoch 951/1000\n",
      "570/570 [==============================] - 0s 775us/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.0247 - val_accuracy: 0.9939\n",
      "Epoch 952/1000\n",
      "570/570 [==============================] - 0s 790us/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0296 - val_accuracy: 0.9947\n",
      "Epoch 953/1000\n",
      "570/570 [==============================] - 0s 769us/step - loss: 0.0108 - accuracy: 0.9957 - val_loss: 0.0299 - val_accuracy: 0.9926\n",
      "Epoch 954/1000\n",
      "570/570 [==============================] - 0s 777us/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0322 - val_accuracy: 0.9930\n",
      "Epoch 955/1000\n",
      "570/570 [==============================] - 0s 762us/step - loss: 0.0079 - accuracy: 0.9969 - val_loss: 0.0283 - val_accuracy: 0.9930\n",
      "Epoch 956/1000\n",
      "570/570 [==============================] - 1s 935us/step - loss: 0.0098 - accuracy: 0.9962 - val_loss: 0.0325 - val_accuracy: 0.9922 - loss: 0.0097 - accuracy: 0.\n",
      "Epoch 957/1000\n",
      "570/570 [==============================] - 0s 784us/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0270 - val_accuracy: 0.9943\n",
      "Epoch 958/1000\n",
      "570/570 [==============================] - 0s 808us/step - loss: 0.0073 - accuracy: 0.9971 - val_loss: 0.0279 - val_accuracy: 0.9947\n",
      "Epoch 959/1000\n",
      "570/570 [==============================] - 0s 769us/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.0228 - val_accuracy: 0.9939\n",
      "Epoch 960/1000\n",
      "570/570 [==============================] - 0s 799us/step - loss: 0.0062 - accuracy: 0.9975 - val_loss: 0.0280 - val_accuracy: 0.9926\n",
      "Epoch 961/1000\n",
      "570/570 [==============================] - 0s 765us/step - loss: 0.0100 - accuracy: 0.9958 - val_loss: 0.0250 - val_accuracy: 0.9930\n",
      "Epoch 962/1000\n",
      "570/570 [==============================] - 0s 794us/step - loss: 0.0083 - accuracy: 0.9966 - val_loss: 0.0380 - val_accuracy: 0.9914\n",
      "Epoch 963/1000\n",
      "570/570 [==============================] - 1s 883us/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.0268 - val_accuracy: 0.9930\n",
      "Epoch 964/1000\n",
      "570/570 [==============================] - 1s 914us/step - loss: 0.0133 - accuracy: 0.9943 - val_loss: 0.0277 - val_accuracy: 0.9930\n",
      "Epoch 965/1000\n",
      "570/570 [==============================] - 1s 909us/step - loss: 0.0106 - accuracy: 0.9955 - val_loss: 0.0358 - val_accuracy: 0.9918\n",
      "Epoch 966/1000\n",
      "570/570 [==============================] - 0s 874us/step - loss: 0.0149 - accuracy: 0.9936 - val_loss: 0.0317 - val_accuracy: 0.9935\n",
      "Epoch 967/1000\n",
      "570/570 [==============================] - 1s 963us/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.0339 - val_accuracy: 0.9918\n",
      "Epoch 968/1000\n",
      "570/570 [==============================] - 0s 766us/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.0320 - val_accuracy: 0.9922\n",
      "Epoch 969/1000\n",
      "570/570 [==============================] - 0s 793us/step - loss: 0.0126 - accuracy: 0.9944 - val_loss: 0.0304 - val_accuracy: 0.9939\n",
      "Epoch 970/1000\n",
      "570/570 [==============================] - 0s 819us/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.0313 - val_accuracy: 0.9939\n",
      "Epoch 971/1000\n",
      "570/570 [==============================] - 0s 798us/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0321 - val_accuracy: 0.9922\n",
      "Epoch 972/1000\n",
      "570/570 [==============================] - 1s 1ms/step - loss: 0.0118 - accuracy: 0.9952 - val_loss: 0.0395 - val_accuracy: 0.9926\n",
      "Epoch 973/1000\n",
      "570/570 [==============================] - 1s 901us/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0337 - val_accuracy: 0.9930\n",
      "Epoch 974/1000\n",
      "570/570 [==============================] - 1s 886us/step - loss: 0.0084 - accuracy: 0.9966 - val_loss: 0.0320 - val_accuracy: 0.9926\n",
      "Epoch 975/1000\n",
      "570/570 [==============================] - 0s 825us/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.0397 - val_accuracy: 0.9926\n",
      "Epoch 976/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.0332 - val_accuracy: 0.9939\n",
      "Epoch 977/1000\n",
      "570/570 [==============================] - 0s 764us/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0345 - val_accuracy: 0.9926\n",
      "Epoch 978/1000\n",
      "570/570 [==============================] - 0s 862us/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.0406 - val_accuracy: 0.9930\n",
      "Epoch 979/1000\n",
      "570/570 [==============================] - 0s 804us/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.0363 - val_accuracy: 0.9930\n",
      "Epoch 980/1000\n",
      "570/570 [==============================] - 0s 779us/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.0363 - val_accuracy: 0.9930\n",
      "Epoch 981/1000\n",
      "570/570 [==============================] - 0s 788us/step - loss: 0.0101 - accuracy: 0.9960 - val_loss: 0.0307 - val_accuracy: 0.9943\n",
      "Epoch 982/1000\n",
      "570/570 [==============================] - 0s 772us/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.0344 - val_accuracy: 0.9926\n",
      "Epoch 983/1000\n",
      "570/570 [==============================] - 0s 866us/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.0333 - val_accuracy: 0.9930\n",
      "Epoch 984/1000\n",
      "570/570 [==============================] - 0s 803us/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0375 - val_accuracy: 0.9926\n",
      "Epoch 985/1000\n",
      "570/570 [==============================] - 0s 768us/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.0360 - val_accuracy: 0.9935\n",
      "Epoch 986/1000\n",
      "570/570 [==============================] - 0s 792us/step - loss: 0.0100 - accuracy: 0.9961 - val_loss: 0.0347 - val_accuracy: 0.9935\n",
      "Epoch 987/1000\n",
      "570/570 [==============================] - 0s 764us/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.0376 - val_accuracy: 0.9930\n",
      "Epoch 988/1000\n",
      "570/570 [==============================] - 0s 740us/step - loss: 0.0090 - accuracy: 0.9956 - val_loss: 0.0354 - val_accuracy: 0.9935\n",
      "Epoch 989/1000\n",
      "570/570 [==============================] - 0s 744us/step - loss: 0.0119 - accuracy: 0.9935 - val_loss: 0.0288 - val_accuracy: 0.9939\n",
      "Epoch 990/1000\n",
      "570/570 [==============================] - 0s 759us/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.0338 - val_accuracy: 0.9922\n",
      "Epoch 991/1000\n",
      "570/570 [==============================] - 0s 744us/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0334 - val_accuracy: 0.9939\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 781us/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.0315 - val_accuracy: 0.9939\n",
      "Epoch 993/1000\n",
      "570/570 [==============================] - 0s 734us/step - loss: 0.0097 - accuracy: 0.9960 - val_loss: 0.0324 - val_accuracy: 0.9930\n",
      "Epoch 994/1000\n",
      "570/570 [==============================] - 0s 738us/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0336 - val_accuracy: 0.9943\n",
      "Epoch 995/1000\n",
      "570/570 [==============================] - 0s 731us/step - loss: 0.0103 - accuracy: 0.9957 - val_loss: 0.0293 - val_accuracy: 0.9943\n",
      "Epoch 996/1000\n",
      "570/570 [==============================] - 0s 733us/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.0400 - val_accuracy: 0.9906\n",
      "Epoch 997/1000\n",
      "570/570 [==============================] - 0s 747us/step - loss: 0.0113 - accuracy: 0.9947 - val_loss: 0.0367 - val_accuracy: 0.9930\n",
      "Epoch 998/1000\n",
      "570/570 [==============================] - 0s 735us/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0328 - val_accuracy: 0.9935\n",
      "Epoch 999/1000\n",
      "570/570 [==============================] - 0s 741us/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.0318 - val_accuracy: 0.9930\n",
      "Epoch 1000/1000\n",
      "570/570 [==============================] - 0s 839us/step - loss: 0.0098 - accuracy: 0.9960 - val_loss: 0.0371 - val_accuracy: 0.9935\n"
     ]
    }
   ],
   "source": [
    "model3 = build_model()\n",
    "\n",
    "history3 = model3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, batch_size=10).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 495us/step - loss: 0.0371 - accuracy: 0.9935\n",
      "Loss 0.019907, Accuracy 0.993451\n",
      "Loss 0.023489, Accuracy 0.990995\n",
      "Loss 0.037080, Accuracy 0.993451\n"
     ]
    }
   ],
   "source": [
    "test_loss_3, test_acc_3 = model3.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_3, test_acc_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history3['loss'], label='Train')\n",
    "plt.plot(history3['val_loss'], label='Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most relevant arguments are:\n",
    "\n",
    "* monitor: quantity to be monitored\n",
    "* patience: number of epochs with no improvement after which training will be stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "456/456 [==============================] - 1s 890us/step - loss: 0.1544 - accuracy: 0.9726 - val_loss: 0.0547 - val_accuracy: 0.9877\n",
      "Epoch 2/100\n",
      "456/456 [==============================] - 0s 698us/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.0506 - val_accuracy: 0.9851\n",
      "Epoch 3/100\n",
      "456/456 [==============================] - 0s 699us/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 0.0554 - val_accuracy: 0.9877\n",
      "Epoch 4/100\n",
      "456/456 [==============================] - 0s 700us/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.0524 - val_accuracy: 0.9868\n",
      "Epoch 5/100\n",
      "456/456 [==============================] - 0s 723us/step - loss: 0.0432 - accuracy: 0.9846 - val_loss: 0.0505 - val_accuracy: 0.9877\n",
      "Epoch 6/100\n",
      "456/456 [==============================] - 0s 694us/step - loss: 0.0305 - accuracy: 0.9886 - val_loss: 0.0481 - val_accuracy: 0.9833\n",
      "Epoch 7/100\n",
      "456/456 [==============================] - 0s 715us/step - loss: 0.0469 - accuracy: 0.9811 - val_loss: 0.0479 - val_accuracy: 0.9877\n",
      "Epoch 8/100\n",
      "456/456 [==============================] - 0s 708us/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.0457 - val_accuracy: 0.9886\n",
      "Epoch 9/100\n",
      "456/456 [==============================] - 0s 716us/step - loss: 0.0249 - accuracy: 0.9900 - val_loss: 0.0410 - val_accuracy: 0.9868\n",
      "Epoch 10/100\n",
      "456/456 [==============================] - 0s 727us/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.0408 - val_accuracy: 0.9877\n",
      "Epoch 11/100\n",
      "456/456 [==============================] - 0s 710us/step - loss: 0.0251 - accuracy: 0.9900 - val_loss: 0.0346 - val_accuracy: 0.9886\n",
      "Epoch 12/100\n",
      "456/456 [==============================] - 0s 709us/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0392 - val_accuracy: 0.9895\n",
      "Epoch 13/100\n",
      "456/456 [==============================] - 0s 709us/step - loss: 0.0242 - accuracy: 0.9906 - val_loss: 0.0298 - val_accuracy: 0.9904\n",
      "Epoch 14/100\n",
      "456/456 [==============================] - 0s 711us/step - loss: 0.0253 - accuracy: 0.9903 - val_loss: 0.0434 - val_accuracy: 0.9877\n",
      "Epoch 15/100\n",
      "456/456 [==============================] - 0s 719us/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 0.0329 - val_accuracy: 0.9895\n",
      "Epoch 16/100\n",
      "456/456 [==============================] - 0s 706us/step - loss: 0.0224 - accuracy: 0.9900 - val_loss: 0.0376 - val_accuracy: 0.9886\n",
      "Epoch 17/100\n",
      "456/456 [==============================] - 0s 704us/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 0.0304 - val_accuracy: 0.9904\n",
      "Epoch 18/100\n",
      "456/456 [==============================] - 0s 749us/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.0318 - val_accuracy: 0.9895\n",
      "Epoch 19/100\n",
      "456/456 [==============================] - 0s 742us/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.0383 - val_accuracy: 0.9868\n",
      "Epoch 20/100\n",
      "456/456 [==============================] - 0s 785us/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.0309 - val_accuracy: 0.9895\n",
      "Epoch 21/100\n",
      "456/456 [==============================] - 0s 761us/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0286 - val_accuracy: 0.9895\n",
      "Epoch 22/100\n",
      "456/456 [==============================] - 0s 727us/step - loss: 0.0237 - accuracy: 0.9908 - val_loss: 0.0408 - val_accuracy: 0.9860\n",
      "Epoch 23/100\n",
      "456/456 [==============================] - 0s 714us/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.0320 - val_accuracy: 0.9904\n",
      "Epoch 24/100\n",
      "456/456 [==============================] - 0s 717us/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.0291 - val_accuracy: 0.9904\n",
      "Epoch 25/100\n",
      "456/456 [==============================] - 0s 715us/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.0311 - val_accuracy: 0.9895\n",
      "Epoch 26/100\n",
      "456/456 [==============================] - 0s 709us/step - loss: 0.0201 - accuracy: 0.9928 - val_loss: 0.0322 - val_accuracy: 0.9895\n",
      "Epoch 27/100\n",
      "456/456 [==============================] - 0s 798us/step - loss: 0.0217 - accuracy: 0.9895 - val_loss: 0.0343 - val_accuracy: 0.9904\n",
      "Epoch 28/100\n",
      "456/456 [==============================] - 0s 725us/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.0355 - val_accuracy: 0.9895\n",
      "Epoch 29/100\n",
      "456/456 [==============================] - 0s 729us/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0360 - val_accuracy: 0.9904\n",
      "Epoch 30/100\n",
      "456/456 [==============================] - 0s 731us/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.0310 - val_accuracy: 0.9895\n",
      "Epoch 31/100\n",
      "456/456 [==============================] - 0s 797us/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0238 - val_accuracy: 0.9912\n",
      "Epoch 32/100\n",
      "456/456 [==============================] - 0s 779us/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 0.0349 - val_accuracy: 0.9904\n",
      "Epoch 33/100\n",
      "456/456 [==============================] - 0s 693us/step - loss: 0.0197 - accuracy: 0.9916 - val_loss: 0.0296 - val_accuracy: 0.9886\n",
      "Epoch 34/100\n",
      "456/456 [==============================] - 0s 807us/step - loss: 0.0232 - accuracy: 0.9913 - val_loss: 0.0329 - val_accuracy: 0.9904\n",
      "Epoch 35/100\n",
      "456/456 [==============================] - 0s 686us/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.0348 - val_accuracy: 0.9886\n",
      "Epoch 36/100\n",
      "456/456 [==============================] - 0s 692us/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 0.0249 - val_accuracy: 0.9904\n",
      "Epoch 37/100\n",
      "456/456 [==============================] - 0s 688us/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0292 - val_accuracy: 0.9912\n",
      "Epoch 38/100\n",
      "456/456 [==============================] - 0s 686us/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.0304 - val_accuracy: 0.9904\n",
      "Epoch 39/100\n",
      "456/456 [==============================] - 0s 683us/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0301 - val_accuracy: 0.9912\n",
      "Epoch 40/100\n",
      "456/456 [==============================] - 0s 682us/step - loss: 0.0195 - accuracy: 0.9922 - val_loss: 0.0368 - val_accuracy: 0.9912\n",
      "Epoch 41/100\n",
      "456/456 [==============================] - 0s 679us/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.0306 - val_accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=10)\n",
    "mc = ModelCheckpoint('best_model_NOREG.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model4 = build_model()\n",
    "history4 = model4.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, \n",
    "                      batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 711us/step - loss: 0.0240 - accuracy: 0.9918\n",
      "Loss 0.019907, Accuracy 0.993451\n",
      "Loss 0.023489, Accuracy 0.990995\n",
      "Loss 0.037080, Accuracy 0.993451\n",
      "Loss 0.023965, Accuracy 0.991813\n"
     ]
    }
   ],
   "source": [
    "test_loss_4, test_acc_4 = model4.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_3, test_acc_3))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_4, test_acc_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def build_L2_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    h_dim=100\n",
    "    model.add(Dense(h_dim, activation='relu', input_shape=(n_feature,), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "456/456 [==============================] - 1s 1ms/step - loss: 1.9445 - accuracy: 0.9588 - val_loss: 0.6915 - val_accuracy: 0.9868\n",
      "Epoch 2/100\n",
      "456/456 [==============================] - 0s 891us/step - loss: 0.6475 - accuracy: 0.9811 - val_loss: 3.5075 - val_accuracy: 0.7947\n",
      "Epoch 3/100\n",
      "456/456 [==============================] - 0s 873us/step - loss: 3.6886 - accuracy: 0.7811 - val_loss: 3.4074 - val_accuracy: 0.7947\n",
      "Epoch 4/100\n",
      "456/456 [==============================] - 0s 1ms/step - loss: 3.3960 - accuracy: 0.7943 - val_loss: 3.3412 - val_accuracy: 0.7947\n",
      "Epoch 5/100\n",
      "456/456 [==============================] - 1s 1ms/step - loss: 3.5314 - accuracy: 0.7815 - val_loss: 3.2921 - val_accuracy: 0.7947\n",
      "Epoch 6/100\n",
      "456/456 [==============================] - 0s 902us/step - loss: 3.3989 - accuracy: 0.7872 - val_loss: 3.2550 - val_accuracy: 0.7947\n",
      "Epoch 7/100\n",
      "456/456 [==============================] - 0s 818us/step - loss: 3.4372 - accuracy: 0.7824 - val_loss: 3.2272 - val_accuracy: 0.7947\n",
      "Epoch 8/100\n",
      "456/456 [==============================] - 0s 851us/step - loss: 3.4531 - accuracy: 0.7797 - val_loss: 3.2067 - val_accuracy: 0.7947\n",
      "Epoch 9/100\n",
      "456/456 [==============================] - 0s 794us/step - loss: 3.4566 - accuracy: 0.7783 - val_loss: 3.1922 - val_accuracy: 0.7947\n",
      "Epoch 10/100\n",
      "456/456 [==============================] - 0s 889us/step - loss: 3.4183 - accuracy: 0.7799 - val_loss: 3.1821 - val_accuracy: 0.7947\n",
      "Epoch 11/100\n",
      "456/456 [==============================] - 0s 913us/step - loss: 3.3772 - accuracy: 0.7820 - val_loss: 3.1756 - val_accuracy: 0.7947\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_L2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "L2_model = build_L2_model()\n",
    "h_L2 = L2_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, \n",
    "                    batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "def build_DROPOUT_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    h_dim=100\n",
    "    model.add(Dense(h_dim, activation='relu', input_shape=(n_feature,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "456/456 [==============================] - 1s 1ms/step - loss: 0.1792 - accuracy: 0.9688 - val_loss: 0.1889 - val_accuracy: 0.9868\n",
      "Epoch 2/100\n",
      "456/456 [==============================] - 0s 1ms/step - loss: 0.1725 - accuracy: 0.9858 - val_loss: 0.1873 - val_accuracy: 0.9877\n",
      "Epoch 3/100\n",
      "456/456 [==============================] - 0s 880us/step - loss: 0.1920 - accuracy: 0.9868 - val_loss: 0.2446 - val_accuracy: 0.9825\n",
      "Epoch 4/100\n",
      "456/456 [==============================] - 0s 904us/step - loss: 0.1951 - accuracy: 0.9859 - val_loss: 0.2162 - val_accuracy: 0.9851\n",
      "Epoch 5/100\n",
      "456/456 [==============================] - 0s 826us/step - loss: 0.2282 - accuracy: 0.9837 - val_loss: 0.1874 - val_accuracy: 0.9877\n",
      "Epoch 6/100\n",
      "456/456 [==============================] - 1s 1ms/step - loss: 0.1856 - accuracy: 0.9878 - val_loss: 0.1873 - val_accuracy: 0.9877\n",
      "Epoch 7/100\n",
      "456/456 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.9866 - val_loss: 0.1880 - val_accuracy: 0.9868\n",
      "Epoch 8/100\n",
      "456/456 [==============================] - 0s 875us/step - loss: 0.2064 - accuracy: 0.9863 - val_loss: 0.2417 - val_accuracy: 0.9842\n",
      "Epoch 9/100\n",
      "456/456 [==============================] - 0s 868us/step - loss: 0.1961 - accuracy: 0.9866 - val_loss: 0.1873 - val_accuracy: 0.9877\n",
      "Epoch 10/100\n",
      "456/456 [==============================] - 0s 918us/step - loss: 0.1944 - accuracy: 0.9868 - val_loss: 0.1873 - val_accuracy: 0.9877\n",
      "Epoch 11/100\n",
      "456/456 [==============================] - 0s 834us/step - loss: 0.1689 - accuracy: 0.9889 - val_loss: 0.3664 - val_accuracy: 0.9746\n",
      "Epoch 12/100\n",
      "456/456 [==============================] - 0s 887us/step - loss: 0.2421 - accuracy: 0.9821 - val_loss: 0.1873 - val_accuracy: 0.9877\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_DROPOUT.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "DROPOUT_model = build_DROPOUT_model()\n",
    "h_DROPOUT = DROPOUT_model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                              epochs=100, batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 449us/step - loss: 0.0215 - accuracy: 0.9922\n",
      "77/77 [==============================] - 0s 532us/step - loss: 0.6342 - accuracy: 0.9910\n",
      "77/77 [==============================] - 0s 488us/step - loss: 0.1382 - accuracy: 0.9906\n"
     ]
    }
   ],
   "source": [
    "# laod best models and test them\n",
    "from keras.models import load_model\n",
    "\n",
    "best_NOREG_model = load_model('best_model_NOREG.h5')\n",
    "best_L2_model = load_model('best_model_L2.h5')\n",
    "best_DROPOUT_model = load_model('best_model_DROPOUT.h5')\n",
    "\n",
    "loss_NOREG, acc_NOREG = best_NOREG_model.evaluate(X_test, y_test)\n",
    "loss_L2, acc_L2 = best_L2_model.evaluate(X_test, y_test)\n",
    "loss_DROPOUT, acc_DROPOUT = best_DROPOUT_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.021535, Accuracy 0.992223\n",
      "Loss 0.634186, Accuracy 0.990995\n",
      "Loss 0.138231, Accuracy 0.990585\n"
     ]
    }
   ],
   "source": [
    "print('Loss %f, Accuracy %f' % (loss_NOREG, acc_NOREG))\n",
    "print('Loss %f, Accuracy %f' % (loss_L2, acc_L2))\n",
    "print('Loss %f, Accuracy %f' % (loss_DROPOUT, acc_DROPOUT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_layers=2, h_dim=64, activation='relu', optimizer='adam'):\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    \n",
    "    model.add(Dense(h_dim, activation=activation, input_shape=(n_feature,)))\n",
    "    for i in range(n_layers-1):\n",
    "        model.add(Dense(h_dim, activation=activation))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = [1, 2, 3]\n",
    "h_dim = [32, 64, 128]\n",
    "activation = ['relu', 'tanh']\n",
    "optimizer = ['adagrad', 'adam']\n",
    "params = dict(optimizer=optimizer, n_layers=n_layers, h_dim=h_dim, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 488us/step - loss: 0.0728 - accuracy: 0.9862\n",
      "48/48 [==============================] - 0s 500us/step - loss: 0.0737 - accuracy: 0.9842\n",
      "48/48 [==============================] - 0s 477us/step - loss: 0.1676 - accuracy: 0.9875\n",
      "48/48 [==============================] - 0s 496us/step - loss: 0.0737 - accuracy: 0.9868\n",
      "48/48 [==============================] - 0s 525us/step - loss: 0.0578 - accuracy: 0.9862\n",
      "48/48 [==============================] - 0s 467us/step - loss: 1.2452 - accuracy: 0.8276\n",
      "48/48 [==============================] - 0s 480us/step - loss: 0.0584 - accuracy: 0.9855\n",
      "48/48 [==============================] - 0s 511us/step - loss: 1.7473 - accuracy: 0.8638\n",
      "48/48 [==============================] - 0s 452us/step - loss: 0.0820 - accuracy: 0.9651\n",
      "48/48 [==============================] - 0s 512us/step - loss: 0.1706 - accuracy: 0.9888\n",
      "48/48 [==============================] - 0s 506us/step - loss: 0.2108 - accuracy: 0.9862\n",
      "48/48 [==============================] - 0s 537us/step - loss: 0.1819 - accuracy: 0.9875\n",
      "48/48 [==============================] - 0s 447us/step - loss: 0.1246 - accuracy: 0.9901\n",
      "48/48 [==============================] - 0s 440us/step - loss: 0.1664 - accuracy: 0.9855\n",
      "48/48 [==============================] - 0s 479us/step - loss: 0.1812 - accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "model = KerasRegressor(build_fn=build_model)\n",
    "\n",
    "rnd = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter=5, cv=3)\n",
    "rnd_result = rnd.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.104686 using {'optimizer': 'adagrad', 'n_layers': 2, 'h_dim': 128, 'activation': 'tanh'}\n",
      "0.104686 (0.044461) with: {'optimizer': 'adagrad', 'n_layers': 2, 'h_dim': 128, 'activation': 'tanh'}\n",
      "0.458918 (0.556023) with: {'optimizer': 'adagrad', 'n_layers': 2, 'h_dim': 32, 'activation': 'tanh'}\n",
      "0.629233 (0.790657) with: {'optimizer': 'adagrad', 'n_layers': 1, 'h_dim': 32, 'activation': 'relu'}\n",
      "0.187738 (0.016946) with: {'optimizer': 'adam', 'n_layers': 3, 'h_dim': 128, 'activation': 'tanh'}\n",
      "0.157399 (0.023955) with: {'optimizer': 'adam', 'n_layers': 1, 'h_dim': 64, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (-rnd_result.best_score_, rnd_result.best_params_))\n",
    "means = rnd_result.cv_results_['mean_test_score']\n",
    "stds = rnd_result.cv_results_['std_test_score']\n",
    "params = rnd_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (-mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 473us/step - loss: 0.0757 - accuracy: 0.9885\n",
      "Loss 0.075692, Accuracy 0.988539\n"
     ]
    }
   ],
   "source": [
    "clf = rnd_result.best_estimator_.model\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test)\n",
    "print('Loss %f, Accuracy %f' % (loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
