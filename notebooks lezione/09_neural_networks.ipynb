{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** [Riccardo Guidotti](http://kdd.isti.cnr.it/people/riccardo-guidotti)  \n",
    "**Python version:**  3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-04 17:51:00</td>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-04 17:51:59</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-04 17:53:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-04 17:54:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-02-04 17:55:00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Temperature  Humidity  Light     CO2  HumidityRatio  \\\n",
       "1  2015-02-04 17:51:00        23.18   27.2720  426.0  721.25       0.004793   \n",
       "2  2015-02-04 17:51:59        23.15   27.2675  429.5  714.00       0.004783   \n",
       "3  2015-02-04 17:53:00        23.15   27.2450  426.0  713.50       0.004779   \n",
       "4  2015-02-04 17:54:00        23.15   27.2000  426.0  708.25       0.004772   \n",
       "5  2015-02-04 17:55:00        23.10   27.2000  426.0  704.50       0.004757   \n",
       "\n",
       "   Occupancy  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = 'Occupancy'\n",
    "df = pd.read_csv('occupancy_data/datatraining.txt', skipinitialspace=True, na_values='?', keep_default_na=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daytime(h):\n",
    "    if 6 <= h < 13:\n",
    "        return 'morning'\n",
    "    elif 13 <= h < 18:\n",
    "        return 'afternoon'\n",
    "    elif 18 <= h < 22:\n",
    "        return 'evening'\n",
    "    return 'night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>daytime</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Light     CO2  HumidityRatio  Occupancy    daytime  \\\n",
       "1        23.18   27.2720  426.0  721.25       0.004793          1  afternoon   \n",
       "2        23.15   27.2675  429.5  714.00       0.004783          1  afternoon   \n",
       "3        23.15   27.2450  426.0  713.50       0.004779          1  afternoon   \n",
       "4        23.15   27.2000  426.0  708.25       0.004772          1  afternoon   \n",
       "5        23.10   27.2000  426.0  704.50       0.004757          1  afternoon   \n",
       "\n",
       "   weekend  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "5        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['daytime'] = [daytime(d.hour) for d in pd.to_datetime(df['date'])]\n",
    "df['weekend'] = [1 if d.weekday() >= 5 else 0 for d in pd.to_datetime(df['date'])]\n",
    "columns2remove = ['date']\n",
    "df.drop(columns2remove, inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>weekend</th>\n",
       "      <th>daytime=afternoon</th>\n",
       "      <th>daytime=evening</th>\n",
       "      <th>daytime=morning</th>\n",
       "      <th>daytime=night</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Light     CO2  HumidityRatio  weekend  \\\n",
       "1        23.18   27.2720  426.0  721.25       0.004793        0   \n",
       "2        23.15   27.2675  429.5  714.00       0.004783        0   \n",
       "3        23.15   27.2450  426.0  713.50       0.004779        0   \n",
       "4        23.15   27.2000  426.0  708.25       0.004772        0   \n",
       "5        23.10   27.2000  426.0  704.50       0.004757        0   \n",
       "\n",
       "   daytime=afternoon  daytime=evening  daytime=morning  daytime=night  \\\n",
       "1                  1                0                0              0   \n",
       "2                  1                0                0              0   \n",
       "3                  1                0                0              0   \n",
       "4                  1                0                0              0   \n",
       "5                  1                0                0              0   \n",
       "\n",
       "   Occupancy  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX = pd.get_dummies(df[[c for c in df.columns if c != class_name]], prefix_sep='=')\n",
    "dfY = df[class_name]\n",
    "df = pd.concat([dfX, dfY], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [col for col in df.columns if col != class_name]\n",
    "X = df[attributes].values\n",
    "y = df[class_name]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "hidden_layer_sizes tuple, length = n_layers - 2, default=(100,)\n",
    "The ith element represents the number of neurons in the ith hidden layer.\n",
    "\n",
    "activation {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
    "Activation function for the hidden layer.\n",
    "* 'identity', no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "* 'logistic', the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "* 'tanh', the hyperbolic tan function, returns f(x) = tanh(x).\n",
    "* 'relu', the rectified linear unit function, returns f(x) = max(0, x)\n",
    "\n",
    "solver {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
    "The solver for weight optimization.\n",
    "* 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
    "* 'sgd' refers to stochastic gradient descent.\n",
    "* 'adam' refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "The default solver 'adam' works pretty well on relatively large datasets (>= 1000 training samples) in terms of both training time and validation score. For small datasets, 'lbfgs' can converge faster and perform better.\n",
    "\n",
    "alpha float, default=0.0001\n",
    "L2 penalty (regularization term) parameter.\n",
    "\n",
    "batch_size int, default='auto'\n",
    "Size of minibatches for stochastic optimizers. If the solver is 'lbfgs', the classifier will not use minibatch. When set to “auto”, batch_size=min(200, n_samples)\n",
    "\n",
    "learning_rate {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
    "Learning rate schedule for weight updates.\n",
    "*'constant' is a constant learning rate given by 'learning_rate_init'.\n",
    "*'invscaling' gradually decreases the learning rate at each time step 't' using an inverse scaling exponent of *'power_t'. effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
    "*'adaptive' keeps the learning rate constant to 'learning_rate_init' as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if 'early_stopping' is on, the current learning rate is divided by 5.\n",
    "Only used when solver='sgd'.\n",
    "\n",
    "learning_rate_init double, default=0.001\n",
    "The initial learning rate used. It controls the step-size in updating the weights. Only used when solver='sgd' or 'adam'.\n",
    "\n",
    "power_t double, default=0.5\n",
    "The exponent for inverse scaling learning rate. It is used in updating effective learning rate when the learning_rate is set to 'invscaling'. Only used when solver='sgd'.\n",
    "\n",
    "max_iter int, default=200\n",
    "Maximum number of iterations. The solver iterates until convergence (determined by 'tol') or this number of iterations. For stochastic solvers ('sgd', 'adam'), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.\n",
    "\n",
    "shuffle bool, default=True\n",
    "Whether to shuffle samples in each iteration. Only used when solver='sgd' or 'adam'.\n",
    "\n",
    "random_state int, RandomState instance or None, default=None\n",
    "If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.\n",
    "\n",
    "tol float, default=1e-4\n",
    "Tolerance for the optimization. When the loss or score is not improving by at least tol for n_iter_no_change consecutive iterations, unless learning_rate is set to 'adaptive', convergence is considered to be reached and training stops.\n",
    "\n",
    "verbose bool, default=False\n",
    "Whether to print progress messages to stdout.\n",
    "\n",
    "warm_start bool, default=False\n",
    "When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.\n",
    "\n",
    "momentum float, default=0.9\n",
    "Momentum for gradient descent update. Should be between 0 and 1. Only used when solver='sgd'.\n",
    "\n",
    "early_stopping bool, default=False\n",
    "Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs. The split is stratified, except in a multilabel setting. Only effective when solver='sgd' or 'adam'\n",
    "\n",
    "validation_fraction float, default=0.1\n",
    "The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True\n",
    "\n",
    "beta_1 float, default=0.9\n",
    "Exponential decay rate for estimates of first moment vector in adam, should be in [0, 1). Only used when solver='adam'\n",
    "\n",
    "beta_2 float, default=0.999\n",
    "Exponential decay rate for estimates of second moment vector in adam, should be in [0, 1). Only used when solver='adam'\n",
    "\n",
    "epsilon float, default=1e-8\n",
    "Value for numerical stability in adam. Only used when solver='adam'\n",
    "\n",
    "n_iter_no_change int, default=10\n",
    "Maximum number of epochs to not meet tol improvement. Only effective when solver='sgd' or 'adam'\n",
    "\n",
    "\n",
    "### Attributes\n",
    "loss_ float\n",
    "The current loss computed with the loss function.\n",
    "\n",
    "coefs_ list, length n_layers - 1\n",
    "The ith element in the list represents the weight matrix corresponding to layer i.\n",
    "\n",
    "intercepts_ list, length n_layers - 1\n",
    "The ith element in the list represents the bias vector corresponding to layer i + 1.\n",
    "\n",
    "n_iter_ int,\n",
    "The number of iterations the solver has ran.\n",
    "\n",
    "n_layers_ int\n",
    "Number of layers.\n",
    "\n",
    "n_outputs_ int\n",
    "Number of outputs.\n",
    "\n",
    "out_activation_ string\n",
    "Name of the output activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9930413426115432\n",
      "F1-score [0.99557407 0.98373206]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      1924\n",
      "           1       0.98      0.99      0.98       519\n",
      "\n",
      "    accuracy                           0.99      2443\n",
      "   macro avg       0.99      0.99      0.99      2443\n",
      "weighted avg       0.99      0.99      0.99      2443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cri98\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.loss_curve_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9897666803110929\n",
      "F1-score [0.99350143 0.9759384 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1924\n",
      "           1       0.97      0.98      0.98       519\n",
      "\n",
      "    accuracy                           0.99      2443\n",
      "   macro avg       0.98      0.99      0.98      2443\n",
      "weighted avg       0.99      0.99      0.99      2443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(128, 64, 32,), alpha=0.1, learning_rate='adaptive', \n",
    "                    activation='tanh', early_stopping=False, momentum=0.9, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.loss_curve_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'solver': 'sgd', 'learning_rate': 'constant', 'momentum': 0,'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'constant', 'momentum': .9,\n",
    "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': 0,\n",
    "           'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': .9,\n",
    "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'adam', 'learning_rate_init': 0.01}]\n",
    "\n",
    "labels = [\"constant learning-rate\", \"constant with momentum\",\n",
    "          \"inv-scaling learning-rate\", \"inv-scaling with momentum\", \"adam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant learning-rate\n",
      "training set score and loss: 0.788, 0.749526\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant with momentum\n",
      "training set score and loss: 0.788, 24.231273\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv-scaling learning-rate\n",
      "training set score and loss: 0.788, 0.754787\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv-scaling with momentum\n",
      "training set score and loss: 0.788, 24.244236\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam\n",
      "training set score and loss: 0.949, 0.147185\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, param in zip(labels, params):\n",
    "    print(label)\n",
    "    clf = MLPClassifier(random_state=0, max_iter=200, **param)\n",
    "\n",
    "    # some parameter combinations will not converge as can be seen on the\n",
    "    # plots so they are ignored here\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "        clf.fit(X, y)\n",
    "\n",
    "    print(\"training set score and loss: %.3f, %f\" % (clf.score(X, y), clf.loss_))\n",
    "    plt.plot(clf.loss_curve_, label=label)\n",
    "    plt.legend(loc=\"upper center\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    n_feature = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=n_feature, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "570/570 [==============================] - 0s 479us/step - loss: 0.0724 - accuracy: 0.9809\n",
      "Epoch 2/50\n",
      "570/570 [==============================] - 0s 447us/step - loss: 0.0407 - accuracy: 0.9875\n",
      "Epoch 3/50\n",
      "570/570 [==============================] - 0s 436us/step - loss: 0.0367 - accuracy: 0.9870\n",
      "Epoch 4/50\n",
      "570/570 [==============================] - 0s 439us/step - loss: 0.0334 - accuracy: 0.9875\n",
      "Epoch 5/50\n",
      "570/570 [==============================] - 0s 452us/step - loss: 0.0323 - accuracy: 0.9891\n",
      "Epoch 6/50\n",
      "570/570 [==============================] - 0s 455us/step - loss: 0.0297 - accuracy: 0.9886\n",
      "Epoch 7/50\n",
      "570/570 [==============================] - 0s 425us/step - loss: 0.0289 - accuracy: 0.9900\n",
      "Epoch 8/50\n",
      "570/570 [==============================] - 0s 437us/step - loss: 0.0271 - accuracy: 0.9905\n",
      "Epoch 9/50\n",
      "570/570 [==============================] - 0s 450us/step - loss: 0.0266 - accuracy: 0.9904\n",
      "Epoch 10/50\n",
      "570/570 [==============================] - 0s 460us/step - loss: 0.0260 - accuracy: 0.9909\n",
      "Epoch 11/50\n",
      "570/570 [==============================] - 0s 420us/step - loss: 0.0256 - accuracy: 0.9919\n",
      "Epoch 12/50\n",
      "570/570 [==============================] - 0s 446us/step - loss: 0.0255 - accuracy: 0.9918\n",
      "Epoch 13/50\n",
      "570/570 [==============================] - 0s 453us/step - loss: 0.0251 - accuracy: 0.9930\n",
      "Epoch 14/50\n",
      "570/570 [==============================] - 0s 473us/step - loss: 0.0258 - accuracy: 0.9916\n",
      "Epoch 15/50\n",
      "570/570 [==============================] - 0s 533us/step - loss: 0.0235 - accuracy: 0.9921\n",
      "Epoch 16/50\n",
      "570/570 [==============================] - 0s 499us/step - loss: 0.0239 - accuracy: 0.9919\n",
      "Epoch 17/50\n",
      "570/570 [==============================] - 0s 459us/step - loss: 0.0237 - accuracy: 0.9925\n",
      "Epoch 18/50\n",
      "570/570 [==============================] - 0s 432us/step - loss: 0.0238 - accuracy: 0.9912\n",
      "Epoch 19/50\n",
      "570/570 [==============================] - 0s 437us/step - loss: 0.0231 - accuracy: 0.9926\n",
      "Epoch 20/50\n",
      "570/570 [==============================] - 0s 492us/step - loss: 0.0243 - accuracy: 0.9919\n",
      "Epoch 21/50\n",
      "570/570 [==============================] - 0s 486us/step - loss: 0.0231 - accuracy: 0.9923\n",
      "Epoch 22/50\n",
      "570/570 [==============================] - 0s 433us/step - loss: 0.0229 - accuracy: 0.9921\n",
      "Epoch 23/50\n",
      "570/570 [==============================] - 0s 446us/step - loss: 0.0217 - accuracy: 0.9925\n",
      "Epoch 24/50\n",
      "570/570 [==============================] - 0s 524us/step - loss: 0.0233 - accuracy: 0.9921\n",
      "Epoch 25/50\n",
      "570/570 [==============================] - 0s 458us/step - loss: 0.0212 - accuracy: 0.9930\n",
      "Epoch 26/50\n",
      "570/570 [==============================] - 0s 426us/step - loss: 0.0222 - accuracy: 0.9925\n",
      "Epoch 27/50\n",
      "570/570 [==============================] - 0s 480us/step - loss: 0.0208 - accuracy: 0.9928\n",
      "Epoch 28/50\n",
      "570/570 [==============================] - 0s 491us/step - loss: 0.0220 - accuracy: 0.9932\n",
      "Epoch 29/50\n",
      "570/570 [==============================] - 0s 478us/step - loss: 0.0213 - accuracy: 0.9923\n",
      "Epoch 30/50\n",
      "570/570 [==============================] - 0s 427us/step - loss: 0.0213 - accuracy: 0.9921\n",
      "Epoch 31/50\n",
      "570/570 [==============================] - 0s 473us/step - loss: 0.0212 - accuracy: 0.9928\n",
      "Epoch 32/50\n",
      "570/570 [==============================] - 0s 492us/step - loss: 0.0219 - accuracy: 0.9925\n",
      "Epoch 33/50\n",
      "570/570 [==============================] - 0s 466us/step - loss: 0.0218 - accuracy: 0.9923\n",
      "Epoch 34/50\n",
      "570/570 [==============================] - 0s 445us/step - loss: 0.0234 - accuracy: 0.9916\n",
      "Epoch 35/50\n",
      "570/570 [==============================] - 0s 469us/step - loss: 0.0207 - accuracy: 0.9925\n",
      "Epoch 36/50\n",
      "570/570 [==============================] - 0s 482us/step - loss: 0.0224 - accuracy: 0.9925\n",
      "Epoch 37/50\n",
      "570/570 [==============================] - 0s 482us/step - loss: 0.0218 - accuracy: 0.9926\n",
      "Epoch 38/50\n",
      "570/570 [==============================] - 0s 452us/step - loss: 0.0208 - accuracy: 0.9930\n",
      "Epoch 39/50\n",
      "570/570 [==============================] - 0s 464us/step - loss: 0.0219 - accuracy: 0.9932\n",
      "Epoch 40/50\n",
      "570/570 [==============================] - 0s 450us/step - loss: 0.0207 - accuracy: 0.9926\n",
      "Epoch 41/50\n",
      "570/570 [==============================] - 0s 430us/step - loss: 0.0206 - accuracy: 0.9937\n",
      "Epoch 42/50\n",
      "570/570 [==============================] - 0s 463us/step - loss: 0.0199 - accuracy: 0.9935\n",
      "Epoch 43/50\n",
      "570/570 [==============================] - 0s 461us/step - loss: 0.0206 - accuracy: 0.9932\n",
      "Epoch 44/50\n",
      "570/570 [==============================] - 0s 452us/step - loss: 0.0209 - accuracy: 0.9928\n",
      "Epoch 45/50\n",
      "570/570 [==============================] - 0s 423us/step - loss: 0.0202 - accuracy: 0.9933\n",
      "Epoch 46/50\n",
      "570/570 [==============================] - 0s 479us/step - loss: 0.0210 - accuracy: 0.9925\n",
      "Epoch 47/50\n",
      "570/570 [==============================] - 0s 470us/step - loss: 0.0196 - accuracy: 0.9928\n",
      "Epoch 48/50\n",
      "570/570 [==============================] - 0s 468us/step - loss: 0.0201 - accuracy: 0.9933\n",
      "Epoch 49/50\n",
      "570/570 [==============================] - 0s 432us/step - loss: 0.0199 - accuracy: 0.9932\n",
      "Epoch 50/50\n",
      "570/570 [==============================] - 0s 486us/step - loss: 0.0197 - accuracy: 0.9937\n"
     ]
    }
   ],
   "source": [
    "model1 = build_model()\n",
    "\n",
    "history1 = model1.fit(X_train, y_train, epochs=50, batch_size=10).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "114/114 [==============================] - 0s 448us/step - loss: 0.1431 - accuracy: 0.9696\n",
      "Epoch 2/50\n",
      "114/114 [==============================] - 0s 431us/step - loss: 0.0460 - accuracy: 0.9874\n",
      "Epoch 3/50\n",
      "114/114 [==============================] - 0s 579us/step - loss: 0.0397 - accuracy: 0.9877\n",
      "Epoch 4/50\n",
      "114/114 [==============================] - 0s 483us/step - loss: 0.0375 - accuracy: 0.9875\n",
      "Epoch 5/50\n",
      "114/114 [==============================] - 0s 513us/step - loss: 0.0359 - accuracy: 0.9877\n",
      "Epoch 6/50\n",
      "114/114 [==============================] - 0s 553us/step - loss: 0.0342 - accuracy: 0.9879\n",
      "Epoch 7/50\n",
      "114/114 [==============================] - 0s 492us/step - loss: 0.0330 - accuracy: 0.9877\n",
      "Epoch 8/50\n",
      "114/114 [==============================] - 0s 522us/step - loss: 0.0313 - accuracy: 0.9874\n",
      "Epoch 9/50\n",
      "114/114 [==============================] - 0s 496us/step - loss: 0.0300 - accuracy: 0.9893\n",
      "Epoch 10/50\n",
      "114/114 [==============================] - 0s 548us/step - loss: 0.0291 - accuracy: 0.9888\n",
      "Epoch 11/50\n",
      "114/114 [==============================] - 0s 483us/step - loss: 0.0278 - accuracy: 0.9893\n",
      "Epoch 12/50\n",
      "114/114 [==============================] - 0s 509us/step - loss: 0.0281 - accuracy: 0.9896\n",
      "Epoch 13/50\n",
      "114/114 [==============================] - 0s 500us/step - loss: 0.0272 - accuracy: 0.9907\n",
      "Epoch 14/50\n",
      "114/114 [==============================] - 0s 535us/step - loss: 0.0261 - accuracy: 0.9898\n",
      "Epoch 15/50\n",
      "114/114 [==============================] - 0s 470us/step - loss: 0.0266 - accuracy: 0.9902\n",
      "Epoch 16/50\n",
      "114/114 [==============================] - 0s 466us/step - loss: 0.0267 - accuracy: 0.9902\n",
      "Epoch 17/50\n",
      "114/114 [==============================] - 0s 457us/step - loss: 0.0249 - accuracy: 0.9909\n",
      "Epoch 18/50\n",
      "114/114 [==============================] - 0s 448us/step - loss: 0.0248 - accuracy: 0.9905\n",
      "Epoch 19/50\n",
      "114/114 [==============================] - 0s 474us/step - loss: 0.0249 - accuracy: 0.9911\n",
      "Epoch 20/50\n",
      "114/114 [==============================] - 0s 509us/step - loss: 0.0244 - accuracy: 0.9921\n",
      "Epoch 21/50\n",
      "114/114 [==============================] - 0s 500us/step - loss: 0.0244 - accuracy: 0.9919\n",
      "Epoch 22/50\n",
      "114/114 [==============================] - 0s 579us/step - loss: 0.0236 - accuracy: 0.9921\n",
      "Epoch 23/50\n",
      "114/114 [==============================] - 0s 566us/step - loss: 0.0228 - accuracy: 0.9919\n",
      "Epoch 24/50\n",
      "114/114 [==============================] - 0s 531us/step - loss: 0.0227 - accuracy: 0.9926\n",
      "Epoch 25/50\n",
      "114/114 [==============================] - 0s 500us/step - loss: 0.0225 - accuracy: 0.9921\n",
      "Epoch 26/50\n",
      "114/114 [==============================] - 0s 553us/step - loss: 0.0226 - accuracy: 0.9928\n",
      "Epoch 27/50\n",
      "114/114 [==============================] - 0s 548us/step - loss: 0.0225 - accuracy: 0.9926\n",
      "Epoch 28/50\n",
      "114/114 [==============================] - 0s 540us/step - loss: 0.0217 - accuracy: 0.9933\n",
      "Epoch 29/50\n",
      "114/114 [==============================] - 0s 540us/step - loss: 0.0215 - accuracy: 0.9928\n",
      "Epoch 30/50\n",
      "114/114 [==============================] - 0s 526us/step - loss: 0.0220 - accuracy: 0.9925\n",
      "Epoch 31/50\n",
      "114/114 [==============================] - 0s 461us/step - loss: 0.0212 - accuracy: 0.9932\n",
      "Epoch 32/50\n",
      "114/114 [==============================] - 0s 457us/step - loss: 0.0215 - accuracy: 0.9930\n",
      "Epoch 33/50\n",
      "114/114 [==============================] - 0s 466us/step - loss: 0.0206 - accuracy: 0.9928\n",
      "Epoch 34/50\n",
      "114/114 [==============================] - 0s 448us/step - loss: 0.0219 - accuracy: 0.9925\n",
      "Epoch 35/50\n",
      "114/114 [==============================] - 0s 452us/step - loss: 0.0205 - accuracy: 0.9937\n",
      "Epoch 36/50\n",
      "114/114 [==============================] - 0s 461us/step - loss: 0.0214 - accuracy: 0.9928\n",
      "Epoch 37/50\n",
      "114/114 [==============================] - 0s 496us/step - loss: 0.0208 - accuracy: 0.9928\n",
      "Epoch 38/50\n",
      "114/114 [==============================] - 0s 461us/step - loss: 0.0206 - accuracy: 0.9925\n",
      "Epoch 39/50\n",
      "114/114 [==============================] - 0s 557us/step - loss: 0.0205 - accuracy: 0.9939\n",
      "Epoch 40/50\n",
      "114/114 [==============================] - 0s 509us/step - loss: 0.0221 - accuracy: 0.9919\n",
      "Epoch 41/50\n",
      "114/114 [==============================] - 0s 513us/step - loss: 0.0208 - accuracy: 0.9916\n",
      "Epoch 42/50\n",
      "114/114 [==============================] - 0s 518us/step - loss: 0.0202 - accuracy: 0.9932\n",
      "Epoch 43/50\n",
      "114/114 [==============================] - 0s 566us/step - loss: 0.0206 - accuracy: 0.9928\n",
      "Epoch 44/50\n",
      "114/114 [==============================] - 0s 544us/step - loss: 0.0205 - accuracy: 0.9925\n",
      "Epoch 45/50\n",
      "114/114 [==============================] - 0s 531us/step - loss: 0.0197 - accuracy: 0.9932\n",
      "Epoch 46/50\n",
      "114/114 [==============================] - 0s 526us/step - loss: 0.0220 - accuracy: 0.9916\n",
      "Epoch 47/50\n",
      "114/114 [==============================] - 0s 553us/step - loss: 0.0199 - accuracy: 0.9928\n",
      "Epoch 48/50\n",
      "114/114 [==============================] - 0s 496us/step - loss: 0.0209 - accuracy: 0.9930\n",
      "Epoch 49/50\n",
      "114/114 [==============================] - 0s 461us/step - loss: 0.0203 - accuracy: 0.9916\n",
      "Epoch 50/50\n",
      "114/114 [==============================] - 0s 474us/step - loss: 0.0197 - accuracy: 0.9935\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model()\n",
    "\n",
    "history2 = model2.fit(X_train, y_train, epochs=50, batch_size=50).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1['loss'], label='Loss 10')\n",
    "plt.plot(history2['loss'], label='Loss 50')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 374us/step - loss: 0.0215 - accuracy: 0.9918\n",
      "77/77 [==============================] - 0s 367us/step - loss: 0.0194 - accuracy: 0.9926\n",
      "Loss 0.021506, Accuracy 0.991813\n",
      "Loss 0.019388, Accuracy 0.992632\n"
     ]
    }
   ],
   "source": [
    "test_loss_1, test_acc_1 = model1.evaluate(X_test, y_test)\n",
    "test_loss_2, test_acc_2 = model2.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.787556283258289\n",
      "F1-score [0.88115411 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      1924\n",
      "           1       0.00      0.00      0.00       519\n",
      "\n",
      "    accuracy                           0.79      2443\n",
      "   macro avg       0.39      0.50      0.44      2443\n",
      "weighted avg       0.62      0.79      0.69      2443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cri98\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(X_test).astype(int)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "570/570 [==============================] - 0s 838us/step - loss: 0.0700 - accuracy: 0.9833 - val_loss: 0.0433 - val_accuracy: 0.9881\n",
      "Epoch 2/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0406 - accuracy: 0.9875 - val_loss: 0.0344 - val_accuracy: 0.9910\n",
      "Epoch 3/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0377 - accuracy: 0.9879 - val_loss: 0.0292 - val_accuracy: 0.9889\n",
      "Epoch 4/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0335 - accuracy: 0.9877 - val_loss: 0.0289 - val_accuracy: 0.9894\n",
      "Epoch 5/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0327 - accuracy: 0.9881 - val_loss: 0.0297 - val_accuracy: 0.9898\n",
      "Epoch 6/1000\n",
      "570/570 [==============================] - 0s 605us/step - loss: 0.0302 - accuracy: 0.9898 - val_loss: 0.0262 - val_accuracy: 0.9898\n",
      "Epoch 7/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0281 - accuracy: 0.9898 - val_loss: 0.0258 - val_accuracy: 0.9902\n",
      "Epoch 8/1000\n",
      "570/570 [==============================] - 0s 549us/step - loss: 0.0284 - accuracy: 0.9905 - val_loss: 0.0237 - val_accuracy: 0.9914\n",
      "Epoch 9/1000\n",
      "570/570 [==============================] - 0s 619us/step - loss: 0.0259 - accuracy: 0.9907 - val_loss: 0.0292 - val_accuracy: 0.9889\n",
      "Epoch 10/1000\n",
      "570/570 [==============================] - 0s 597us/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.0246 - val_accuracy: 0.9918\n",
      "Epoch 11/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.0226 - val_accuracy: 0.9926\n",
      "Epoch 12/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.0224 - val_accuracy: 0.9926\n",
      "Epoch 13/1000\n",
      "570/570 [==============================] - 0s 617us/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.0296 - val_accuracy: 0.9894\n",
      "Epoch 14/1000\n",
      "570/570 [==============================] - 0s 556us/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0227 - val_accuracy: 0.9926\n",
      "Epoch 15/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0226 - val_accuracy: 0.9918\n",
      "Epoch 16/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.0205 - val_accuracy: 0.9918\n",
      "Epoch 17/1000\n",
      "570/570 [==============================] - 0s 554us/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.0206 - val_accuracy: 0.9930\n",
      "Epoch 18/1000\n",
      "570/570 [==============================] - 0s 614us/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.0244 - val_accuracy: 0.9894\n",
      "Epoch 19/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.0222 - val_accuracy: 0.9922\n",
      "Epoch 20/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.0251 - val_accuracy: 0.9881\n",
      "Epoch 21/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0276 - val_accuracy: 0.9906\n",
      "Epoch 22/1000\n",
      "570/570 [==============================] - 0s 583us/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.0246 - val_accuracy: 0.9906\n",
      "Epoch 23/1000\n",
      "570/570 [==============================] - 0s 550us/step - loss: 0.0223 - accuracy: 0.9925 - val_loss: 0.0222 - val_accuracy: 0.9922\n",
      "Epoch 24/1000\n",
      "570/570 [==============================] - 0s 640us/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.0232 - val_accuracy: 0.9902\n",
      "Epoch 25/1000\n",
      "570/570 [==============================] - 0s 565us/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.0197 - val_accuracy: 0.9926\n",
      "Epoch 26/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.0230 - val_accuracy: 0.9902\n",
      "Epoch 27/1000\n",
      "570/570 [==============================] - 0s 619us/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.0209 - val_accuracy: 0.9906\n",
      "Epoch 28/1000\n",
      "570/570 [==============================] - 0s 643us/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0204 - val_accuracy: 0.9910\n",
      "Epoch 29/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.0255 - val_accuracy: 0.9918\n",
      "Epoch 30/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.0246 - val_accuracy: 0.9910\n",
      "Epoch 31/1000\n",
      "570/570 [==============================] - 0s 634us/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 0.0244 - val_accuracy: 0.9910\n",
      "Epoch 32/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0226 - accuracy: 0.9918 - val_loss: 0.0211 - val_accuracy: 0.9914\n",
      "Epoch 33/1000\n",
      "570/570 [==============================] - 0s 650us/step - loss: 0.0202 - accuracy: 0.9919 - val_loss: 0.0181 - val_accuracy: 0.9939\n",
      "Epoch 34/1000\n",
      "570/570 [==============================] - 0s 540us/step - loss: 0.0202 - accuracy: 0.9925 - val_loss: 0.0181 - val_accuracy: 0.9926\n",
      "Epoch 35/1000\n",
      "570/570 [==============================] - 0s 608us/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.0257 - val_accuracy: 0.9906\n",
      "Epoch 36/1000\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.0240 - val_accuracy: 0.9914\n",
      "Epoch 37/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.0217 - val_accuracy: 0.9906\n",
      "Epoch 38/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.0186 - val_accuracy: 0.9926\n",
      "Epoch 39/1000\n",
      "570/570 [==============================] - 0s 601us/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.0190 - val_accuracy: 0.9930\n",
      "Epoch 40/1000\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.0198 - val_accuracy: 0.9922\n",
      "Epoch 41/1000\n",
      "570/570 [==============================] - 0s 669us/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.0196 - val_accuracy: 0.9926\n",
      "Epoch 42/1000\n",
      "570/570 [==============================] - 0s 597us/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.0189 - val_accuracy: 0.9935\n",
      "Epoch 43/1000\n",
      "570/570 [==============================] - 0s 694us/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0197 - val_accuracy: 0.9918\n",
      "Epoch 44/1000\n",
      "570/570 [==============================] - 0s 714us/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.0201 - val_accuracy: 0.9922\n",
      "Epoch 45/1000\n",
      "570/570 [==============================] - 0s 665us/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.0204 - val_accuracy: 0.9926\n",
      "Epoch 46/1000\n",
      "570/570 [==============================] - 0s 638us/step - loss: 0.0202 - accuracy: 0.9926 - val_loss: 0.0197 - val_accuracy: 0.9922\n",
      "Epoch 47/1000\n",
      "570/570 [==============================] - 0s 699us/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0232 - val_accuracy: 0.9914\n",
      "Epoch 48/1000\n",
      "570/570 [==============================] - 0s 654us/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.0194 - val_accuracy: 0.9926\n",
      "Epoch 49/1000\n",
      "570/570 [==============================] - 0s 660us/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0212 - val_accuracy: 0.9922\n",
      "Epoch 50/1000\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.0199 - val_accuracy: 0.9914\n",
      "Epoch 51/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0203 - accuracy: 0.9925 - val_loss: 0.0228 - val_accuracy: 0.9926\n",
      "Epoch 52/1000\n",
      "570/570 [==============================] - 0s 718us/step - loss: 0.0195 - accuracy: 0.9925 - val_loss: 0.0244 - val_accuracy: 0.9914\n",
      "Epoch 53/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.0201 - val_accuracy: 0.9922\n",
      "Epoch 54/1000\n",
      "570/570 [==============================] - 0s 652us/step - loss: 0.0189 - accuracy: 0.9928 - val_loss: 0.0214 - val_accuracy: 0.9918\n",
      "Epoch 55/1000\n",
      "570/570 [==============================] - 0s 679us/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.0262 - val_accuracy: 0.9902\n",
      "Epoch 56/1000\n",
      "570/570 [==============================] - 0s 559us/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.0215 - val_accuracy: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "570/570 [==============================] - 0s 595us/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 0.0198 - val_accuracy: 0.9935\n",
      "Epoch 58/1000\n",
      "570/570 [==============================] - 0s 727us/step - loss: 0.0189 - accuracy: 0.9930 - val_loss: 0.0251 - val_accuracy: 0.9902\n",
      "Epoch 59/1000\n",
      "570/570 [==============================] - 0s 553us/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.0187 - val_accuracy: 0.9922\n",
      "Epoch 60/1000\n",
      "570/570 [==============================] - 0s 601us/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0192 - val_accuracy: 0.9922\n",
      "Epoch 61/1000\n",
      "570/570 [==============================] - 0s 693us/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.0187 - val_accuracy: 0.9926\n",
      "Epoch 62/1000\n",
      "570/570 [==============================] - 0s 640us/step - loss: 0.0192 - accuracy: 0.9930 - val_loss: 0.0221 - val_accuracy: 0.9889\n",
      "Epoch 63/1000\n",
      "570/570 [==============================] - 0s 622us/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0260 - val_accuracy: 0.9914\n",
      "Epoch 64/1000\n",
      "570/570 [==============================] - 0s 561us/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.0226 - val_accuracy: 0.9922\n",
      "Epoch 65/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0193 - accuracy: 0.9932 - val_loss: 0.0211 - val_accuracy: 0.9910\n",
      "Epoch 66/1000\n",
      "570/570 [==============================] - 0s 701us/step - loss: 0.0193 - accuracy: 0.9926 - val_loss: 0.0192 - val_accuracy: 0.9910\n",
      "Epoch 67/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0181 - val_accuracy: 0.9922\n",
      "Epoch 68/1000\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.0185 - val_accuracy: 0.9930\n",
      "Epoch 69/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0188 - accuracy: 0.9935 - val_loss: 0.0220 - val_accuracy: 0.9918\n",
      "Epoch 70/1000\n",
      "570/570 [==============================] - 0s 568us/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.0188 - val_accuracy: 0.9939\n",
      "Epoch 71/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.0210 - val_accuracy: 0.9918\n",
      "Epoch 72/1000\n",
      "570/570 [==============================] - 0s 648us/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.0208 - val_accuracy: 0.9926\n",
      "Epoch 73/1000\n",
      "570/570 [==============================] - 0s 564us/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.0239 - val_accuracy: 0.9918\n",
      "Epoch 74/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0192 - accuracy: 0.9926 - val_loss: 0.0191 - val_accuracy: 0.9926\n",
      "Epoch 75/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.0191 - val_accuracy: 0.9918\n",
      "Epoch 76/1000\n",
      "570/570 [==============================] - 0s 558us/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.0216 - val_accuracy: 0.9898\n",
      "Epoch 77/1000\n",
      "570/570 [==============================] - 0s 626us/step - loss: 0.0185 - accuracy: 0.9930 - val_loss: 0.0181 - val_accuracy: 0.9922\n",
      "Epoch 78/1000\n",
      "570/570 [==============================] - 0s 604us/step - loss: 0.0186 - accuracy: 0.9930 - val_loss: 0.0215 - val_accuracy: 0.9918\n",
      "Epoch 79/1000\n",
      "570/570 [==============================] - 0s 561us/step - loss: 0.0194 - accuracy: 0.9923 - val_loss: 0.0192 - val_accuracy: 0.9918\n",
      "Epoch 80/1000\n",
      "570/570 [==============================] - 0s 606us/step - loss: 0.0185 - accuracy: 0.9932 - val_loss: 0.0194 - val_accuracy: 0.9926\n",
      "Epoch 81/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.0232 - val_accuracy: 0.9906\n",
      "Epoch 82/1000\n",
      "570/570 [==============================] - 0s 543us/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.0208 - val_accuracy: 0.9930\n",
      "Epoch 83/1000\n",
      "570/570 [==============================] - 0s 631us/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 0.0210 - val_accuracy: 0.9902\n",
      "Epoch 84/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.0219 - val_accuracy: 0.9910\n",
      "Epoch 85/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.0181 - val_accuracy: 0.9918\n",
      "Epoch 86/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.0208 - val_accuracy: 0.9926\n",
      "Epoch 87/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0182 - accuracy: 0.9933 - val_loss: 0.0217 - val_accuracy: 0.9914\n",
      "Epoch 88/1000\n",
      "570/570 [==============================] - 0s 567us/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0182 - val_accuracy: 0.9930\n",
      "Epoch 89/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.0219 - val_accuracy: 0.9918\n",
      "Epoch 90/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0183 - accuracy: 0.9932 - val_loss: 0.0232 - val_accuracy: 0.9914\n",
      "Epoch 91/1000\n",
      "570/570 [==============================] - 0s 556us/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0207 - val_accuracy: 0.9935\n",
      "Epoch 92/1000\n",
      "570/570 [==============================] - 0s 621us/step - loss: 0.0184 - accuracy: 0.9930 - val_loss: 0.0202 - val_accuracy: 0.9918\n",
      "Epoch 93/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.0219 - val_accuracy: 0.9926\n",
      "Epoch 94/1000\n",
      "570/570 [==============================] - 0s 589us/step - loss: 0.0180 - accuracy: 0.9928 - val_loss: 0.0183 - val_accuracy: 0.9939\n",
      "Epoch 95/1000\n",
      "570/570 [==============================] - 0s 702us/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0194 - val_accuracy: 0.9922\n",
      "Epoch 96/1000\n",
      "570/570 [==============================] - 0s 567us/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0208 - val_accuracy: 0.9922\n",
      "Epoch 97/1000\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0190 - accuracy: 0.9930 - val_loss: 0.0217 - val_accuracy: 0.9922\n",
      "Epoch 98/1000\n",
      "570/570 [==============================] - 0s 610us/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0209 - val_accuracy: 0.9914\n",
      "Epoch 99/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.0198 - val_accuracy: 0.9935\n",
      "Epoch 100/1000\n",
      "570/570 [==============================] - 0s 577us/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0192 - val_accuracy: 0.9926\n",
      "Epoch 101/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.0218 - val_accuracy: 0.9910\n",
      "Epoch 102/1000\n",
      "570/570 [==============================] - 0s 553us/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.0213 - val_accuracy: 0.9906\n",
      "Epoch 103/1000\n",
      "570/570 [==============================] - 0s 572us/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.0186 - val_accuracy: 0.9922\n",
      "Epoch 104/1000\n",
      "570/570 [==============================] - 0s 619us/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.0413 - val_accuracy: 0.9849\n",
      "Epoch 105/1000\n",
      "570/570 [==============================] - 0s 568us/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.0197 - val_accuracy: 0.9918\n",
      "Epoch 106/1000\n",
      "570/570 [==============================] - 0s 609us/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0181 - val_accuracy: 0.9930\n",
      "Epoch 107/1000\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.0205 - val_accuracy: 0.9914\n",
      "Epoch 108/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.0208 - val_accuracy: 0.9922\n",
      "Epoch 109/1000\n",
      "570/570 [==============================] - 0s 633us/step - loss: 0.0178 - accuracy: 0.9935 - val_loss: 0.0213 - val_accuracy: 0.9910\n",
      "Epoch 110/1000\n",
      "570/570 [==============================] - 0s 596us/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.0208 - val_accuracy: 0.9918\n",
      "Epoch 111/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.0220 - val_accuracy: 0.9914\n",
      "Epoch 112/1000\n",
      "570/570 [==============================] - 0s 637us/step - loss: 0.0177 - accuracy: 0.9928 - val_loss: 0.0226 - val_accuracy: 0.9906\n",
      "Epoch 113/1000\n",
      "570/570 [==============================] - 0s 656us/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0198 - val_accuracy: 0.9930\n",
      "Epoch 114/1000\n",
      "570/570 [==============================] - 0s 618us/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.0222 - val_accuracy: 0.9922\n",
      "Epoch 115/1000\n",
      "570/570 [==============================] - 0s 674us/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.0230 - val_accuracy: 0.9918\n",
      "Epoch 116/1000\n",
      "570/570 [==============================] - 0s 622us/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.0223 - val_accuracy: 0.9914\n",
      "Epoch 117/1000\n",
      "570/570 [==============================] - 0s 616us/step - loss: 0.0174 - accuracy: 0.9937 - val_loss: 0.0199 - val_accuracy: 0.9926\n",
      "Epoch 118/1000\n",
      "570/570 [==============================] - 0s 714us/step - loss: 0.0171 - accuracy: 0.9937 - val_loss: 0.0204 - val_accuracy: 0.9906\n",
      "Epoch 119/1000\n",
      "570/570 [==============================] - 0s 632us/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.0194 - val_accuracy: 0.9926\n",
      "Epoch 120/1000\n",
      "570/570 [==============================] - 0s 606us/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0237 - val_accuracy: 0.9918\n",
      "Epoch 121/1000\n",
      "570/570 [==============================] - 0s 865us/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.0240 - val_accuracy: 0.9914\n",
      "Epoch 122/1000\n",
      "570/570 [==============================] - 0s 663us/step - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.0225 - val_accuracy: 0.9918\n",
      "Epoch 123/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.0210 - val_accuracy: 0.9926\n",
      "Epoch 124/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0173 - accuracy: 0.9933 - val_loss: 0.0213 - val_accuracy: 0.9930\n",
      "Epoch 125/1000\n",
      "570/570 [==============================] - 0s 550us/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.0238 - val_accuracy: 0.9918\n",
      "Epoch 126/1000\n",
      "570/570 [==============================] - 0s 582us/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0223 - val_accuracy: 0.9914\n",
      "Epoch 127/1000\n",
      "570/570 [==============================] - 0s 567us/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.0203 - val_accuracy: 0.9926\n",
      "Epoch 128/1000\n",
      "570/570 [==============================] - 0s 561us/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.0199 - val_accuracy: 0.9902\n",
      "Epoch 129/1000\n",
      "570/570 [==============================] - 0s 590us/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.0262 - val_accuracy: 0.9910\n",
      "Epoch 130/1000\n",
      "570/570 [==============================] - 0s 559us/step - loss: 0.0176 - accuracy: 0.9935 - val_loss: 0.0189 - val_accuracy: 0.9926\n",
      "Epoch 131/1000\n",
      "570/570 [==============================] - 0s 548us/step - loss: 0.0182 - accuracy: 0.9930 - val_loss: 0.0199 - val_accuracy: 0.9935\n",
      "Epoch 132/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.0272 - val_accuracy: 0.9906\n",
      "Epoch 133/1000\n",
      "570/570 [==============================] - 0s 574us/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.0235 - val_accuracy: 0.9926\n",
      "Epoch 134/1000\n",
      "570/570 [==============================] - 0s 555us/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.0276 - val_accuracy: 0.9914\n",
      "Epoch 135/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.0224 - val_accuracy: 0.9922\n",
      "Epoch 136/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0220 - val_accuracy: 0.9918\n",
      "Epoch 137/1000\n",
      "570/570 [==============================] - 0s 526us/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.0202 - val_accuracy: 0.9935\n",
      "Epoch 138/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.0207 - val_accuracy: 0.9918\n",
      "Epoch 139/1000\n",
      "570/570 [==============================] - 0s 558us/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.0240 - val_accuracy: 0.9918\n",
      "Epoch 140/1000\n",
      "570/570 [==============================] - 0s 539us/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.0211 - val_accuracy: 0.9926\n",
      "Epoch 141/1000\n",
      "570/570 [==============================] - 0s 581us/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 0.0182 - val_accuracy: 0.9926\n",
      "Epoch 142/1000\n",
      "570/570 [==============================] - 0s 565us/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.0194 - val_accuracy: 0.9930\n",
      "Epoch 143/1000\n",
      "570/570 [==============================] - 0s 532us/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.0249 - val_accuracy: 0.9918\n",
      "Epoch 144/1000\n",
      "570/570 [==============================] - 0s 567us/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.0202 - val_accuracy: 0.9906\n",
      "Epoch 145/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0173 - accuracy: 0.9933 - val_loss: 0.0286 - val_accuracy: 0.9902\n",
      "Epoch 146/1000\n",
      "570/570 [==============================] - 0s 545us/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.0232 - val_accuracy: 0.9922\n",
      "Epoch 147/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.0212 - val_accuracy: 0.9922\n",
      "Epoch 148/1000\n",
      "570/570 [==============================] - 0s 579us/step - loss: 0.0167 - accuracy: 0.9933 - val_loss: 0.0229 - val_accuracy: 0.9906\n",
      "Epoch 149/1000\n",
      "570/570 [==============================] - 0s 564us/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 0.0270 - val_accuracy: 0.9889\n",
      "Epoch 150/1000\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.0248 - val_accuracy: 0.9926\n",
      "Epoch 151/1000\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.99 - 0s 580us/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.0202 - val_accuracy: 0.9922\n",
      "Epoch 152/1000\n",
      "570/570 [==============================] - 0s 530us/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0214 - val_accuracy: 0.9926\n",
      "Epoch 153/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.0249 - val_accuracy: 0.9881\n",
      "Epoch 154/1000\n",
      "570/570 [==============================] - 0s 579us/step - loss: 0.0166 - accuracy: 0.9940 - val_loss: 0.0240 - val_accuracy: 0.9906\n",
      "Epoch 155/1000\n",
      "570/570 [==============================] - 0s 726us/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.0202 - val_accuracy: 0.9910\n",
      "Epoch 156/1000\n",
      "570/570 [==============================] - 0s 622us/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.0229 - val_accuracy: 0.9918\n",
      "Epoch 157/1000\n",
      "570/570 [==============================] - 0s 737us/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.0251 - val_accuracy: 0.9926\n",
      "Epoch 158/1000\n",
      "570/570 [==============================] - 0s 762us/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 0.0224 - val_accuracy: 0.9918\n",
      "Epoch 159/1000\n",
      "570/570 [==============================] - 0s 669us/step - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.0215 - val_accuracy: 0.9930\n",
      "Epoch 160/1000\n",
      "570/570 [==============================] - 0s 604us/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.0231 - val_accuracy: 0.9930\n",
      "Epoch 161/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0245 - val_accuracy: 0.9926\n",
      "Epoch 162/1000\n",
      "570/570 [==============================] - 0s 734us/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.0221 - val_accuracy: 0.9918\n",
      "Epoch 163/1000\n",
      "570/570 [==============================] - 0s 777us/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.0232 - val_accuracy: 0.9930\n",
      "Epoch 164/1000\n",
      "570/570 [==============================] - 0s 754us/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0243 - val_accuracy: 0.9898\n",
      "Epoch 165/1000\n",
      "570/570 [==============================] - 0s 649us/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0222 - val_accuracy: 0.9914\n",
      "Epoch 166/1000\n",
      "570/570 [==============================] - 0s 592us/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 0.0229 - val_accuracy: 0.9918\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 577us/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.0202 - val_accuracy: 0.9918\n",
      "Epoch 168/1000\n",
      "570/570 [==============================] - 0s 532us/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.0231 - val_accuracy: 0.9926\n",
      "Epoch 169/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.0321 - val_accuracy: 0.9877\n",
      "Epoch 170/1000\n",
      "570/570 [==============================] - 0s 571us/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 0.0237 - val_accuracy: 0.9894\n",
      "Epoch 171/1000\n",
      "570/570 [==============================] - 0s 534us/step - loss: 0.0173 - accuracy: 0.9930 - val_loss: 0.0247 - val_accuracy: 0.9914\n",
      "Epoch 172/1000\n",
      "570/570 [==============================] - 0s 556us/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0246 - val_accuracy: 0.9922\n",
      "Epoch 173/1000\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0219 - val_accuracy: 0.9926\n",
      "Epoch 174/1000\n",
      "570/570 [==============================] - 0s 546us/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.0226 - val_accuracy: 0.9926\n",
      "Epoch 175/1000\n",
      "570/570 [==============================] - 0s 575us/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.0240 - val_accuracy: 0.9910\n",
      "Epoch 176/1000\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.0213 - val_accuracy: 0.9914\n",
      "Epoch 177/1000\n",
      "570/570 [==============================] - 0s 679us/step - loss: 0.0159 - accuracy: 0.9940 - val_loss: 0.0242 - val_accuracy: 0.9922\n",
      "Epoch 178/1000\n",
      "570/570 [==============================] - 0s 685us/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0200 - val_accuracy: 0.9926\n",
      "Epoch 179/1000\n",
      "570/570 [==============================] - 0s 816us/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.0208 - val_accuracy: 0.9914\n",
      "Epoch 180/1000\n",
      "570/570 [==============================] - 0s 617us/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.0226 - val_accuracy: 0.9926\n",
      "Epoch 181/1000\n",
      "570/570 [==============================] - 0s 633us/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.0212 - val_accuracy: 0.9894\n",
      "Epoch 182/1000\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.99 - 0s 579us/step - loss: 0.0175 - accuracy: 0.9930 - val_loss: 0.0270 - val_accuracy: 0.9910\n",
      "Epoch 183/1000\n",
      "570/570 [==============================] - 0s 547us/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.0198 - val_accuracy: 0.9935\n",
      "Epoch 184/1000\n",
      "570/570 [==============================] - 0s 577us/step - loss: 0.0159 - accuracy: 0.9940 - val_loss: 0.0236 - val_accuracy: 0.9889\n",
      "Epoch 185/1000\n",
      "570/570 [==============================] - 0s 557us/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 0.0251 - val_accuracy: 0.9902\n",
      "Epoch 186/1000\n",
      "570/570 [==============================] - 0s 537us/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0237 - val_accuracy: 0.9926\n",
      "Epoch 187/1000\n",
      "570/570 [==============================] - 0s 585us/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.0225 - val_accuracy: 0.9918\n",
      "Epoch 188/1000\n",
      "570/570 [==============================] - 0s 582us/step - loss: 0.0179 - accuracy: 0.9935 - val_loss: 0.0288 - val_accuracy: 0.9906\n",
      "Epoch 189/1000\n",
      "570/570 [==============================] - 0s 565us/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.0227 - val_accuracy: 0.9930\n",
      "Epoch 190/1000\n",
      "570/570 [==============================] - 0s 747us/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.0224 - val_accuracy: 0.9922\n",
      "Epoch 191/1000\n",
      "570/570 [==============================] - 0s 733us/step - loss: 0.0166 - accuracy: 0.9940 - val_loss: 0.0233 - val_accuracy: 0.9922\n",
      "Epoch 192/1000\n",
      "570/570 [==============================] - 0s 782us/step - loss: 0.0159 - accuracy: 0.9937 - val_loss: 0.0236 - val_accuracy: 0.9889\n",
      "Epoch 193/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.0243 - val_accuracy: 0.9885\n",
      "Epoch 194/1000\n",
      "570/570 [==============================] - 0s 548us/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0223 - val_accuracy: 0.9914\n",
      "Epoch 195/1000\n",
      "570/570 [==============================] - 0s 752us/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0216 - val_accuracy: 0.9922\n",
      "Epoch 196/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.0208 - val_accuracy: 0.9930\n",
      "Epoch 197/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.0200 - val_accuracy: 0.9918\n",
      "Epoch 198/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.0285 - val_accuracy: 0.9918\n",
      "Epoch 199/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 0.0243 - val_accuracy: 0.9935\n",
      "Epoch 200/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 0.0264 - val_accuracy: 0.9926\n",
      "Epoch 201/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.0349 - val_accuracy: 0.9861\n",
      "Epoch 202/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0249 - val_accuracy: 0.9918\n",
      "Epoch 203/1000\n",
      "570/570 [==============================] - 0s 648us/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 0.0252 - val_accuracy: 0.9939\n",
      "Epoch 204/1000\n",
      "570/570 [==============================] - 0s 624us/step - loss: 0.0158 - accuracy: 0.9939 - val_loss: 0.0219 - val_accuracy: 0.9935\n",
      "Epoch 205/1000\n",
      "570/570 [==============================] - 0s 553us/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.0212 - val_accuracy: 0.9930\n",
      "Epoch 206/1000\n",
      "570/570 [==============================] - 0s 614us/step - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.0225 - val_accuracy: 0.9930\n",
      "Epoch 207/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0156 - accuracy: 0.9940 - val_loss: 0.0197 - val_accuracy: 0.9926\n",
      "Epoch 208/1000\n",
      "570/570 [==============================] - 0s 553us/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0233 - val_accuracy: 0.9918\n",
      "Epoch 209/1000\n",
      "570/570 [==============================] - 0s 610us/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.0229 - val_accuracy: 0.9902\n",
      "Epoch 210/1000\n",
      "570/570 [==============================] - 0s 608us/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.0189 - val_accuracy: 0.9926\n",
      "Epoch 211/1000\n",
      "570/570 [==============================] - 0s 545us/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0212 - val_accuracy: 0.9926\n",
      "Epoch 212/1000\n",
      "570/570 [==============================] - 0s 628us/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0209 - val_accuracy: 0.9926\n",
      "Epoch 213/1000\n",
      "570/570 [==============================] - 0s 608us/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0209 - val_accuracy: 0.9943\n",
      "Epoch 214/1000\n",
      "570/570 [==============================] - 0s 546us/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.0245 - val_accuracy: 0.9922\n",
      "Epoch 215/1000\n",
      "570/570 [==============================] - 0s 609us/step - loss: 0.0157 - accuracy: 0.9940 - val_loss: 0.0216 - val_accuracy: 0.9935\n",
      "Epoch 216/1000\n",
      "570/570 [==============================] - 0s 605us/step - loss: 0.0149 - accuracy: 0.9933 - val_loss: 0.0203 - val_accuracy: 0.9939\n",
      "Epoch 217/1000\n",
      "570/570 [==============================] - 0s 552us/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0208 - val_accuracy: 0.9918\n",
      "Epoch 218/1000\n",
      "570/570 [==============================] - 0s 619us/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0243 - val_accuracy: 0.9885\n",
      "Epoch 219/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0227 - val_accuracy: 0.9906\n",
      "Epoch 220/1000\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0154 - accuracy: 0.9935 - val_loss: 0.0207 - val_accuracy: 0.9918\n",
      "Epoch 221/1000\n",
      "570/570 [==============================] - 0s 652us/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 0.0198 - val_accuracy: 0.9922\n",
      "Epoch 222/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.0270 - val_accuracy: 0.9902\n",
      "Epoch 223/1000\n",
      "570/570 [==============================] - 0s 546us/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0249 - val_accuracy: 0.9922\n",
      "Epoch 224/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.0185 - val_accuracy: 0.9926\n",
      "Epoch 225/1000\n",
      "570/570 [==============================] - 0s 590us/step - loss: 0.0156 - accuracy: 0.9940 - val_loss: 0.0223 - val_accuracy: 0.9914\n",
      "Epoch 226/1000\n",
      "570/570 [==============================] - 0s 565us/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.0183 - val_accuracy: 0.9935\n",
      "Epoch 227/1000\n",
      "570/570 [==============================] - 0s 614us/step - loss: 0.0152 - accuracy: 0.9939 - val_loss: 0.0217 - val_accuracy: 0.9943\n",
      "Epoch 228/1000\n",
      "570/570 [==============================] - 0s 582us/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0201 - val_accuracy: 0.9939\n",
      "Epoch 229/1000\n",
      "570/570 [==============================] - 0s 546us/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.0234 - val_accuracy: 0.9922\n",
      "Epoch 230/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0156 - accuracy: 0.9944 - val_loss: 0.0209 - val_accuracy: 0.9922\n",
      "Epoch 231/1000\n",
      "570/570 [==============================] - 0s 589us/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0236 - val_accuracy: 0.9926\n",
      "Epoch 232/1000\n",
      "570/570 [==============================] - 0s 557us/step - loss: 0.0174 - accuracy: 0.9930 - val_loss: 0.0311 - val_accuracy: 0.9865\n",
      "Epoch 233/1000\n",
      "570/570 [==============================] - 0s 610us/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.0214 - val_accuracy: 0.9914\n",
      "Epoch 234/1000\n",
      "570/570 [==============================] - 0s 579us/step - loss: 0.0155 - accuracy: 0.9940 - val_loss: 0.0203 - val_accuracy: 0.9939\n",
      "Epoch 235/1000\n",
      "570/570 [==============================] - 0s 624us/step - loss: 0.0153 - accuracy: 0.9940 - val_loss: 0.0187 - val_accuracy: 0.9914\n",
      "Epoch 236/1000\n",
      "570/570 [==============================] - 0s 661us/step - loss: 0.0156 - accuracy: 0.9944 - val_loss: 0.0209 - val_accuracy: 0.9922\n",
      "Epoch 237/1000\n",
      "570/570 [==============================] - 0s 618us/step - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.0216 - val_accuracy: 0.9918\n",
      "Epoch 238/1000\n",
      "570/570 [==============================] - 0s 616us/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.0244 - val_accuracy: 0.9922\n",
      "Epoch 239/1000\n",
      "570/570 [==============================] - 0s 650us/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0224 - val_accuracy: 0.9910\n",
      "Epoch 240/1000\n",
      "570/570 [==============================] - 0s 549us/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0251 - val_accuracy: 0.9914\n",
      "Epoch 241/1000\n",
      "570/570 [==============================] - 0s 588us/step - loss: 0.0155 - accuracy: 0.9940 - val_loss: 0.0231 - val_accuracy: 0.9918\n",
      "Epoch 242/1000\n",
      "570/570 [==============================] - 0s 614us/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.0208 - val_accuracy: 0.9926\n",
      "Epoch 243/1000\n",
      "570/570 [==============================] - 0s 558us/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.0222 - val_accuracy: 0.9918\n",
      "Epoch 244/1000\n",
      "570/570 [==============================] - 0s 596us/step - loss: 0.0148 - accuracy: 0.9946 - val_loss: 0.0225 - val_accuracy: 0.9922\n",
      "Epoch 245/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.0237 - val_accuracy: 0.9910\n",
      "Epoch 246/1000\n",
      "570/570 [==============================] - 0s 550us/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.0183 - val_accuracy: 0.9914\n",
      "Epoch 247/1000\n",
      "570/570 [==============================] - 0s 577us/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.0201 - val_accuracy: 0.9898\n",
      "Epoch 248/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.0342 - val_accuracy: 0.9877\n",
      "Epoch 249/1000\n",
      "570/570 [==============================] - 0s 547us/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0235 - val_accuracy: 0.9926\n",
      "Epoch 250/1000\n",
      "570/570 [==============================] - 0s 616us/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.0193 - val_accuracy: 0.9939\n",
      "Epoch 251/1000\n",
      "570/570 [==============================] - 0s 606us/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.0208 - val_accuracy: 0.9914\n",
      "Epoch 252/1000\n",
      "570/570 [==============================] - 0s 545us/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0215 - val_accuracy: 0.9922\n",
      "Epoch 253/1000\n",
      "570/570 [==============================] - 0s 724us/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0187 - val_accuracy: 0.9930\n",
      "Epoch 254/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.0244 - val_accuracy: 0.9906\n",
      "Epoch 255/1000\n",
      "570/570 [==============================] - 0s 543us/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.0222 - val_accuracy: 0.9939\n",
      "Epoch 256/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0250 - val_accuracy: 0.9930\n",
      "Epoch 257/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0185 - val_accuracy: 0.9914\n",
      "Epoch 258/1000\n",
      "570/570 [==============================] - 0s 538us/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.0271 - val_accuracy: 0.9885\n",
      "Epoch 259/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.0207 - val_accuracy: 0.9930\n",
      "Epoch 260/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0201 - val_accuracy: 0.9914\n",
      "Epoch 261/1000\n",
      "570/570 [==============================] - 0s 545us/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0202 - val_accuracy: 0.9930\n",
      "Epoch 262/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0207 - val_accuracy: 0.9918\n",
      "Epoch 263/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.0192 - val_accuracy: 0.9930\n",
      "Epoch 264/1000\n",
      "570/570 [==============================] - 0s 544us/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.0230 - val_accuracy: 0.9906\n",
      "Epoch 265/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.0202 - val_accuracy: 0.9930\n",
      "Epoch 266/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.0229 - val_accuracy: 0.9922\n",
      "Epoch 267/1000\n",
      "570/570 [==============================] - 0s 540us/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0217 - val_accuracy: 0.9910\n",
      "Epoch 268/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.0210 - val_accuracy: 0.9935\n",
      "Epoch 269/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0226 - val_accuracy: 0.9918\n",
      "Epoch 270/1000\n",
      "570/570 [==============================] - 0s 542us/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0176 - val_accuracy: 0.9930\n",
      "Epoch 271/1000\n",
      "570/570 [==============================] - 0s 647us/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.0203 - val_accuracy: 0.9922\n",
      "Epoch 272/1000\n",
      "570/570 [==============================] - 0s 597us/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.0211 - val_accuracy: 0.9914\n",
      "Epoch 273/1000\n",
      "570/570 [==============================] - 0s 575us/step - loss: 0.0152 - accuracy: 0.9944 - val_loss: 0.0215 - val_accuracy: 0.9910\n",
      "Epoch 274/1000\n",
      "570/570 [==============================] - 0s 660us/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.0198 - val_accuracy: 0.9914\n",
      "Epoch 275/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.0264 - val_accuracy: 0.9914\n",
      "Epoch 276/1000\n",
      "570/570 [==============================] - 0s 557us/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.0199 - val_accuracy: 0.9926\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 600us/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0235 - val_accuracy: 0.9930\n",
      "Epoch 278/1000\n",
      "570/570 [==============================] - 0s 621us/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.0261 - val_accuracy: 0.9910\n",
      "Epoch 279/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.0280 - val_accuracy: 0.9914\n",
      "Epoch 280/1000\n",
      "570/570 [==============================] - 0s 622us/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0263 - val_accuracy: 0.9926\n",
      "Epoch 281/1000\n",
      "570/570 [==============================] - 0s 581us/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.0213 - val_accuracy: 0.9914\n",
      "Epoch 282/1000\n",
      "570/570 [==============================] - 0s 556us/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.0191 - val_accuracy: 0.9930\n",
      "Epoch 283/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0140 - accuracy: 0.9944 - val_loss: 0.0212 - val_accuracy: 0.9906\n",
      "Epoch 284/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0144 - accuracy: 0.9946 - val_loss: 0.0207 - val_accuracy: 0.9922\n",
      "Epoch 285/1000\n",
      "570/570 [==============================] - 0s 556us/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.0237 - val_accuracy: 0.9930\n",
      "Epoch 286/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.0226 - val_accuracy: 0.9914\n",
      "Epoch 287/1000\n",
      "570/570 [==============================] - 0s 581us/step - loss: 0.0147 - accuracy: 0.9942 - val_loss: 0.0273 - val_accuracy: 0.9914\n",
      "Epoch 288/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.0297 - val_accuracy: 0.9918\n",
      "Epoch 289/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.0244 - val_accuracy: 0.9914\n",
      "Epoch 290/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0205 - val_accuracy: 0.9918\n",
      "Epoch 291/1000\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.0185 - val_accuracy: 0.9922\n",
      "Epoch 292/1000\n",
      "570/570 [==============================] - 0s 588us/step - loss: 0.0141 - accuracy: 0.9946 - val_loss: 0.0191 - val_accuracy: 0.9939\n",
      "Epoch 293/1000\n",
      "570/570 [==============================] - 0s 583us/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.0278 - val_accuracy: 0.9914\n",
      "Epoch 294/1000\n",
      "570/570 [==============================] - 0s 597us/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0238 - val_accuracy: 0.9930\n",
      "Epoch 295/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0204 - val_accuracy: 0.9914\n",
      "Epoch 296/1000\n",
      "570/570 [==============================] - 0s 590us/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.0251 - val_accuracy: 0.9906\n",
      "Epoch 297/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.0295 - val_accuracy: 0.9914\n",
      "Epoch 298/1000\n",
      "570/570 [==============================] - 0s 633us/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.0246 - val_accuracy: 0.9918\n",
      "Epoch 299/1000\n",
      "570/570 [==============================] - 0s 568us/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.0258 - val_accuracy: 0.9918\n",
      "Epoch 300/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0222 - val_accuracy: 0.9922\n",
      "Epoch 301/1000\n",
      "570/570 [==============================] - 0s 664us/step - loss: 0.0144 - accuracy: 0.9946 - val_loss: 0.0200 - val_accuracy: 0.9922\n",
      "Epoch 302/1000\n",
      "570/570 [==============================] - 0s 587us/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.0180 - val_accuracy: 0.9914\n",
      "Epoch 303/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.0212 - val_accuracy: 0.9930\n",
      "Epoch 304/1000\n",
      "570/570 [==============================] - 0s 630us/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.0234 - val_accuracy: 0.9922\n",
      "Epoch 305/1000\n",
      "570/570 [==============================] - 0s 617us/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0241 - val_accuracy: 0.9918\n",
      "Epoch 306/1000\n",
      "570/570 [==============================] - 0s 621us/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.0210 - val_accuracy: 0.9918\n",
      "Epoch 307/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.0240 - val_accuracy: 0.9914\n",
      "Epoch 308/1000\n",
      "570/570 [==============================] - 0s 616us/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.0268 - val_accuracy: 0.9910\n",
      "Epoch 309/1000\n",
      "570/570 [==============================] - 0s 724us/step - loss: 0.0148 - accuracy: 0.9946 - val_loss: 0.0212 - val_accuracy: 0.9922\n",
      "Epoch 310/1000\n",
      "570/570 [==============================] - 0s 595us/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.0270 - val_accuracy: 0.9906\n",
      "Epoch 311/1000\n",
      "570/570 [==============================] - 0s 583us/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.0221 - val_accuracy: 0.9943\n",
      "Epoch 312/1000\n",
      "570/570 [==============================] - 0s 601us/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.0320 - val_accuracy: 0.9918\n",
      "Epoch 313/1000\n",
      "570/570 [==============================] - 0s 604us/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.0231 - val_accuracy: 0.9914\n",
      "Epoch 314/1000\n",
      "570/570 [==============================] - 0s 597us/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.0264 - val_accuracy: 0.9930\n",
      "Epoch 315/1000\n",
      "570/570 [==============================] - 0s 679us/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.0214 - val_accuracy: 0.9922\n",
      "Epoch 316/1000\n",
      "570/570 [==============================] - 0s 658us/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0189 - val_accuracy: 0.9935\n",
      "Epoch 317/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.0229 - val_accuracy: 0.9918\n",
      "Epoch 318/1000\n",
      "570/570 [==============================] - 0s 714us/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.0227 - val_accuracy: 0.9922\n",
      "Epoch 319/1000\n",
      "570/570 [==============================] - 0s 654us/step - loss: 0.0147 - accuracy: 0.9944 - val_loss: 0.0210 - val_accuracy: 0.9926\n",
      "Epoch 320/1000\n",
      "570/570 [==============================] - 0s 642us/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0192 - val_accuracy: 0.9943\n",
      "Epoch 321/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0144 - accuracy: 0.9946 - val_loss: 0.0218 - val_accuracy: 0.9926\n",
      "Epoch 322/1000\n",
      "570/570 [==============================] - 0s 604us/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.0218 - val_accuracy: 0.9926\n",
      "Epoch 323/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0156 - accuracy: 0.9944 - val_loss: 0.0246 - val_accuracy: 0.9906\n",
      "Epoch 324/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.0204 - val_accuracy: 0.9922\n",
      "Epoch 325/1000\n",
      "570/570 [==============================] - 0s 567us/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.0210 - val_accuracy: 0.9914\n",
      "Epoch 326/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.0242 - val_accuracy: 0.9930\n",
      "Epoch 327/1000\n",
      "570/570 [==============================] - 0s 588us/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.0209 - val_accuracy: 0.9922\n",
      "Epoch 328/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.0233 - val_accuracy: 0.9926\n",
      "Epoch 329/1000\n",
      "570/570 [==============================] - 0s 605us/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0254 - val_accuracy: 0.9930\n",
      "Epoch 330/1000\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0146 - accuracy: 0.9944 - val_loss: 0.0285 - val_accuracy: 0.9918\n",
      "Epoch 331/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0146 - accuracy: 0.9940 - val_loss: 0.0194 - val_accuracy: 0.9926\n",
      "Epoch 332/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.0236 - val_accuracy: 0.9935\n",
      "Epoch 333/1000\n",
      "570/570 [==============================] - 0s 568us/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.0205 - val_accuracy: 0.9943\n",
      "Epoch 334/1000\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0255 - val_accuracy: 0.9918\n",
      "Epoch 335/1000\n",
      "570/570 [==============================] - 0s 606us/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0228 - val_accuracy: 0.9926\n",
      "Epoch 336/1000\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0141 - accuracy: 0.9940 - val_loss: 0.0192 - val_accuracy: 0.9922\n",
      "Epoch 337/1000\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.0244 - val_accuracy: 0.9906\n",
      "Epoch 338/1000\n",
      "570/570 [==============================] - 0s 626us/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.0222 - val_accuracy: 0.9914\n",
      "Epoch 339/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.0227 - val_accuracy: 0.9914\n",
      "Epoch 340/1000\n",
      "570/570 [==============================] - 0s 589us/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0220 - val_accuracy: 0.9943\n",
      "Epoch 341/1000\n",
      "570/570 [==============================] - 0s 592us/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.0214 - val_accuracy: 0.9930\n",
      "Epoch 342/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0229 - val_accuracy: 0.9922\n",
      "Epoch 343/1000\n",
      "570/570 [==============================] - 0s 592us/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0249 - val_accuracy: 0.9918\n",
      "Epoch 344/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0137 - accuracy: 0.9946 - val_loss: 0.0241 - val_accuracy: 0.9943\n",
      "Epoch 345/1000\n",
      "570/570 [==============================] - 0s 556us/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.0230 - val_accuracy: 0.9939\n",
      "Epoch 346/1000\n",
      "570/570 [==============================] - 0s 575us/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0226 - val_accuracy: 0.9922\n",
      "Epoch 347/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0139 - accuracy: 0.9946 - val_loss: 0.0223 - val_accuracy: 0.9935\n",
      "Epoch 348/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.0271 - val_accuracy: 0.9930\n",
      "Epoch 349/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.0219 - val_accuracy: 0.9939\n",
      "Epoch 350/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.0262 - val_accuracy: 0.9918\n",
      "Epoch 351/1000\n",
      "570/570 [==============================] - 0s 558us/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.0213 - val_accuracy: 0.9926\n",
      "Epoch 352/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.0211 - val_accuracy: 0.9939\n",
      "Epoch 353/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0164 - accuracy: 0.9935 - val_loss: 0.0218 - val_accuracy: 0.9898\n",
      "Epoch 354/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.0239 - val_accuracy: 0.9930\n",
      "Epoch 355/1000\n",
      "570/570 [==============================] - 0s 614us/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.0253 - val_accuracy: 0.9914\n",
      "Epoch 356/1000\n",
      "570/570 [==============================] - 0s 604us/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.0281 - val_accuracy: 0.9902\n",
      "Epoch 357/1000\n",
      "570/570 [==============================] - 0s 555us/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0198 - val_accuracy: 0.9922\n",
      "Epoch 358/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0256 - val_accuracy: 0.9898\n",
      "Epoch 359/1000\n",
      "570/570 [==============================] - 0s 609us/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.0222 - val_accuracy: 0.9930\n",
      "Epoch 360/1000\n",
      "570/570 [==============================] - 0s 555us/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.0263 - val_accuracy: 0.9922\n",
      "Epoch 361/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.0219 - val_accuracy: 0.9906\n",
      "Epoch 362/1000\n",
      "570/570 [==============================] - 0s 617us/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0218 - val_accuracy: 0.9914\n",
      "Epoch 363/1000\n",
      "570/570 [==============================] - 0s 556us/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0231 - val_accuracy: 0.9930\n",
      "Epoch 364/1000\n",
      "570/570 [==============================] - 0s 601us/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.0209 - val_accuracy: 0.9935\n",
      "Epoch 365/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.0228 - val_accuracy: 0.9910\n",
      "Epoch 366/1000\n",
      "570/570 [==============================] - 0s 553us/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0247 - val_accuracy: 0.9926\n",
      "Epoch 367/1000\n",
      "570/570 [==============================] - 0s 644us/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0224 - val_accuracy: 0.9922\n",
      "Epoch 368/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0236 - val_accuracy: 0.9935\n",
      "Epoch 369/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0228 - val_accuracy: 0.9926\n",
      "Epoch 370/1000\n",
      "570/570 [==============================] - 0s 611us/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.0233 - val_accuracy: 0.9918\n",
      "Epoch 371/1000\n",
      "570/570 [==============================] - 0s 595us/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.0256 - val_accuracy: 0.9918\n",
      "Epoch 372/1000\n",
      "570/570 [==============================] - 0s 547us/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0270 - val_accuracy: 0.9910\n",
      "Epoch 373/1000\n",
      "570/570 [==============================] - 0s 610us/step - loss: 0.0144 - accuracy: 0.9944 - val_loss: 0.0274 - val_accuracy: 0.9898\n",
      "Epoch 374/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.0220 - val_accuracy: 0.9922\n",
      "Epoch 375/1000\n",
      "570/570 [==============================] - 0s 547us/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0329 - val_accuracy: 0.9910\n",
      "Epoch 376/1000\n",
      "570/570 [==============================] - 0s 614us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0234 - val_accuracy: 0.9926\n",
      "Epoch 377/1000\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0237 - val_accuracy: 0.9935\n",
      "Epoch 378/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0236 - val_accuracy: 0.9910\n",
      "Epoch 379/1000\n",
      "570/570 [==============================] - 0s 700us/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0246 - val_accuracy: 0.9906\n",
      "Epoch 380/1000\n",
      "570/570 [==============================] - 0s 641us/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0221 - val_accuracy: 0.9939\n",
      "Epoch 381/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.0248 - val_accuracy: 0.9935\n",
      "Epoch 382/1000\n",
      "570/570 [==============================] - 0s 667us/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.0261 - val_accuracy: 0.9930\n",
      "Epoch 383/1000\n",
      "570/570 [==============================] - 0s 596us/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0297 - val_accuracy: 0.9906\n",
      "Epoch 384/1000\n",
      "570/570 [==============================] - 0s 643us/step - loss: 0.0147 - accuracy: 0.9944 - val_loss: 0.0292 - val_accuracy: 0.9926\n",
      "Epoch 385/1000\n",
      "570/570 [==============================] - 0s 726us/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.0286 - val_accuracy: 0.9926\n",
      "Epoch 386/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 628us/step - loss: 0.0141 - accuracy: 0.9946 - val_loss: 0.0259 - val_accuracy: 0.9930\n",
      "Epoch 388/1000\n",
      "570/570 [==============================] - 0s 638us/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0259 - val_accuracy: 0.9922\n",
      "Epoch 389/1000\n",
      "570/570 [==============================] - 0s 553us/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.0230 - val_accuracy: 0.9939\n",
      "Epoch 390/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0221 - val_accuracy: 0.9922\n",
      "Epoch 391/1000\n",
      "570/570 [==============================] - 0s 605us/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0265 - val_accuracy: 0.9914\n",
      "Epoch 392/1000\n",
      "570/570 [==============================] - 0s 631us/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.0255 - val_accuracy: 0.9930\n",
      "Epoch 393/1000\n",
      "570/570 [==============================] - 0s 646us/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0298 - val_accuracy: 0.9926\n",
      "Epoch 394/1000\n",
      "570/570 [==============================] - 0s 611us/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.0216 - val_accuracy: 0.9935\n",
      "Epoch 395/1000\n",
      "570/570 [==============================] - 0s 579us/step - loss: 0.0141 - accuracy: 0.9946 - val_loss: 0.0270 - val_accuracy: 0.9939\n",
      "Epoch 396/1000\n",
      "570/570 [==============================] - 0s 636us/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.0270 - val_accuracy: 0.9914\n",
      "Epoch 397/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.0267 - val_accuracy: 0.9930\n",
      "Epoch 398/1000\n",
      "570/570 [==============================] - 0s 575us/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0256 - val_accuracy: 0.9926\n",
      "Epoch 399/1000\n",
      "570/570 [==============================] - 0s 605us/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0277 - val_accuracy: 0.9935\n",
      "Epoch 400/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0277 - val_accuracy: 0.9914\n",
      "Epoch 401/1000\n",
      "570/570 [==============================] - 0s 582us/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0226 - val_accuracy: 0.9926\n",
      "Epoch 402/1000\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.0316 - val_accuracy: 0.9935\n",
      "Epoch 403/1000\n",
      "570/570 [==============================] - 0s 574us/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0281 - val_accuracy: 0.9930\n",
      "Epoch 404/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0237 - val_accuracy: 0.9943\n",
      "Epoch 405/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0254 - val_accuracy: 0.9914\n",
      "Epoch 406/1000\n",
      "570/570 [==============================] - 0s 564us/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0278 - val_accuracy: 0.9918\n",
      "Epoch 407/1000\n",
      "570/570 [==============================] - 0s 574us/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0262 - val_accuracy: 0.9939\n",
      "Epoch 408/1000\n",
      "570/570 [==============================] - 0s 609us/step - loss: 0.0143 - accuracy: 0.9944 - val_loss: 0.0235 - val_accuracy: 0.9930\n",
      "Epoch 409/1000\n",
      "570/570 [==============================] - 0s 572us/step - loss: 0.0142 - accuracy: 0.9944 - val_loss: 0.0231 - val_accuracy: 0.9943\n",
      "Epoch 410/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.0239 - val_accuracy: 0.9922\n",
      "Epoch 411/1000\n",
      "570/570 [==============================] - 0s 618us/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0253 - val_accuracy: 0.9926\n",
      "Epoch 412/1000\n",
      "570/570 [==============================] - 0s 561us/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.0224 - val_accuracy: 0.9922\n",
      "Epoch 413/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.0246 - val_accuracy: 0.9930\n",
      "Epoch 414/1000\n",
      "570/570 [==============================] - 0s 633us/step - loss: 0.0138 - accuracy: 0.9947 - val_loss: 0.0302 - val_accuracy: 0.9922\n",
      "Epoch 415/1000\n",
      "570/570 [==============================] - 0s 558us/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0249 - val_accuracy: 0.9926\n",
      "Epoch 416/1000\n",
      "570/570 [==============================] - 0s 581us/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0226 - val_accuracy: 0.9939\n",
      "Epoch 417/1000\n",
      "570/570 [==============================] - 0s 616us/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0243 - val_accuracy: 0.9930\n",
      "Epoch 418/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.0246 - val_accuracy: 0.9939\n",
      "Epoch 419/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0256 - val_accuracy: 0.9926\n",
      "Epoch 420/1000\n",
      "570/570 [==============================] - 0s 633us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0239 - val_accuracy: 0.9930\n",
      "Epoch 421/1000\n",
      "570/570 [==============================] - 0s 555us/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0234 - val_accuracy: 0.9922\n",
      "Epoch 422/1000\n",
      "570/570 [==============================] - 0s 592us/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.0230 - val_accuracy: 0.9939\n",
      "Epoch 423/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.0272 - val_accuracy: 0.9918\n",
      "Epoch 424/1000\n",
      "570/570 [==============================] - 0s 550us/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0269 - val_accuracy: 0.9935\n",
      "Epoch 425/1000\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.0274 - val_accuracy: 0.9930\n",
      "Epoch 426/1000\n",
      "570/570 [==============================] - 0s 639us/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.0313 - val_accuracy: 0.9939\n",
      "Epoch 427/1000\n",
      "570/570 [==============================] - 0s 555us/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0302 - val_accuracy: 0.9930\n",
      "Epoch 428/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0248 - val_accuracy: 0.9930\n",
      "Epoch 429/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.0302 - val_accuracy: 0.9930\n",
      "Epoch 430/1000\n",
      "570/570 [==============================] - 0s 557us/step - loss: 0.0136 - accuracy: 0.9946 - val_loss: 0.0295 - val_accuracy: 0.9922\n",
      "Epoch 431/1000\n",
      "570/570 [==============================] - 0s 622us/step - loss: 0.0144 - accuracy: 0.9946 - val_loss: 0.0254 - val_accuracy: 0.9918\n",
      "Epoch 432/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0283 - val_accuracy: 0.9930\n",
      "Epoch 433/1000\n",
      "570/570 [==============================] - 0s 550us/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0333 - val_accuracy: 0.9922\n",
      "Epoch 434/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0225 - val_accuracy: 0.9930\n",
      "Epoch 435/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0235 - val_accuracy: 0.9918\n",
      "Epoch 436/1000\n",
      "570/570 [==============================] - 0s 562us/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0347 - val_accuracy: 0.9926\n",
      "Epoch 437/1000\n",
      "570/570 [==============================] - 0s 626us/step - loss: 0.0148 - accuracy: 0.9946 - val_loss: 0.0263 - val_accuracy: 0.9926\n",
      "Epoch 438/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0128 - accuracy: 0.9944 - val_loss: 0.0303 - val_accuracy: 0.9910\n",
      "Epoch 439/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0264 - val_accuracy: 0.9914\n",
      "Epoch 440/1000\n",
      "570/570 [==============================] - 0s 605us/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0283 - val_accuracy: 0.9918\n",
      "Epoch 441/1000\n",
      "570/570 [==============================] - 0s 590us/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0327 - val_accuracy: 0.9889\n",
      "Epoch 442/1000\n",
      "570/570 [==============================] - 0s 564us/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.0257 - val_accuracy: 0.9918\n",
      "Epoch 443/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.0290 - val_accuracy: 0.9914\n",
      "Epoch 444/1000\n",
      "570/570 [==============================] - 0s 584us/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0297 - val_accuracy: 0.9914\n",
      "Epoch 445/1000\n",
      "570/570 [==============================] - 0s 565us/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0280 - val_accuracy: 0.9926\n",
      "Epoch 446/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.0302 - val_accuracy: 0.9935\n",
      "Epoch 447/1000\n",
      "570/570 [==============================] - 0s 583us/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.0278 - val_accuracy: 0.9939\n",
      "Epoch 448/1000\n",
      "570/570 [==============================] - 0s 565us/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.0376 - val_accuracy: 0.9918\n",
      "Epoch 449/1000\n",
      "570/570 [==============================] - 0s 617us/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0239 - val_accuracy: 0.9922\n",
      "Epoch 450/1000\n",
      "570/570 [==============================] - 0s 583us/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0312 - val_accuracy: 0.9902\n",
      "Epoch 451/1000\n",
      "570/570 [==============================] - 0s 562us/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.0290 - val_accuracy: 0.9930\n",
      "Epoch 452/1000\n",
      "570/570 [==============================] - 0s 630us/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.0246 - val_accuracy: 0.9930\n",
      "Epoch 453/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0270 - val_accuracy: 0.9935\n",
      "Epoch 454/1000\n",
      "570/570 [==============================] - 0s 583us/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.0217 - val_accuracy: 0.9935\n",
      "Epoch 455/1000\n",
      "570/570 [==============================] - 0s 669us/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.0259 - val_accuracy: 0.9943\n",
      "Epoch 456/1000\n",
      "570/570 [==============================] - 0s 589us/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.0267 - val_accuracy: 0.9930\n",
      "Epoch 457/1000\n",
      "570/570 [==============================] - 0s 609us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0252 - val_accuracy: 0.9930\n",
      "Epoch 458/1000\n",
      "570/570 [==============================] - 0s 624us/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0305 - val_accuracy: 0.9918\n",
      "Epoch 459/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0313 - val_accuracy: 0.9930\n",
      "Epoch 460/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.0339 - val_accuracy: 0.9926\n",
      "Epoch 461/1000\n",
      "570/570 [==============================] - 0s 635us/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.0317 - val_accuracy: 0.9935\n",
      "Epoch 462/1000\n",
      "570/570 [==============================] - 0s 558us/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0245 - val_accuracy: 0.9918\n",
      "Epoch 463/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0419 - val_accuracy: 0.9898\n",
      "Epoch 464/1000\n",
      "570/570 [==============================] - 0s 632us/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.0249 - val_accuracy: 0.9918\n",
      "Epoch 465/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.0232 - val_accuracy: 0.9930\n",
      "Epoch 466/1000\n",
      "570/570 [==============================] - 0s 644us/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.0237 - val_accuracy: 0.9922\n",
      "Epoch 467/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0277 - val_accuracy: 0.9930\n",
      "Epoch 468/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0144 - accuracy: 0.9944 - val_loss: 0.0325 - val_accuracy: 0.9922\n",
      "Epoch 469/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0295 - val_accuracy: 0.9914\n",
      "Epoch 470/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.0302 - val_accuracy: 0.9926\n",
      "Epoch 471/1000\n",
      "570/570 [==============================] - 0s 590us/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.0261 - val_accuracy: 0.9898\n",
      "Epoch 472/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.0249 - val_accuracy: 0.9930\n",
      "Epoch 473/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0280 - val_accuracy: 0.9926\n",
      "Epoch 474/1000\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0271 - val_accuracy: 0.9914\n",
      "Epoch 475/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0403 - val_accuracy: 0.9926\n",
      "Epoch 476/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.0312 - val_accuracy: 0.9910\n",
      "Epoch 477/1000\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.0308 - val_accuracy: 0.9918\n",
      "Epoch 478/1000\n",
      "570/570 [==============================] - 0s 609us/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.0294 - val_accuracy: 0.9922\n",
      "Epoch 479/1000\n",
      "570/570 [==============================] - 0s 589us/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.0295 - val_accuracy: 0.9922\n",
      "Epoch 480/1000\n",
      "570/570 [==============================] - 0s 590us/step - loss: 0.0137 - accuracy: 0.9946 - val_loss: 0.0282 - val_accuracy: 0.9926\n",
      "Epoch 481/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.0279 - val_accuracy: 0.9926\n",
      "Epoch 482/1000\n",
      "570/570 [==============================] - 0s 575us/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0295 - val_accuracy: 0.9930\n",
      "Epoch 483/1000\n",
      "570/570 [==============================] - 0s 590us/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
      "Epoch 484/1000\n",
      "570/570 [==============================] - 0s 645us/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.0278 - val_accuracy: 0.9918\n",
      "Epoch 485/1000\n",
      "570/570 [==============================] - 0s 568us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0317 - val_accuracy: 0.9906\n",
      "Epoch 486/1000\n",
      "570/570 [==============================] - 0s 589us/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.0264 - val_accuracy: 0.9918\n",
      "Epoch 487/1000\n",
      "570/570 [==============================] - 0s 610us/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0299 - val_accuracy: 0.9906\n",
      "Epoch 488/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0329 - val_accuracy: 0.9922\n",
      "Epoch 489/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0308 - val_accuracy: 0.9939\n",
      "Epoch 490/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0342 - val_accuracy: 0.9918\n",
      "Epoch 491/1000\n",
      "570/570 [==============================] - 0s 568us/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0321 - val_accuracy: 0.9926\n",
      "Epoch 492/1000\n",
      "570/570 [==============================] - 0s 595us/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.0367 - val_accuracy: 0.9894\n",
      "Epoch 493/1000\n",
      "570/570 [==============================] - 0s 611us/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.0299 - val_accuracy: 0.9898\n",
      "Epoch 494/1000\n",
      "570/570 [==============================] - 0s 564us/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0300 - val_accuracy: 0.9930\n",
      "Epoch 495/1000\n",
      "570/570 [==============================] - 0s 601us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0314 - val_accuracy: 0.9910\n",
      "Epoch 496/1000\n",
      "570/570 [==============================] - 0s 609us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0315 - val_accuracy: 0.9918\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.99 - 0s 570us/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0319 - val_accuracy: 0.9914\n",
      "Epoch 498/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.0310 - val_accuracy: 0.9914\n",
      "Epoch 499/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0273 - val_accuracy: 0.9918\n",
      "Epoch 500/1000\n",
      "570/570 [==============================] - 0s 553us/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0255 - val_accuracy: 0.9930\n",
      "Epoch 501/1000\n",
      "570/570 [==============================] - 0s 606us/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.0312 - val_accuracy: 0.9922\n",
      "Epoch 502/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.0316 - val_accuracy: 0.9910\n",
      "Epoch 503/1000\n",
      "570/570 [==============================] - 0s 585us/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.0420 - val_accuracy: 0.9930\n",
      "Epoch 504/1000\n",
      "570/570 [==============================] - 0s 640us/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0899 - val_accuracy: 0.9902\n",
      "Epoch 505/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 0.0328 - val_accuracy: 0.9935\n",
      "Epoch 506/1000\n",
      "570/570 [==============================] - 0s 556us/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.0315 - val_accuracy: 0.9935\n",
      "Epoch 507/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0333 - val_accuracy: 0.9926\n",
      "Epoch 508/1000\n",
      "570/570 [==============================] - 0s 597us/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.0335 - val_accuracy: 0.9935\n",
      "Epoch 509/1000\n",
      "570/570 [==============================] - 0s 564us/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0389 - val_accuracy: 0.9918\n",
      "Epoch 510/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0127 - accuracy: 0.9947 - val_loss: 0.0307 - val_accuracy: 0.9914\n",
      "Epoch 511/1000\n",
      "570/570 [==============================] - 0s 588us/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0337 - val_accuracy: 0.9939\n",
      "Epoch 512/1000\n",
      "570/570 [==============================] - 0s 575us/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.0274 - val_accuracy: 0.9935\n",
      "Epoch 513/1000\n",
      "570/570 [==============================] - 0s 649us/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0283 - val_accuracy: 0.9914\n",
      "Epoch 514/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0120 - accuracy: 0.9953 - val_loss: 0.0379 - val_accuracy: 0.9910\n",
      "Epoch 515/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0396 - val_accuracy: 0.9930\n",
      "Epoch 516/1000\n",
      "570/570 [==============================] - 0s 633us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0354 - val_accuracy: 0.9914\n",
      "Epoch 517/1000\n",
      "570/570 [==============================] - 0s 588us/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.0409 - val_accuracy: 0.9922\n",
      "Epoch 518/1000\n",
      "570/570 [==============================] - 0s 596us/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0315 - val_accuracy: 0.9918\n",
      "Epoch 519/1000\n",
      "570/570 [==============================] - 0s 650us/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 0.0337 - val_accuracy: 0.9930\n",
      "Epoch 520/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0320 - val_accuracy: 0.9918\n",
      "Epoch 521/1000\n",
      "570/570 [==============================] - 0s 754us/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0306 - val_accuracy: 0.9926\n",
      "Epoch 522/1000\n",
      "570/570 [==============================] - 0s 626us/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0328 - val_accuracy: 0.9935\n",
      "Epoch 523/1000\n",
      "570/570 [==============================] - 0s 595us/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0271 - val_accuracy: 0.9922\n",
      "Epoch 524/1000\n",
      "570/570 [==============================] - 0s 635us/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0341 - val_accuracy: 0.9906\n",
      "Epoch 525/1000\n",
      "570/570 [==============================] - 0s 621us/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0277 - val_accuracy: 0.9926\n",
      "Epoch 526/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0307 - val_accuracy: 0.9922\n",
      "Epoch 527/1000\n",
      "570/570 [==============================] - 0s 632us/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0311 - val_accuracy: 0.9930\n",
      "Epoch 528/1000\n",
      "570/570 [==============================] - 0s 609us/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.0317 - val_accuracy: 0.9926\n",
      "Epoch 529/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0343 - val_accuracy: 0.9898\n",
      "Epoch 530/1000\n",
      "570/570 [==============================] - 0s 624us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0327 - val_accuracy: 0.9918\n",
      "Epoch 531/1000\n",
      "570/570 [==============================] - 0s 590us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0336 - val_accuracy: 0.9922\n",
      "Epoch 532/1000\n",
      "570/570 [==============================] - 0s 637us/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.0386 - val_accuracy: 0.9930\n",
      "Epoch 533/1000\n",
      "570/570 [==============================] - 0s 622us/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.0294 - val_accuracy: 0.9918\n",
      "Epoch 534/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.0351 - val_accuracy: 0.9930\n",
      "Epoch 535/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0322 - val_accuracy: 0.9930\n",
      "Epoch 536/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0350 - val_accuracy: 0.9926\n",
      "Epoch 537/1000\n",
      "570/570 [==============================] - 0s 559us/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0298 - val_accuracy: 0.9894\n",
      "Epoch 538/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.0316 - val_accuracy: 0.9922\n",
      "Epoch 539/1000\n",
      "570/570 [==============================] - 0s 608us/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0332 - val_accuracy: 0.9926\n",
      "Epoch 540/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0370 - val_accuracy: 0.9918\n",
      "Epoch 541/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0364 - val_accuracy: 0.9914\n",
      "Epoch 542/1000\n",
      "570/570 [==============================] - 0s 621us/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0283 - val_accuracy: 0.9926\n",
      "Epoch 543/1000\n",
      "570/570 [==============================] - 0s 545us/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0335 - val_accuracy: 0.9922\n",
      "Epoch 544/1000\n",
      "570/570 [==============================] - 0s 608us/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0333 - val_accuracy: 0.9930\n",
      "Epoch 545/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0325 - val_accuracy: 0.9926\n",
      "Epoch 546/1000\n",
      "570/570 [==============================] - 0s 553us/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0289 - val_accuracy: 0.9947\n",
      "Epoch 547/1000\n",
      "570/570 [==============================] - 0s 619us/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.0310 - val_accuracy: 0.9914\n",
      "Epoch 548/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0307 - val_accuracy: 0.9922\n",
      "Epoch 549/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 0.0301 - val_accuracy: 0.9930\n",
      "Epoch 550/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.0337 - val_accuracy: 0.9906\n",
      "Epoch 551/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.0265 - val_accuracy: 0.9922\n",
      "Epoch 552/1000\n",
      "570/570 [==============================] - 0s 565us/step - loss: 0.0132 - accuracy: 0.9947 - val_loss: 0.0282 - val_accuracy: 0.9926\n",
      "Epoch 553/1000\n",
      "570/570 [==============================] - 0s 636us/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0292 - val_accuracy: 0.9926\n",
      "Epoch 554/1000\n",
      "570/570 [==============================] - 0s 619us/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.0278 - val_accuracy: 0.9922\n",
      "Epoch 555/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.0325 - val_accuracy: 0.9930\n",
      "Epoch 556/1000\n",
      "570/570 [==============================] - 0s 626us/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.0413 - val_accuracy: 0.9922\n",
      "Epoch 557/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0352 - val_accuracy: 0.9906\n",
      "Epoch 558/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0311 - val_accuracy: 0.9926\n",
      "Epoch 559/1000\n",
      "570/570 [==============================] - 0s 639us/step - loss: 0.0146 - accuracy: 0.9939 - val_loss: 0.0379 - val_accuracy: 0.9922\n",
      "Epoch 560/1000\n",
      "570/570 [==============================] - 0s 605us/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0323 - val_accuracy: 0.9926\n",
      "Epoch 561/1000\n",
      "570/570 [==============================] - 0s 646us/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0263 - val_accuracy: 0.9930\n",
      "Epoch 562/1000\n",
      "570/570 [==============================] - 0s 635us/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0349 - val_accuracy: 0.9914\n",
      "Epoch 563/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0354 - val_accuracy: 0.9922\n",
      "Epoch 564/1000\n",
      "570/570 [==============================] - 0s 624us/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.0288 - val_accuracy: 0.9910\n",
      "Epoch 565/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0307 - val_accuracy: 0.9922\n",
      "Epoch 566/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.0300 - val_accuracy: 0.9918\n",
      "Epoch 567/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0350 - val_accuracy: 0.9935\n",
      "Epoch 568/1000\n",
      "570/570 [==============================] - 0s 599us/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0284 - val_accuracy: 0.9930\n",
      "Epoch 569/1000\n",
      "570/570 [==============================] - 0s 553us/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0315 - val_accuracy: 0.9918\n",
      "Epoch 570/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0284 - val_accuracy: 0.9930\n",
      "Epoch 571/1000\n",
      "570/570 [==============================] - 0s 614us/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0293 - val_accuracy: 0.9939\n",
      "Epoch 572/1000\n",
      "570/570 [==============================] - 0s 551us/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0312 - val_accuracy: 0.9918\n",
      "Epoch 573/1000\n",
      "570/570 [==============================] - 0s 634us/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0299 - val_accuracy: 0.9935\n",
      "Epoch 574/1000\n",
      "570/570 [==============================] - 0s 577us/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0263 - val_accuracy: 0.9939\n",
      "Epoch 575/1000\n",
      "570/570 [==============================] - 0s 555us/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0348 - val_accuracy: 0.9922\n",
      "Epoch 576/1000\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0375 - val_accuracy: 0.9914\n",
      "Epoch 577/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0252 - val_accuracy: 0.9926\n",
      "Epoch 578/1000\n",
      "570/570 [==============================] - 0s 546us/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0276 - val_accuracy: 0.9910\n",
      "Epoch 579/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0271 - val_accuracy: 0.9947\n",
      "Epoch 580/1000\n",
      "570/570 [==============================] - 0s 589us/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.0324 - val_accuracy: 0.9935\n",
      "Epoch 581/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0334 - val_accuracy: 0.9926\n",
      "Epoch 582/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.0259 - val_accuracy: 0.9926\n",
      "Epoch 583/1000\n",
      "570/570 [==============================] - 0s 585us/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0347 - val_accuracy: 0.9902\n",
      "Epoch 584/1000\n",
      "570/570 [==============================] - 0s 554us/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0276 - val_accuracy: 0.9943\n",
      "Epoch 585/1000\n",
      "570/570 [==============================] - 0s 610us/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0328 - val_accuracy: 0.9922\n",
      "Epoch 586/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0336 - val_accuracy: 0.9910\n",
      "Epoch 587/1000\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0402 - val_accuracy: 0.9930\n",
      "Epoch 588/1000\n",
      "570/570 [==============================] - 0s 604us/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0334 - val_accuracy: 0.9939\n",
      "Epoch 589/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0305 - val_accuracy: 0.9914\n",
      "Epoch 590/1000\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0338 - val_accuracy: 0.9914\n",
      "Epoch 591/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.0406 - val_accuracy: 0.9914\n",
      "Epoch 592/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0372 - val_accuracy: 0.9935\n",
      "Epoch 593/1000\n",
      "570/570 [==============================] - 0s 559us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0336 - val_accuracy: 0.9918\n",
      "Epoch 594/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 0.0394 - val_accuracy: 0.9930\n",
      "Epoch 595/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0380 - val_accuracy: 0.9910\n",
      "Epoch 596/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0343 - val_accuracy: 0.9906\n",
      "Epoch 597/1000\n",
      "570/570 [==============================] - 0s 601us/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.0337 - val_accuracy: 0.9930\n",
      "Epoch 598/1000\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0296 - val_accuracy: 0.9918\n",
      "Epoch 599/1000\n",
      "570/570 [==============================] - 0s 564us/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0384 - val_accuracy: 0.9926\n",
      "Epoch 600/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0396 - val_accuracy: 0.9935\n",
      "Epoch 601/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0338 - val_accuracy: 0.9922\n",
      "Epoch 602/1000\n",
      "570/570 [==============================] - 0s 554us/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0371 - val_accuracy: 0.9914\n",
      "Epoch 603/1000\n",
      "570/570 [==============================] - 0s 559us/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.0344 - val_accuracy: 0.9918\n",
      "Epoch 604/1000\n",
      "570/570 [==============================] - 0s 597us/step - loss: 0.0128 - accuracy: 0.9946 - val_loss: 0.0342 - val_accuracy: 0.9914\n",
      "Epoch 605/1000\n",
      "570/570 [==============================] - 0s 553us/step - loss: 0.0137 - accuracy: 0.9947 - val_loss: 0.0346 - val_accuracy: 0.9930\n",
      "Epoch 606/1000\n",
      "570/570 [==============================] - 0s 565us/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0317 - val_accuracy: 0.9926\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 589us/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0323 - val_accuracy: 0.9918\n",
      "Epoch 608/1000\n",
      "570/570 [==============================] - 0s 546us/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0294 - val_accuracy: 0.9943\n",
      "Epoch 609/1000\n",
      "570/570 [==============================] - 0s 551us/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0341 - val_accuracy: 0.9922\n",
      "Epoch 610/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0291 - val_accuracy: 0.9922\n",
      "Epoch 611/1000\n",
      "570/570 [==============================] - 0s 547us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0325 - val_accuracy: 0.9914\n",
      "Epoch 612/1000\n",
      "570/570 [==============================] - 0s 565us/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.0341 - val_accuracy: 0.9935\n",
      "Epoch 613/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0137 - accuracy: 0.9947 - val_loss: 0.0310 - val_accuracy: 0.9930\n",
      "Epoch 614/1000\n",
      "570/570 [==============================] - 0s 545us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0268 - val_accuracy: 0.9926\n",
      "Epoch 615/1000\n",
      "570/570 [==============================] - 0s 558us/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 0.0319 - val_accuracy: 0.9918\n",
      "Epoch 616/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.0274 - val_accuracy: 0.9926\n",
      "Epoch 617/1000\n",
      "570/570 [==============================] - 0s 546us/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0335 - val_accuracy: 0.9930\n",
      "Epoch 618/1000\n",
      "570/570 [==============================] - 0s 553us/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.0320 - val_accuracy: 0.9939\n",
      "Epoch 619/1000\n",
      "570/570 [==============================] - 0s 596us/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.0294 - val_accuracy: 0.9943\n",
      "Epoch 620/1000\n",
      "570/570 [==============================] - 0s 548us/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0343 - val_accuracy: 0.9935\n",
      "Epoch 621/1000\n",
      "570/570 [==============================] - 0s 556us/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0298 - val_accuracy: 0.9935\n",
      "Epoch 622/1000\n",
      "570/570 [==============================] - 0s 610us/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0300 - val_accuracy: 0.9943\n",
      "Epoch 623/1000\n",
      "570/570 [==============================] - 0s 552us/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0275 - val_accuracy: 0.9939\n",
      "Epoch 624/1000\n",
      "570/570 [==============================] - 0s 554us/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.0276 - val_accuracy: 0.9926\n",
      "Epoch 625/1000\n",
      "570/570 [==============================] - 0s 611us/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.0276 - val_accuracy: 0.9943\n",
      "Epoch 626/1000\n",
      "570/570 [==============================] - 0s 564us/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0355 - val_accuracy: 0.9918\n",
      "Epoch 627/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0316 - val_accuracy: 0.9926\n",
      "Epoch 628/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0323 - val_accuracy: 0.9926\n",
      "Epoch 629/1000\n",
      "570/570 [==============================] - 0s 549us/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0297 - val_accuracy: 0.9930\n",
      "Epoch 630/1000\n",
      "570/570 [==============================] - 0s 564us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
      "Epoch 631/1000\n",
      "570/570 [==============================] - 0s 579us/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.0332 - val_accuracy: 0.9918\n",
      "Epoch 632/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.0333 - val_accuracy: 0.9926\n",
      "Epoch 633/1000\n",
      "570/570 [==============================] - 0s 555us/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.0299 - val_accuracy: 0.9922\n",
      "Epoch 634/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0306 - val_accuracy: 0.9930\n",
      "Epoch 635/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0118 - accuracy: 0.9953 - val_loss: 0.0362 - val_accuracy: 0.9910\n",
      "Epoch 636/1000\n",
      "570/570 [==============================] - 0s 557us/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0277 - val_accuracy: 0.9935\n",
      "Epoch 637/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0324 - val_accuracy: 0.9926\n",
      "Epoch 638/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.0289 - val_accuracy: 0.9930\n",
      "Epoch 639/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0251 - val_accuracy: 0.9930\n",
      "Epoch 640/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.0301 - val_accuracy: 0.9939\n",
      "Epoch 641/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.0305 - val_accuracy: 0.9930\n",
      "Epoch 642/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0425 - val_accuracy: 0.9910\n",
      "Epoch 643/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.0285 - val_accuracy: 0.9918\n",
      "Epoch 644/1000\n",
      "570/570 [==============================] - 0s 721us/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0325 - val_accuracy: 0.9922\n",
      "Epoch 645/1000\n",
      "570/570 [==============================] - 0s 619us/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0280 - val_accuracy: 0.9910\n",
      "Epoch 646/1000\n",
      "570/570 [==============================] - 0s 648us/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0362 - val_accuracy: 0.9914\n",
      "Epoch 647/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0301 - val_accuracy: 0.9930\n",
      "Epoch 648/1000\n",
      "570/570 [==============================] - 0s 634us/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0482 - val_accuracy: 0.9906\n",
      "Epoch 649/1000\n",
      "570/570 [==============================] - 0s 616us/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 650/1000\n",
      "570/570 [==============================] - 0s 601us/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0428 - val_accuracy: 0.9914\n",
      "Epoch 651/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.0375 - val_accuracy: 0.9922\n",
      "Epoch 652/1000\n",
      "570/570 [==============================] - 0s 654us/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0370 - val_accuracy: 0.9930\n",
      "Epoch 653/1000\n",
      "570/570 [==============================] - 0s 584us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0379 - val_accuracy: 0.9926\n",
      "Epoch 654/1000\n",
      "570/570 [==============================] - 0s 589us/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0411 - val_accuracy: 0.9918\n",
      "Epoch 655/1000\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0356 - val_accuracy: 0.9918\n",
      "Epoch 656/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.0376 - val_accuracy: 0.9935\n",
      "Epoch 657/1000\n",
      "570/570 [==============================] - 0s 588us/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0422 - val_accuracy: 0.9926\n",
      "Epoch 658/1000\n",
      "570/570 [==============================] - 0s 589us/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0311 - val_accuracy: 0.9930\n",
      "Epoch 659/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0391 - val_accuracy: 0.9922\n",
      "Epoch 660/1000\n",
      "570/570 [==============================] - 0s 579us/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.0338 - val_accuracy: 0.9939\n",
      "Epoch 661/1000\n",
      "570/570 [==============================] - 0s 631us/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0308 - val_accuracy: 0.9926\n",
      "Epoch 662/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.0379 - val_accuracy: 0.9914\n",
      "Epoch 663/1000\n",
      "570/570 [==============================] - 0s 584us/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0376 - val_accuracy: 0.9930\n",
      "Epoch 664/1000\n",
      "570/570 [==============================] - 0s 633us/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.0381 - val_accuracy: 0.9922\n",
      "Epoch 665/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0292 - val_accuracy: 0.9939\n",
      "Epoch 666/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0383 - val_accuracy: 0.9930\n",
      "Epoch 667/1000\n",
      "570/570 [==============================] - 0s 579us/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0350 - val_accuracy: 0.9922\n",
      "Epoch 668/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 669/1000\n",
      "570/570 [==============================] - 0s 604us/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.0436 - val_accuracy: 0.9918\n",
      "Epoch 670/1000\n",
      "570/570 [==============================] - 0s 565us/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.0411 - val_accuracy: 0.9926\n",
      "Epoch 671/1000\n",
      "570/570 [==============================] - 0s 568us/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.0370 - val_accuracy: 0.9922\n",
      "Epoch 672/1000\n",
      "570/570 [==============================] - 0s 582us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0394 - val_accuracy: 0.9914\n",
      "Epoch 673/1000\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0444 - val_accuracy: 0.9922\n",
      "Epoch 674/1000\n",
      "570/570 [==============================] - 0s 579us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0415 - val_accuracy: 0.9926\n",
      "Epoch 675/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.0376 - val_accuracy: 0.9922\n",
      "Epoch 676/1000\n",
      "570/570 [==============================] - 0s 582us/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0345 - val_accuracy: 0.9922\n",
      "Epoch 677/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.0314 - val_accuracy: 0.9922\n",
      "Epoch 678/1000\n",
      "570/570 [==============================] - 0s 583us/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0305 - val_accuracy: 0.9918\n",
      "Epoch 679/1000\n",
      "570/570 [==============================] - 0s 579us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0284 - val_accuracy: 0.9922\n",
      "Epoch 680/1000\n",
      "570/570 [==============================] - 0s 561us/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.0372 - val_accuracy: 0.9926\n",
      "Epoch 681/1000\n",
      "570/570 [==============================] - 0s 589us/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.0435 - val_accuracy: 0.9918\n",
      "Epoch 682/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0467 - val_accuracy: 0.9918\n",
      "Epoch 683/1000\n",
      "570/570 [==============================] - 0s 572us/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0369 - val_accuracy: 0.9930\n",
      "Epoch 684/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0336 - val_accuracy: 0.9918\n",
      "Epoch 685/1000\n",
      "570/570 [==============================] - 0s 592us/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0372 - val_accuracy: 0.9918\n",
      "Epoch 686/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0426 - val_accuracy: 0.9926\n",
      "Epoch 687/1000\n",
      "570/570 [==============================] - 0s 599us/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.0361 - val_accuracy: 0.9930\n",
      "Epoch 688/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0410 - val_accuracy: 0.9930\n",
      "Epoch 689/1000\n",
      "570/570 [==============================] - 0s 567us/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.0364 - val_accuracy: 0.9939\n",
      "Epoch 690/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0376 - val_accuracy: 0.9935\n",
      "Epoch 691/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0442 - val_accuracy: 0.9926\n",
      "Epoch 692/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0433 - val_accuracy: 0.9906\n",
      "Epoch 693/1000\n",
      "570/570 [==============================] - 0s 595us/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.0466 - val_accuracy: 0.9906\n",
      "Epoch 694/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0441 - val_accuracy: 0.9922\n",
      "Epoch 695/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 0.0466 - val_accuracy: 0.9914\n",
      "Epoch 696/1000\n",
      "570/570 [==============================] - 0s 601us/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0456 - val_accuracy: 0.9918\n",
      "Epoch 697/1000\n",
      "570/570 [==============================] - 0s 581us/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.0395 - val_accuracy: 0.9926\n",
      "Epoch 698/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.0364 - val_accuracy: 0.9918\n",
      "Epoch 699/1000\n",
      "570/570 [==============================] - 0s 619us/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0390 - val_accuracy: 0.9922\n",
      "Epoch 700/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0443 - val_accuracy: 0.9918\n",
      "Epoch 701/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0416 - val_accuracy: 0.9930\n",
      "Epoch 702/1000\n",
      "570/570 [==============================] - 0s 616us/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0370 - val_accuracy: 0.9926\n",
      "Epoch 703/1000\n",
      "570/570 [==============================] - 0s 606us/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0389 - val_accuracy: 0.9922\n",
      "Epoch 704/1000\n",
      "570/570 [==============================] - 0s 629us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0430 - val_accuracy: 0.9935\n",
      "Epoch 705/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0445 - val_accuracy: 0.9918\n",
      "Epoch 706/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0394 - val_accuracy: 0.9926\n",
      "Epoch 707/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.0427 - val_accuracy: 0.9918\n",
      "Epoch 708/1000\n",
      "570/570 [==============================] - 0s 611us/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.0381 - val_accuracy: 0.9935\n",
      "Epoch 709/1000\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.0524 - val_accuracy: 0.9926\n",
      "Epoch 710/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0478 - val_accuracy: 0.9922\n",
      "Epoch 711/1000\n",
      "570/570 [==============================] - 0s 630us/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.0529 - val_accuracy: 0.9922\n",
      "Epoch 712/1000\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0488 - val_accuracy: 0.9926\n",
      "Epoch 713/1000\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0491 - val_accuracy: 0.9930\n",
      "Epoch 714/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0419 - val_accuracy: 0.9930\n",
      "Epoch 715/1000\n",
      "570/570 [==============================] - 0s 579us/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.0469 - val_accuracy: 0.9939\n",
      "Epoch 716/1000\n",
      "570/570 [==============================] - 0s 614us/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0446 - val_accuracy: 0.9935\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 610us/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.0475 - val_accuracy: 0.9935\n",
      "Epoch 718/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.0457 - val_accuracy: 0.9926\n",
      "Epoch 719/1000\n",
      "570/570 [==============================] - 0s 637us/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0328 - val_accuracy: 0.9926\n",
      "Epoch 720/1000\n",
      "570/570 [==============================] - 0s 636us/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0503 - val_accuracy: 0.9914\n",
      "Epoch 721/1000\n",
      "570/570 [==============================] - 0s 564us/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0482 - val_accuracy: 0.9914\n",
      "Epoch 722/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0435 - val_accuracy: 0.9914\n",
      "Epoch 723/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0403 - val_accuracy: 0.9930\n",
      "Epoch 724/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0407 - val_accuracy: 0.9918\n",
      "Epoch 725/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.0429 - val_accuracy: 0.9930\n",
      "Epoch 726/1000\n",
      "570/570 [==============================] - 0s 633us/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0388 - val_accuracy: 0.9930\n",
      "Epoch 727/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.0435 - val_accuracy: 0.9922\n",
      "Epoch 728/1000\n",
      "570/570 [==============================] - 0s 626us/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0388 - val_accuracy: 0.9930\n",
      "Epoch 729/1000\n",
      "570/570 [==============================] - 0s 653us/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0404 - val_accuracy: 0.9930\n",
      "Epoch 730/1000\n",
      "570/570 [==============================] - 0s 767us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0432 - val_accuracy: 0.9930\n",
      "Epoch 731/1000\n",
      "570/570 [==============================] - 0s 711us/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0404 - val_accuracy: 0.9926\n",
      "Epoch 732/1000\n",
      "570/570 [==============================] - 0s 631us/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.0459 - val_accuracy: 0.9935\n",
      "Epoch 733/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0395 - val_accuracy: 0.9926\n",
      "Epoch 734/1000\n",
      "570/570 [==============================] - 0s 636us/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0346 - val_accuracy: 0.9926\n",
      "Epoch 735/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.0405 - val_accuracy: 0.9926\n",
      "Epoch 736/1000\n",
      "570/570 [==============================] - 0s 646us/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0351 - val_accuracy: 0.9910\n",
      "Epoch 737/1000\n",
      "570/570 [==============================] - 0s 664us/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0355 - val_accuracy: 0.9926\n",
      "Epoch 738/1000\n",
      "570/570 [==============================] - 0s 640us/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0370 - val_accuracy: 0.9943\n",
      "Epoch 739/1000\n",
      "570/570 [==============================] - 0s 599us/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.0419 - val_accuracy: 0.9914\n",
      "Epoch 740/1000\n",
      "570/570 [==============================] - 0s 640us/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0434 - val_accuracy: 0.9922\n",
      "Epoch 741/1000\n",
      "570/570 [==============================] - 0s 562us/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.0481 - val_accuracy: 0.9926\n",
      "Epoch 742/1000\n",
      "570/570 [==============================] - 0s 608us/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0445 - val_accuracy: 0.9922\n",
      "Epoch 743/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0495 - val_accuracy: 0.9918\n",
      "Epoch 744/1000\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0484 - val_accuracy: 0.9910\n",
      "Epoch 745/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0509 - val_accuracy: 0.9906\n",
      "Epoch 746/1000\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0455 - val_accuracy: 0.9926\n",
      "Epoch 747/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0505 - val_accuracy: 0.9894\n",
      "Epoch 748/1000\n",
      "570/570 [==============================] - 0s 624us/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.0378 - val_accuracy: 0.9914\n",
      "Epoch 749/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.0453 - val_accuracy: 0.9930\n",
      "Epoch 750/1000\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0421 - val_accuracy: 0.9918\n",
      "Epoch 751/1000\n",
      "570/570 [==============================] - 0s 608us/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0456 - val_accuracy: 0.9926\n",
      "Epoch 752/1000\n",
      "570/570 [==============================] - 0s 596us/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0459 - val_accuracy: 0.9914\n",
      "Epoch 753/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0126 - accuracy: 0.9949 - val_loss: 0.0370 - val_accuracy: 0.9930\n",
      "Epoch 754/1000\n",
      "570/570 [==============================] - 0s 616us/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0351 - val_accuracy: 0.9939\n",
      "Epoch 755/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0378 - val_accuracy: 0.9926\n",
      "Epoch 756/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0413 - val_accuracy: 0.9918\n",
      "Epoch 757/1000\n",
      "570/570 [==============================] - 0s 611us/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0509 - val_accuracy: 0.9914\n",
      "Epoch 758/1000\n",
      "570/570 [==============================] - 0s 589us/step - loss: 0.0138 - accuracy: 0.9946 - val_loss: 0.0423 - val_accuracy: 0.9926\n",
      "Epoch 759/1000\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0414 - val_accuracy: 0.9935\n",
      "Epoch 760/1000\n",
      "570/570 [==============================] - 0s 610us/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0400 - val_accuracy: 0.9926\n",
      "Epoch 761/1000\n",
      "570/570 [==============================] - 0s 588us/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0371 - val_accuracy: 0.9939\n",
      "Epoch 762/1000\n",
      "570/570 [==============================] - 0s 581us/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.0427 - val_accuracy: 0.9918\n",
      "Epoch 763/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0391 - val_accuracy: 0.9922\n",
      "Epoch 764/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0436 - val_accuracy: 0.9914\n",
      "Epoch 765/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0437 - val_accuracy: 0.9914\n",
      "Epoch 766/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 0.0382 - val_accuracy: 0.9910\n",
      "Epoch 767/1000\n",
      "570/570 [==============================] - 0s 575us/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0352 - val_accuracy: 0.9935\n",
      "Epoch 768/1000\n",
      "570/570 [==============================] - 0s 592us/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0397 - val_accuracy: 0.9922\n",
      "Epoch 769/1000\n",
      "570/570 [==============================] - 0s 619us/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0460 - val_accuracy: 0.9939\n",
      "Epoch 770/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0106 - accuracy: 0.9960 - val_loss: 0.0572 - val_accuracy: 0.9918\n",
      "Epoch 771/1000\n",
      "570/570 [==============================] - 0s 608us/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.0507 - val_accuracy: 0.9939\n",
      "Epoch 772/1000\n",
      "570/570 [==============================] - 0s 631us/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.0483 - val_accuracy: 0.9926\n",
      "Epoch 773/1000\n",
      "570/570 [==============================] - 0s 562us/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0475 - val_accuracy: 0.9935\n",
      "Epoch 774/1000\n",
      "570/570 [==============================] - 0s 606us/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.0371 - val_accuracy: 0.9926\n",
      "Epoch 775/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0495 - val_accuracy: 0.9918\n",
      "Epoch 776/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0423 - val_accuracy: 0.9930\n",
      "Epoch 777/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0407 - val_accuracy: 0.9926\n",
      "Epoch 778/1000\n",
      "570/570 [==============================] - 0s 624us/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0401 - val_accuracy: 0.9930\n",
      "Epoch 779/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 0.0392 - val_accuracy: 0.9926\n",
      "Epoch 780/1000\n",
      "570/570 [==============================] - 0s 626us/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0374 - val_accuracy: 0.9926\n",
      "Epoch 781/1000\n",
      "570/570 [==============================] - 0s 647us/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.0415 - val_accuracy: 0.9926\n",
      "Epoch 782/1000\n",
      "570/570 [==============================] - 0s 562us/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.0421 - val_accuracy: 0.9926\n",
      "Epoch 783/1000\n",
      "570/570 [==============================] - 0s 616us/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.0491 - val_accuracy: 0.9918\n",
      "Epoch 784/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0421 - val_accuracy: 0.9922\n",
      "Epoch 785/1000\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.0484 - val_accuracy: 0.9926\n",
      "Epoch 786/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0123 - accuracy: 0.9949 - val_loss: 0.0440 - val_accuracy: 0.9926\n",
      "Epoch 787/1000\n",
      "570/570 [==============================] - 0s 608us/step - loss: 0.0105 - accuracy: 0.9960 - val_loss: 0.0493 - val_accuracy: 0.9898\n",
      "Epoch 788/1000\n",
      "570/570 [==============================] - 0s 565us/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0442 - val_accuracy: 0.9926\n",
      "Epoch 789/1000\n",
      "570/570 [==============================] - 0s 617us/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.0336 - val_accuracy: 0.9935\n",
      "Epoch 790/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.0438 - val_accuracy: 0.9894\n",
      "Epoch 791/1000\n",
      "570/570 [==============================] - 0s 567us/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0406 - val_accuracy: 0.9914\n",
      "Epoch 792/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0325 - val_accuracy: 0.9906\n",
      "Epoch 793/1000\n",
      "570/570 [==============================] - 0s 584us/step - loss: 0.0132 - accuracy: 0.9947 - val_loss: 0.0396 - val_accuracy: 0.9935\n",
      "Epoch 794/1000\n",
      "570/570 [==============================] - 0s 572us/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0474 - val_accuracy: 0.9910\n",
      "Epoch 795/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.0405 - val_accuracy: 0.9947\n",
      "Epoch 796/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0391 - val_accuracy: 0.9926\n",
      "Epoch 797/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0328 - val_accuracy: 0.9922\n",
      "Epoch 798/1000\n",
      "570/570 [==============================] - 0s 625us/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0337 - val_accuracy: 0.9922\n",
      "Epoch 799/1000\n",
      "570/570 [==============================] - 0s 605us/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0453 - val_accuracy: 0.9930\n",
      "Epoch 800/1000\n",
      "570/570 [==============================] - 0s 587us/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.0331 - val_accuracy: 0.9922\n",
      "Epoch 801/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0307 - val_accuracy: 0.9926\n",
      "Epoch 802/1000\n",
      "570/570 [==============================] - 0s 575us/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0352 - val_accuracy: 0.9918\n",
      "Epoch 803/1000\n",
      "570/570 [==============================] - 0s 587us/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0360 - val_accuracy: 0.9922\n",
      "Epoch 804/1000\n",
      "570/570 [==============================] - 0s 628us/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0312 - val_accuracy: 0.9918\n",
      "Epoch 805/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0352 - val_accuracy: 0.9922\n",
      "Epoch 806/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.0358 - val_accuracy: 0.9943\n",
      "Epoch 807/1000\n",
      "570/570 [==============================] - 0s 654us/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0341 - val_accuracy: 0.9918\n",
      "Epoch 808/1000\n",
      "570/570 [==============================] - 0s 561us/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.0312 - val_accuracy: 0.9926\n",
      "Epoch 809/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.0365 - val_accuracy: 0.9914\n",
      "Epoch 810/1000\n",
      "570/570 [==============================] - 0s 610us/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0370 - val_accuracy: 0.9926\n",
      "Epoch 811/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.0362 - val_accuracy: 0.9930\n",
      "Epoch 812/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0413 - val_accuracy: 0.9930\n",
      "Epoch 813/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.0390 - val_accuracy: 0.9906\n",
      "Epoch 814/1000\n",
      "570/570 [==============================] - 0s 608us/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0464 - val_accuracy: 0.9926\n",
      "Epoch 815/1000\n",
      "570/570 [==============================] - 0s 624us/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.0347 - val_accuracy: 0.9906\n",
      "Epoch 816/1000\n",
      "570/570 [==============================] - 0s 645us/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0372 - val_accuracy: 0.9926\n",
      "Epoch 817/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0332 - val_accuracy: 0.9935\n",
      "Epoch 818/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0322 - val_accuracy: 0.9943\n",
      "Epoch 819/1000\n",
      "570/570 [==============================] - 0s 642us/step - loss: 0.0126 - accuracy: 0.9946 - val_loss: 0.0334 - val_accuracy: 0.9935\n",
      "Epoch 820/1000\n",
      "570/570 [==============================] - 0s 628us/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.0382 - val_accuracy: 0.9926\n",
      "Epoch 821/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0375 - val_accuracy: 0.9935\n",
      "Epoch 822/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0297 - val_accuracy: 0.9939\n",
      "Epoch 823/1000\n",
      "570/570 [==============================] - 0s 587us/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0319 - val_accuracy: 0.9914\n",
      "Epoch 824/1000\n",
      "570/570 [==============================] - 0s 658us/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0345 - val_accuracy: 0.9939\n",
      "Epoch 825/1000\n",
      "570/570 [==============================] - 0s 611us/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0394 - val_accuracy: 0.9918\n",
      "Epoch 826/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.0329 - val_accuracy: 0.9930\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 659us/step - loss: 0.0109 - accuracy: 0.9956 - val_loss: 0.0422 - val_accuracy: 0.9910\n",
      "Epoch 828/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.0483 - val_accuracy: 0.9922\n",
      "Epoch 829/1000\n",
      "570/570 [==============================] - 0s 645us/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.0368 - val_accuracy: 0.9935\n",
      "Epoch 830/1000\n",
      "570/570 [==============================] - 0s 668us/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0436 - val_accuracy: 0.9935\n",
      "Epoch 831/1000\n",
      "570/570 [==============================] - 0s 618us/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 0.0359 - val_accuracy: 0.9922\n",
      "Epoch 832/1000\n",
      "570/570 [==============================] - 0s 664us/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0351 - val_accuracy: 0.9943\n",
      "Epoch 833/1000\n",
      "570/570 [==============================] - 0s 619us/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0333 - val_accuracy: 0.9939\n",
      "Epoch 834/1000\n",
      "570/570 [==============================] - 0s 642us/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0306 - val_accuracy: 0.9926\n",
      "Epoch 835/1000\n",
      "570/570 [==============================] - 0s 670us/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0348 - val_accuracy: 0.9930\n",
      "Epoch 836/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0345 - val_accuracy: 0.9922\n",
      "Epoch 837/1000\n",
      "570/570 [==============================] - 0s 596us/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0527 - val_accuracy: 0.9906\n",
      "Epoch 838/1000\n",
      "570/570 [==============================] - 0s 621us/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.0343 - val_accuracy: 0.9926\n",
      "Epoch 839/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.0466 - val_accuracy: 0.9906\n",
      "Epoch 840/1000\n",
      "570/570 [==============================] - 0s 601us/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 841/1000\n",
      "570/570 [==============================] - 0s 616us/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0326 - val_accuracy: 0.9930\n",
      "Epoch 842/1000\n",
      "570/570 [==============================] - 0s 559us/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0414 - val_accuracy: 0.9914\n",
      "Epoch 843/1000\n",
      "570/570 [==============================] - 0s 600us/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0415 - val_accuracy: 0.9918\n",
      "Epoch 844/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0313 - val_accuracy: 0.9939\n",
      "Epoch 845/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0360 - val_accuracy: 0.9930\n",
      "Epoch 846/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.0346 - val_accuracy: 0.9922\n",
      "Epoch 847/1000\n",
      "570/570 [==============================] - 0s 605us/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0351 - val_accuracy: 0.9935\n",
      "Epoch 848/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0307 - val_accuracy: 0.9930\n",
      "Epoch 849/1000\n",
      "570/570 [==============================] - 0s 633us/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0354 - val_accuracy: 0.9935\n",
      "Epoch 850/1000\n",
      "570/570 [==============================] - 0s 594us/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.0338 - val_accuracy: 0.9926\n",
      "Epoch 851/1000\n",
      "570/570 [==============================] - 0s 549us/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0313 - val_accuracy: 0.9935\n",
      "Epoch 852/1000\n",
      "570/570 [==============================] - 0s 601us/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0257 - val_accuracy: 0.9930\n",
      "Epoch 853/1000\n",
      "570/570 [==============================] - 0s 599us/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0393 - val_accuracy: 0.9926\n",
      "Epoch 854/1000\n",
      "570/570 [==============================] - 0s 568us/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.0279 - val_accuracy: 0.9947\n",
      "Epoch 855/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.0268 - val_accuracy: 0.9939\n",
      "Epoch 856/1000\n",
      "570/570 [==============================] - 0s 605us/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0371 - val_accuracy: 0.9935\n",
      "Epoch 857/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0327 - val_accuracy: 0.9926\n",
      "Epoch 858/1000\n",
      "570/570 [==============================] - 0s 635us/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0295 - val_accuracy: 0.9926\n",
      "Epoch 859/1000\n",
      "570/570 [==============================] - 0s 598us/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0384 - val_accuracy: 0.9918\n",
      "Epoch 860/1000\n",
      "570/570 [==============================] - 0s 572us/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0334 - val_accuracy: 0.9918\n",
      "Epoch 861/1000\n",
      "570/570 [==============================] - 0s 616us/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 0.0406 - val_accuracy: 0.9922\n",
      "Epoch 862/1000\n",
      "570/570 [==============================] - 0s 588us/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.0322 - val_accuracy: 0.9926\n",
      "Epoch 863/1000\n",
      "570/570 [==============================] - 0s 574us/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0425 - val_accuracy: 0.9939\n",
      "Epoch 864/1000\n",
      "570/570 [==============================] - 0s 643us/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.0428 - val_accuracy: 0.9935\n",
      "Epoch 865/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0462 - val_accuracy: 0.9930\n",
      "Epoch 866/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0396 - val_accuracy: 0.9922\n",
      "Epoch 867/1000\n",
      "570/570 [==============================] - 0s 640us/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.0425 - val_accuracy: 0.9930\n",
      "Epoch 868/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0333 - val_accuracy: 0.9922\n",
      "Epoch 869/1000\n",
      "570/570 [==============================] - 0s 596us/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.0358 - val_accuracy: 0.9943\n",
      "Epoch 870/1000\n",
      "570/570 [==============================] - 0s 614us/step - loss: 0.0107 - accuracy: 0.9960 - val_loss: 0.0354 - val_accuracy: 0.9947\n",
      "Epoch 871/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.0457 - val_accuracy: 0.9926\n",
      "Epoch 872/1000\n",
      "570/570 [==============================] - 0s 595us/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0471 - val_accuracy: 0.9935\n",
      "Epoch 873/1000\n",
      "570/570 [==============================] - 0s 618us/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.0337 - val_accuracy: 0.9939\n",
      "Epoch 874/1000\n",
      "570/570 [==============================] - 0s 563us/step - loss: 0.0111 - accuracy: 0.9953 - val_loss: 0.0364 - val_accuracy: 0.9922\n",
      "Epoch 875/1000\n",
      "570/570 [==============================] - 0s 604us/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.0371 - val_accuracy: 0.9922\n",
      "Epoch 876/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.0322 - val_accuracy: 0.9935\n",
      "Epoch 877/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.0373 - val_accuracy: 0.9935\n",
      "Epoch 878/1000\n",
      "570/570 [==============================] - 0s 595us/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0316 - val_accuracy: 0.9926\n",
      "Epoch 879/1000\n",
      "570/570 [==============================] - 0s 624us/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0366 - val_accuracy: 0.9930\n",
      "Epoch 880/1000\n",
      "570/570 [==============================] - 0s 556us/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0404 - val_accuracy: 0.9930\n",
      "Epoch 881/1000\n",
      "570/570 [==============================] - 0s 590us/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.0322 - val_accuracy: 0.9935\n",
      "Epoch 882/1000\n",
      "570/570 [==============================] - 0s 618us/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.0310 - val_accuracy: 0.9930\n",
      "Epoch 883/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0389 - val_accuracy: 0.9922\n",
      "Epoch 884/1000\n",
      "570/570 [==============================] - 0s 616us/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.0323 - val_accuracy: 0.9930\n",
      "Epoch 885/1000\n",
      "570/570 [==============================] - 0s 691us/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0366 - val_accuracy: 0.9914\n",
      "Epoch 886/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0327 - val_accuracy: 0.9935\n",
      "Epoch 887/1000\n",
      "570/570 [==============================] - 0s 632us/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0372 - val_accuracy: 0.9939\n",
      "Epoch 888/1000\n",
      "570/570 [==============================] - 0s 602us/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.0343 - val_accuracy: 0.9922\n",
      "Epoch 889/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0368 - val_accuracy: 0.9926\n",
      "Epoch 890/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0427 - val_accuracy: 0.9935\n",
      "Epoch 891/1000\n",
      "570/570 [==============================] - 0s 592us/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0342 - val_accuracy: 0.9918\n",
      "Epoch 892/1000\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0352 - val_accuracy: 0.9939\n",
      "Epoch 893/1000\n",
      "570/570 [==============================] - 0s 651us/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0352 - val_accuracy: 0.9943\n",
      "Epoch 894/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0382 - val_accuracy: 0.9930\n",
      "Epoch 895/1000\n",
      "570/570 [==============================] - 0s 572us/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0409 - val_accuracy: 0.9922\n",
      "Epoch 896/1000\n",
      "570/570 [==============================] - 0s 637us/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 897/1000\n",
      "570/570 [==============================] - 0s 580us/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0369 - val_accuracy: 0.9930\n",
      "Epoch 898/1000\n",
      "570/570 [==============================] - 0s 579us/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0371 - val_accuracy: 0.9939\n",
      "Epoch 899/1000\n",
      "570/570 [==============================] - 0s 625us/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0418 - val_accuracy: 0.9922\n",
      "Epoch 900/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 901/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0388 - val_accuracy: 0.9926\n",
      "Epoch 902/1000\n",
      "570/570 [==============================] - 0s 642us/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0416 - val_accuracy: 0.9922\n",
      "Epoch 903/1000\n",
      "570/570 [==============================] - 0s 568us/step - loss: 0.0124 - accuracy: 0.9949 - val_loss: 0.0408 - val_accuracy: 0.9935\n",
      "Epoch 904/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.0435 - val_accuracy: 0.9930\n",
      "Epoch 905/1000\n",
      "570/570 [==============================] - 0s 628us/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 0.0351 - val_accuracy: 0.9939\n",
      "Epoch 906/1000\n",
      "570/570 [==============================] - 0s 561us/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0412 - val_accuracy: 0.9902\n",
      "Epoch 907/1000\n",
      "570/570 [==============================] - 0s 595us/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.0291 - val_accuracy: 0.9930\n",
      "Epoch 908/1000\n",
      "570/570 [==============================] - 0s 639us/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0396 - val_accuracy: 0.9930\n",
      "Epoch 909/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.0425 - val_accuracy: 0.9922\n",
      "Epoch 910/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0396 - val_accuracy: 0.9930\n",
      "Epoch 911/1000\n",
      "570/570 [==============================] - 0s 625us/step - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.0293 - val_accuracy: 0.9922\n",
      "Epoch 912/1000\n",
      "570/570 [==============================] - 0s 557us/step - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.0427 - val_accuracy: 0.9926\n",
      "Epoch 913/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0369 - val_accuracy: 0.9926\n",
      "Epoch 914/1000\n",
      "570/570 [==============================] - 0s 626us/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0356 - val_accuracy: 0.9926\n",
      "Epoch 915/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0416 - val_accuracy: 0.9926\n",
      "Epoch 916/1000\n",
      "570/570 [==============================] - 0s 610us/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.0336 - val_accuracy: 0.9922\n",
      "Epoch 917/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0354 - val_accuracy: 0.9935\n",
      "Epoch 918/1000\n",
      "570/570 [==============================] - 0s 558us/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0426 - val_accuracy: 0.9930\n",
      "Epoch 919/1000\n",
      "570/570 [==============================] - 0s 623us/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0410 - val_accuracy: 0.9918\n",
      "Epoch 920/1000\n",
      "570/570 [==============================] - 0s 620us/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0382 - val_accuracy: 0.9935\n",
      "Epoch 921/1000\n",
      "570/570 [==============================] - 0s 567us/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.0376 - val_accuracy: 0.9922\n",
      "Epoch 922/1000\n",
      "570/570 [==============================] - 0s 621us/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 0.0380 - val_accuracy: 0.9922\n",
      "Epoch 923/1000\n",
      "570/570 [==============================] - 0s 615us/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 924/1000\n",
      "570/570 [==============================] - 0s 574us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0404 - val_accuracy: 0.9926\n",
      "Epoch 925/1000\n",
      "570/570 [==============================] - 0s 619us/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.0349 - val_accuracy: 0.9926\n",
      "Epoch 926/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0432 - val_accuracy: 0.9930\n",
      "Epoch 927/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.0338 - val_accuracy: 0.9926\n",
      "Epoch 928/1000\n",
      "570/570 [==============================] - 0s 605us/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0375 - val_accuracy: 0.9926\n",
      "Epoch 929/1000\n",
      "570/570 [==============================] - 0s 582us/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0397 - val_accuracy: 0.9914\n",
      "Epoch 930/1000\n",
      "570/570 [==============================] - 0s 556us/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0394 - val_accuracy: 0.9926\n",
      "Epoch 931/1000\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.0403 - val_accuracy: 0.9922\n",
      "Epoch 932/1000\n",
      "570/570 [==============================] - 0s 582us/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0420 - val_accuracy: 0.9922\n",
      "Epoch 933/1000\n",
      "570/570 [==============================] - 0s 555us/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 934/1000\n",
      "570/570 [==============================] - 0s 599us/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0467 - val_accuracy: 0.9930\n",
      "Epoch 935/1000\n",
      "570/570 [==============================] - 0s 585us/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0582 - val_accuracy: 0.9926\n",
      "Epoch 936/1000\n",
      "570/570 [==============================] - 0s 559us/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0452 - val_accuracy: 0.9939\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 611us/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0432 - val_accuracy: 0.9926\n",
      "Epoch 938/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0336 - val_accuracy: 0.9922\n",
      "Epoch 939/1000\n",
      "570/570 [==============================] - 0s 557us/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0378 - val_accuracy: 0.9930\n",
      "Epoch 940/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0439 - val_accuracy: 0.9926\n",
      "Epoch 941/1000\n",
      "570/570 [==============================] - 0s 613us/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.0388 - val_accuracy: 0.9902\n",
      "Epoch 942/1000\n",
      "570/570 [==============================] - 0s 556us/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0485 - val_accuracy: 0.9930\n",
      "Epoch 943/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0440 - val_accuracy: 0.9926\n",
      "Epoch 944/1000\n",
      "570/570 [==============================] - 0s 582us/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.0464 - val_accuracy: 0.9930\n",
      "Epoch 945/1000\n",
      "570/570 [==============================] - 0s 555us/step - loss: 0.0104 - accuracy: 0.9961 - val_loss: 0.0351 - val_accuracy: 0.9926\n",
      "Epoch 946/1000\n",
      "570/570 [==============================] - 0s 635us/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.0340 - val_accuracy: 0.9930\n",
      "Epoch 947/1000\n",
      "570/570 [==============================] - 0s 581us/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0328 - val_accuracy: 0.9930\n",
      "Epoch 948/1000\n",
      "570/570 [==============================] - 0s 559us/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0407 - val_accuracy: 0.9939\n",
      "Epoch 949/1000\n",
      "570/570 [==============================] - 0s 597us/step - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.0401 - val_accuracy: 0.9930\n",
      "Epoch 950/1000\n",
      "570/570 [==============================] - 0s 581us/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.0440 - val_accuracy: 0.9914\n",
      "Epoch 951/1000\n",
      "570/570 [==============================] - 0s 597us/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0399 - val_accuracy: 0.9935\n",
      "Epoch 952/1000\n",
      "570/570 [==============================] - 0s 590us/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.0344 - val_accuracy: 0.9926\n",
      "Epoch 953/1000\n",
      "570/570 [==============================] - 0s 599us/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0361 - val_accuracy: 0.9926\n",
      "Epoch 954/1000\n",
      "570/570 [==============================] - 0s 570us/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0422 - val_accuracy: 0.9922\n",
      "Epoch 955/1000\n",
      "570/570 [==============================] - 0s 612us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0374 - val_accuracy: 0.9926\n",
      "Epoch 956/1000\n",
      "570/570 [==============================] - 0s 572us/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0363 - val_accuracy: 0.9926\n",
      "Epoch 957/1000\n",
      "570/570 [==============================] - 0s 577us/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.0450 - val_accuracy: 0.9930\n",
      "Epoch 958/1000\n",
      "570/570 [==============================] - 0s 587us/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0468 - val_accuracy: 0.9926\n",
      "Epoch 959/1000\n",
      "570/570 [==============================] - 0s 576us/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.0368 - val_accuracy: 0.9935\n",
      "Epoch 960/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0445 - val_accuracy: 0.9926\n",
      "Epoch 961/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0325 - val_accuracy: 0.9935\n",
      "Epoch 962/1000\n",
      "570/570 [==============================] - 0s 587us/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.0374 - val_accuracy: 0.9930\n",
      "Epoch 963/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0102 - accuracy: 0.9961 - val_loss: 0.0434 - val_accuracy: 0.9930\n",
      "Epoch 964/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0319 - val_accuracy: 0.9930\n",
      "Epoch 965/1000\n",
      "570/570 [==============================] - 0s 582us/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0355 - val_accuracy: 0.9926\n",
      "Epoch 966/1000\n",
      "570/570 [==============================] - 0s 586us/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0334 - val_accuracy: 0.9930\n",
      "Epoch 967/1000\n",
      "570/570 [==============================] - 0s 603us/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.0328 - val_accuracy: 0.9939\n",
      "Epoch 968/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.0383 - val_accuracy: 0.9943\n",
      "Epoch 969/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0318 - val_accuracy: 0.9930\n",
      "Epoch 970/1000\n",
      "570/570 [==============================] - 0s 607us/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.0404 - val_accuracy: 0.9935\n",
      "Epoch 971/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.0322 - val_accuracy: 0.9930\n",
      "Epoch 972/1000\n",
      "570/570 [==============================] - 0s 581us/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0324 - val_accuracy: 0.9943\n",
      "Epoch 973/1000\n",
      "570/570 [==============================] - 0s 628us/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.0372 - val_accuracy: 0.9926\n",
      "Epoch 974/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.0350 - val_accuracy: 0.9935\n",
      "Epoch 975/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0105 - accuracy: 0.9961 - val_loss: 0.0470 - val_accuracy: 0.9930\n",
      "Epoch 976/1000\n",
      "570/570 [==============================] - 0s 794us/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0366 - val_accuracy: 0.9922\n",
      "Epoch 977/1000\n",
      "570/570 [==============================] - 0s 636us/step - loss: 0.0098 - accuracy: 0.9961 - val_loss: 0.0443 - val_accuracy: 0.9918\n",
      "Epoch 978/1000\n",
      "570/570 [==============================] - 0s 625us/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0350 - val_accuracy: 0.9935\n",
      "Epoch 979/1000\n",
      "570/570 [==============================] - 0s 584us/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.0391 - val_accuracy: 0.9922\n",
      "Epoch 980/1000\n",
      "570/570 [==============================] - 0s 577us/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 0.0403 - val_accuracy: 0.9922\n",
      "Epoch 981/1000\n",
      "570/570 [==============================] - 0s 592us/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.0368 - val_accuracy: 0.9930\n",
      "Epoch 982/1000\n",
      "570/570 [==============================] - 0s 627us/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.0334 - val_accuracy: 0.9926\n",
      "Epoch 983/1000\n",
      "570/570 [==============================] - 0s 574us/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0320 - val_accuracy: 0.9926\n",
      "Epoch 984/1000\n",
      "570/570 [==============================] - 0s 593us/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0317 - val_accuracy: 0.9922\n",
      "Epoch 985/1000\n",
      "570/570 [==============================] - 0s 584us/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 0.0366 - val_accuracy: 0.9930\n",
      "Epoch 986/1000\n",
      "570/570 [==============================] - 0s 573us/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0417 - val_accuracy: 0.9926\n",
      "Epoch 987/1000\n",
      "570/570 [==============================] - 0s 591us/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0431 - val_accuracy: 0.9930\n",
      "Epoch 988/1000\n",
      "570/570 [==============================] - 0s 587us/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0426 - val_accuracy: 0.9935\n",
      "Epoch 989/1000\n",
      "570/570 [==============================] - 0s 590us/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0349 - val_accuracy: 0.9939\n",
      "Epoch 990/1000\n",
      "570/570 [==============================] - 0s 590us/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.0375 - val_accuracy: 0.9939\n",
      "Epoch 991/1000\n",
      "570/570 [==============================] - 0s 578us/step - loss: 0.0111 - accuracy: 0.9956 - val_loss: 0.0333 - val_accuracy: 0.9930\n",
      "Epoch 992/1000\n",
      "570/570 [==============================] - 0s 566us/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0331 - val_accuracy: 0.9939\n",
      "Epoch 993/1000\n",
      "570/570 [==============================] - 0s 568us/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0456 - val_accuracy: 0.9914\n",
      "Epoch 994/1000\n",
      "570/570 [==============================] - 0s 604us/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 995/1000\n",
      "570/570 [==============================] - 0s 560us/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0431 - val_accuracy: 0.9935\n",
      "Epoch 996/1000\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0508 - val_accuracy: 0.9939\n",
      "Epoch 997/1000\n",
      "570/570 [==============================] - 0s 610us/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0516 - val_accuracy: 0.9930\n",
      "Epoch 998/1000\n",
      "570/570 [==============================] - 0s 569us/step - loss: 0.0102 - accuracy: 0.9960 - val_loss: 0.0418 - val_accuracy: 0.9939\n",
      "Epoch 999/1000\n",
      "570/570 [==============================] - 0s 571us/step - loss: 0.0176 - accuracy: 0.9960 - val_loss: 0.0402 - val_accuracy: 0.9918\n",
      "Epoch 1000/1000\n",
      "570/570 [==============================] - 0s 585us/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.0468 - val_accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "model3 = build_model()\n",
    "\n",
    "history3 = model3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, batch_size=10).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 496us/step - loss: 0.0468 - accuracy: 0.9918\n",
      "Loss 0.021506, Accuracy 0.991813\n",
      "Loss 0.019388, Accuracy 0.992632\n",
      "Loss 0.046756, Accuracy 0.991813\n"
     ]
    }
   ],
   "source": [
    "test_loss_3, test_acc_3 = model3.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_3, test_acc_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history3['loss'], label='Train')\n",
    "plt.plot(history3['val_loss'], label='Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most relevant arguments are:\n",
    "\n",
    "* monitor: quantity to be monitored\n",
    "* patience: number of epochs with no improvement after which training will be stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "456/456 [==============================] - 0s 823us/step - loss: 0.0774 - accuracy: 0.9816 - val_loss: 0.0624 - val_accuracy: 0.9833\n",
      "Epoch 2/100\n",
      "456/456 [==============================] - 0s 609us/step - loss: 0.0423 - accuracy: 0.9884 - val_loss: 0.0476 - val_accuracy: 0.9842\n",
      "Epoch 3/100\n",
      "456/456 [==============================] - 0s 595us/step - loss: 0.0367 - accuracy: 0.9875 - val_loss: 0.0434 - val_accuracy: 0.9851\n",
      "Epoch 4/100\n",
      "456/456 [==============================] - 0s 584us/step - loss: 0.0342 - accuracy: 0.9877 - val_loss: 0.0402 - val_accuracy: 0.9842\n",
      "Epoch 5/100\n",
      "456/456 [==============================] - 0s 605us/step - loss: 0.0327 - accuracy: 0.9871 - val_loss: 0.0416 - val_accuracy: 0.9851\n",
      "Epoch 6/100\n",
      "456/456 [==============================] - 0s 613us/step - loss: 0.0297 - accuracy: 0.9901 - val_loss: 0.0419 - val_accuracy: 0.9842\n",
      "Epoch 7/100\n",
      "456/456 [==============================] - 0s 595us/step - loss: 0.0287 - accuracy: 0.9893 - val_loss: 0.0379 - val_accuracy: 0.9842\n",
      "Epoch 8/100\n",
      "456/456 [==============================] - 0s 708us/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.0359 - val_accuracy: 0.9842\n",
      "Epoch 9/100\n",
      "456/456 [==============================] - 0s 635us/step - loss: 0.0260 - accuracy: 0.9906 - val_loss: 0.0374 - val_accuracy: 0.9877\n",
      "Epoch 10/100\n",
      "456/456 [==============================] - 0s 571us/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.0407 - val_accuracy: 0.9877\n",
      "Epoch 11/100\n",
      "456/456 [==============================] - 0s 599us/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0411 - val_accuracy: 0.9860\n",
      "Epoch 12/100\n",
      "456/456 [==============================] - 0s 610us/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.0520 - val_accuracy: 0.9833\n",
      "Epoch 13/100\n",
      "456/456 [==============================] - 0s 633us/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.0316 - val_accuracy: 0.9877\n",
      "Epoch 14/100\n",
      "456/456 [==============================] - 0s 570us/step - loss: 0.0232 - accuracy: 0.9919 - val_loss: 0.0363 - val_accuracy: 0.9895\n",
      "Epoch 15/100\n",
      "456/456 [==============================] - 0s 582us/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0508 - val_accuracy: 0.9789\n",
      "Epoch 16/100\n",
      "456/456 [==============================] - 0s 607us/step - loss: 0.0228 - accuracy: 0.9919 - val_loss: 0.0452 - val_accuracy: 0.9851\n",
      "Epoch 17/100\n",
      "456/456 [==============================] - 0s 620us/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0286 - val_accuracy: 0.9877\n",
      "Epoch 18/100\n",
      "456/456 [==============================] - 0s 508us/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 0.0349 - val_accuracy: 0.9895\n",
      "Epoch 19/100\n",
      "456/456 [==============================] - 0s 541us/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.0336 - val_accuracy: 0.9868\n",
      "Epoch 20/100\n",
      "456/456 [==============================] - 0s 517us/step - loss: 0.0221 - accuracy: 0.9921 - val_loss: 0.0356 - val_accuracy: 0.9895\n",
      "Epoch 21/100\n",
      "456/456 [==============================] - 0s 535us/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 0.0327 - val_accuracy: 0.9886\n",
      "Epoch 22/100\n",
      "456/456 [==============================] - 0s 501us/step - loss: 0.0221 - accuracy: 0.9917 - val_loss: 0.0333 - val_accuracy: 0.9895\n",
      "Epoch 23/100\n",
      "456/456 [==============================] - 0s 697us/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.0320 - val_accuracy: 0.9895\n",
      "Epoch 24/100\n",
      "456/456 [==============================] - 0s 620us/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0291 - val_accuracy: 0.9904\n",
      "Epoch 25/100\n",
      "456/456 [==============================] - 0s 570us/step - loss: 0.0204 - accuracy: 0.9923 - val_loss: 0.0313 - val_accuracy: 0.9895\n",
      "Epoch 26/100\n",
      "456/456 [==============================] - 0s 606us/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.0276 - val_accuracy: 0.9912\n",
      "Epoch 27/100\n",
      "456/456 [==============================] - 0s 587us/step - loss: 0.0203 - accuracy: 0.9923 - val_loss: 0.0316 - val_accuracy: 0.9904\n",
      "Epoch 28/100\n",
      "456/456 [==============================] - 0s 560us/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.0287 - val_accuracy: 0.9912\n",
      "Epoch 29/100\n",
      "456/456 [==============================] - 0s 557us/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 0.0311 - val_accuracy: 0.9904\n",
      "Epoch 30/100\n",
      "456/456 [==============================] - 0s 616us/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.0294 - val_accuracy: 0.9912\n",
      "Epoch 31/100\n",
      "456/456 [==============================] - 0s 559us/step - loss: 0.0199 - accuracy: 0.9923 - val_loss: 0.0434 - val_accuracy: 0.9877\n",
      "Epoch 32/100\n",
      "456/456 [==============================] - 0s 666us/step - loss: 0.0193 - accuracy: 0.9932 - val_loss: 0.0263 - val_accuracy: 0.9921\n",
      "Epoch 33/100\n",
      "456/456 [==============================] - 0s 506us/step - loss: 0.0188 - accuracy: 0.9930 - val_loss: 0.0306 - val_accuracy: 0.9895\n",
      "Epoch 34/100\n",
      "456/456 [==============================] - 0s 602us/step - loss: 0.0208 - accuracy: 0.9923 - val_loss: 0.0284 - val_accuracy: 0.9912\n",
      "Epoch 35/100\n",
      "456/456 [==============================] - 0s 555us/step - loss: 0.0198 - accuracy: 0.9925 - val_loss: 0.0312 - val_accuracy: 0.9904\n",
      "Epoch 36/100\n",
      "456/456 [==============================] - 0s 638us/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.0305 - val_accuracy: 0.9912\n",
      "Epoch 37/100\n",
      "456/456 [==============================] - 0s 541us/step - loss: 0.0191 - accuracy: 0.9941 - val_loss: 0.0269 - val_accuracy: 0.9904\n",
      "Epoch 38/100\n",
      "456/456 [==============================] - 0s 560us/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.0287 - val_accuracy: 0.9904\n",
      "Epoch 39/100\n",
      "456/456 [==============================] - 0s 604us/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0286 - val_accuracy: 0.9895\n",
      "Epoch 40/100\n",
      "456/456 [==============================] - 0s 583us/step - loss: 0.0190 - accuracy: 0.9934 - val_loss: 0.0325 - val_accuracy: 0.9904\n",
      "Epoch 41/100\n",
      "456/456 [==============================] - 0s 520us/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0280 - val_accuracy: 0.9912\n",
      "Epoch 42/100\n",
      "456/456 [==============================] - 0s 575us/step - loss: 0.0195 - accuracy: 0.9925 - val_loss: 0.0263 - val_accuracy: 0.9904\n",
      "Epoch 43/100\n",
      "456/456 [==============================] - 0s 553us/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 0.0292 - val_accuracy: 0.9895\n",
      "Epoch 44/100\n",
      "456/456 [==============================] - 0s 550us/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.0285 - val_accuracy: 0.9895\n",
      "Epoch 45/100\n",
      "456/456 [==============================] - 0s 521us/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.0357 - val_accuracy: 0.9904\n",
      "Epoch 46/100\n",
      "456/456 [==============================] - 0s 578us/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0260 - val_accuracy: 0.9904\n",
      "Epoch 47/100\n",
      "456/456 [==============================] - 0s 556us/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0352 - val_accuracy: 0.9904\n",
      "Epoch 48/100\n",
      "456/456 [==============================] - 0s 617us/step - loss: 0.0184 - accuracy: 0.9934 - val_loss: 0.0255 - val_accuracy: 0.9912\n",
      "Epoch 49/100\n",
      "456/456 [==============================] - 0s 524us/step - loss: 0.0189 - accuracy: 0.9925 - val_loss: 0.0305 - val_accuracy: 0.9904\n",
      "Epoch 50/100\n",
      "456/456 [==============================] - 0s 560us/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0338 - val_accuracy: 0.9904\n",
      "Epoch 51/100\n",
      "456/456 [==============================] - 0s 608us/step - loss: 0.0189 - accuracy: 0.9930 - val_loss: 0.0303 - val_accuracy: 0.9912\n",
      "Epoch 52/100\n",
      "456/456 [==============================] - 0s 547us/step - loss: 0.0184 - accuracy: 0.9930 - val_loss: 0.0256 - val_accuracy: 0.9921\n",
      "Epoch 53/100\n",
      "456/456 [==============================] - 0s 534us/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0293 - val_accuracy: 0.9930\n",
      "Epoch 54/100\n",
      "456/456 [==============================] - 0s 563us/step - loss: 0.0186 - accuracy: 0.9928 - val_loss: 0.0269 - val_accuracy: 0.9904\n",
      "Epoch 55/100\n",
      "456/456 [==============================] - 0s 609us/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0289 - val_accuracy: 0.9904\n",
      "Epoch 56/100\n",
      "456/456 [==============================] - 0s 557us/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.0270 - val_accuracy: 0.9912\n",
      "Epoch 57/100\n",
      "456/456 [==============================] - 0s 529us/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.0277 - val_accuracy: 0.9904\n",
      "Epoch 58/100\n",
      "456/456 [==============================] - 0s 546us/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.0352 - val_accuracy: 0.9877\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=10)\n",
    "mc = ModelCheckpoint('best_model_NOREG.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model4 = build_model()\n",
    "history4 = model4.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, \n",
    "                      batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 593us/step - loss: 0.0287 - accuracy: 0.9894\n",
      "Loss 0.021506, Accuracy 0.991813\n",
      "Loss 0.019388, Accuracy 0.992632\n",
      "Loss 0.046756, Accuracy 0.991813\n",
      "Loss 0.028725, Accuracy 0.989357\n"
     ]
    }
   ],
   "source": [
    "test_loss_4, test_acc_4 = model4.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_3, test_acc_3))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_4, test_acc_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def build_L2_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    h_dim=100\n",
    "    model.add(Dense(h_dim, activation='relu', input_shape=(n_feature,), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "456/456 [==============================] - 0s 930us/step - loss: 1.0357 - accuracy: 0.9794 - val_loss: 0.3995 - val_accuracy: 0.8746\n",
      "Epoch 2/100\n",
      "456/456 [==============================] - 0s 678us/step - loss: 0.2934 - accuracy: 0.9855 - val_loss: 0.2784 - val_accuracy: 0.9868\n",
      "Epoch 3/100\n",
      "456/456 [==============================] - 0s 641us/step - loss: 0.2245 - accuracy: 0.9776 - val_loss: 0.2440 - val_accuracy: 0.9868\n",
      "Epoch 4/100\n",
      "456/456 [==============================] - 0s 707us/step - loss: 0.1921 - accuracy: 0.9871 - val_loss: 0.1140 - val_accuracy: 0.9737\n",
      "Epoch 5/100\n",
      "456/456 [==============================] - 0s 680us/step - loss: 0.2004 - accuracy: 0.9794 - val_loss: 0.2354 - val_accuracy: 0.9842\n",
      "Epoch 6/100\n",
      "456/456 [==============================] - 0s 612us/step - loss: 0.1852 - accuracy: 0.9846 - val_loss: 0.2267 - val_accuracy: 0.9868\n",
      "Epoch 7/100\n",
      "456/456 [==============================] - 0s 636us/step - loss: 0.2011 - accuracy: 0.9785 - val_loss: 0.2328 - val_accuracy: 0.9868\n",
      "Epoch 8/100\n",
      "456/456 [==============================] - 0s 633us/step - loss: 0.1732 - accuracy: 0.9851 - val_loss: 0.1587 - val_accuracy: 0.9868\n",
      "Epoch 9/100\n",
      "456/456 [==============================] - 0s 598us/step - loss: 0.1198 - accuracy: 0.9857 - val_loss: 0.1420 - val_accuracy: 0.9851\n",
      "Epoch 10/100\n",
      "456/456 [==============================] - 0s 617us/step - loss: 0.1367 - accuracy: 0.9877 - val_loss: 0.1300 - val_accuracy: 0.9833\n",
      "Epoch 11/100\n",
      "456/456 [==============================] - 0s 677us/step - loss: 0.1236 - accuracy: 0.9864 - val_loss: 0.2007 - val_accuracy: 0.9868\n",
      "Epoch 12/100\n",
      "456/456 [==============================] - 0s 605us/step - loss: 0.1155 - accuracy: 0.9807 - val_loss: 0.1727 - val_accuracy: 0.9868\n",
      "Epoch 13/100\n",
      "456/456 [==============================] - 0s 599us/step - loss: 0.1133 - accuracy: 0.9875 - val_loss: 0.1367 - val_accuracy: 0.9868\n",
      "Epoch 14/100\n",
      "456/456 [==============================] - 0s 655us/step - loss: 0.2450 - accuracy: 0.9404 - val_loss: 0.1619 - val_accuracy: 0.9491\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_L2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "L2_model = build_L2_model()\n",
    "h_L2 = L2_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, \n",
    "                    batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "def build_DROPOUT_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    h_dim=100\n",
    "    model.add(Dense(h_dim, activation='relu', input_shape=(n_feature,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "456/456 [==============================] - 0s 956us/step - loss: 0.2316 - accuracy: 0.9726 - val_loss: 0.2014 - val_accuracy: 0.9868\n",
      "Epoch 2/100\n",
      "456/456 [==============================] - 0s 778us/step - loss: 0.1972 - accuracy: 0.9833 - val_loss: 0.2006 - val_accuracy: 0.9868\n",
      "Epoch 3/100\n",
      "456/456 [==============================] - 0s 672us/step - loss: 0.1739 - accuracy: 0.9871 - val_loss: 0.2006 - val_accuracy: 0.9868\n",
      "Epoch 4/100\n",
      "456/456 [==============================] - 0s 727us/step - loss: 0.1808 - accuracy: 0.9882 - val_loss: 0.2006 - val_accuracy: 0.9868\n",
      "Epoch 5/100\n",
      "456/456 [==============================] - 0s 749us/step - loss: 0.1779 - accuracy: 0.9882 - val_loss: 0.2006 - val_accuracy: 0.9868\n",
      "Epoch 6/100\n",
      "456/456 [==============================] - 0s 678us/step - loss: 0.1752 - accuracy: 0.9879 - val_loss: 0.2008 - val_accuracy: 0.9868\n",
      "Epoch 7/100\n",
      "456/456 [==============================] - 0s 694us/step - loss: 0.1856 - accuracy: 0.9868 - val_loss: 0.2006 - val_accuracy: 0.9868\n",
      "Epoch 8/100\n",
      "456/456 [==============================] - 0s 695us/step - loss: 0.1845 - accuracy: 0.9877 - val_loss: 0.2006 - val_accuracy: 0.9868\n",
      "Epoch 9/100\n",
      "456/456 [==============================] - 0s 674us/step - loss: 0.1774 - accuracy: 0.9884 - val_loss: 0.2006 - val_accuracy: 0.9868\n",
      "Epoch 10/100\n",
      "456/456 [==============================] - 0s 689us/step - loss: 0.1751 - accuracy: 0.9882 - val_loss: 0.2006 - val_accuracy: 0.9868\n",
      "Epoch 11/100\n",
      "456/456 [==============================] - 0s 682us/step - loss: 0.1806 - accuracy: 0.9882 - val_loss: 0.2006 - val_accuracy: 0.9868\n",
      "Epoch 12/100\n",
      "456/456 [==============================] - 0s 670us/step - loss: 0.1773 - accuracy: 0.9884 - val_loss: 0.2006 - val_accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_DROPOUT.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "DROPOUT_model = build_DROPOUT_model()\n",
    "h_DROPOUT = DROPOUT_model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                              epochs=100, batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 367us/step - loss: 0.0198 - accuracy: 0.9926\n",
      " 1/77 [..............................] - ETA: 0s - loss: 0.1706 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0005s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0005s). Check your callbacks.\n",
      "77/77 [==============================] - 0s 464us/step - loss: 0.1123 - accuracy: 0.9754\n",
      "77/77 [==============================] - 0s 412us/step - loss: 0.1436 - accuracy: 0.9906\n"
     ]
    }
   ],
   "source": [
    "# laod best models and test them\n",
    "from keras.models import load_model\n",
    "\n",
    "best_NOREG_model = load_model('best_model_NOREG.h5')\n",
    "best_L2_model = load_model('best_model_L2.h5')\n",
    "best_DROPOUT_model = load_model('best_model_DROPOUT.h5')\n",
    "\n",
    "loss_NOREG, acc_NOREG = best_NOREG_model.evaluate(X_test, y_test)\n",
    "loss_L2, acc_L2 = best_L2_model.evaluate(X_test, y_test)\n",
    "loss_DROPOUT, acc_DROPOUT = best_DROPOUT_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.019843, Accuracy 0.992632\n",
      "Loss 0.112273, Accuracy 0.975440\n",
      "Loss 0.143627, Accuracy 0.990585\n"
     ]
    }
   ],
   "source": [
    "print('Loss %f, Accuracy %f' % (loss_NOREG, acc_NOREG))\n",
    "print('Loss %f, Accuracy %f' % (loss_L2, acc_L2))\n",
    "print('Loss %f, Accuracy %f' % (loss_DROPOUT, acc_DROPOUT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_layers=2, h_dim=64, activation='relu', optimizer='adam'):\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    \n",
    "    model.add(Dense(h_dim, activation=activation, input_shape=(n_feature,)))\n",
    "    for i in range(n_layers-1):\n",
    "        model.add(Dense(h_dim, activation=activation))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = [1, 2, 3]\n",
    "h_dim = [32, 64, 128]\n",
    "activation = ['relu', 'tanh']\n",
    "optimizer = ['adagrad', 'adam']\n",
    "params = dict(optimizer=optimizer, n_layers=n_layers, h_dim=h_dim, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 362us/step - loss: 0.1706 - accuracy: 0.9888\n",
      "48/48 [==============================] - 0s 403us/step - loss: 0.1613 - accuracy: 0.9888\n",
      "48/48 [==============================] - 0s 393us/step - loss: 0.2009 - accuracy: 0.9868\n",
      "48/48 [==============================] - 0s 393us/step - loss: 0.1175 - accuracy: 0.9875\n",
      " 1/48 [..............................] - ETA: 0s - loss: 0.0237 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0005s). Check your callbacks.\n",
      "48/48 [==============================] - 0s 475us/step - loss: 0.1166 - accuracy: 0.9888\n",
      "48/48 [==============================] - 0s 351us/step - loss: 0.2027 - accuracy: 0.9855\n",
      "48/48 [==============================] - 0s 382us/step - loss: 0.1405 - accuracy: 0.9908\n",
      "48/48 [==============================] - 0s 362us/step - loss: 0.1634 - accuracy: 0.9882\n",
      " 1/48 [..............................] - ETA: 0s - loss: 2.4101 - accuracy: 0.8438WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0005s). Check your callbacks.\n",
      "48/48 [==============================] - 0s 434us/step - loss: 3.3184 - accuracy: 0.7849\n",
      "48/48 [==============================] - 0s 465us/step - loss: 3.1966 - accuracy: 0.7928\n",
      "48/48 [==============================] - 0s 372us/step - loss: 0.1621 - accuracy: 0.9888\n",
      "48/48 [==============================] - 0s 444us/step - loss: 0.2011 - accuracy: 0.9868\n",
      "48/48 [==============================] - 0s 372us/step - loss: 0.1625 - accuracy: 0.9882\n",
      "48/48 [==============================] - 0s 362us/step - loss: 0.1613 - accuracy: 0.9888\n",
      "48/48 [==============================] - 0s 362us/step - loss: 0.2207 - accuracy: 0.9855\n"
     ]
    }
   ],
   "source": [
    "model = KerasRegressor(build_fn=build_model)\n",
    "\n",
    "rnd = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter=5, cv=3)\n",
    "rnd_result = rnd.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.145603 using {'optimizer': 'adam', 'n_layers': 1, 'h_dim': 64, 'activation': 'tanh'}\n",
      "0.177595 (0.016938) with: {'optimizer': 'adam', 'n_layers': 1, 'h_dim': 128, 'activation': 'relu'}\n",
      "0.145603 (0.040358) with: {'optimizer': 'adam', 'n_layers': 1, 'h_dim': 64, 'activation': 'tanh'}\n",
      "1.207406 (1.492723) with: {'optimizer': 'adam', 'n_layers': 2, 'h_dim': 64, 'activation': 'relu'}\n",
      "1.186600 (1.421386) with: {'optimizer': 'adam', 'n_layers': 2, 'h_dim': 32, 'activation': 'relu'}\n",
      "0.181500 (0.027732) with: {'optimizer': 'adam', 'n_layers': 3, 'h_dim': 32, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (-rnd_result.best_score_, rnd_result.best_params_))\n",
    "means = rnd_result.cv_results_['mean_test_score']\n",
    "stds = rnd_result.cv_results_['std_test_score']\n",
    "params = rnd_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (-mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/77 [..............................] - ETA: 0s - loss: 0.4765 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0005s). Check your callbacks.\n",
      "77/77 [==============================] - 0s 329us/step - loss: 0.1370 - accuracy: 0.9894\n",
      "Loss 0.137008, Accuracy 0.989357\n"
     ]
    }
   ],
   "source": [
    "clf = rnd_result.best_estimator_.model\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test)\n",
    "print('Loss %f, Accuracy %f' % (loss, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
